= Общие

== Что такое ООП?

Объектно-ориентированное программирование (ООП) — методология программирования, основанная на представлении программы в виде совокупности объектов, каждый из которых является экземпляром определённого класса, а классы образуют иерархию наследования.

== Какие преимущества у ООП?

* Возможность легкой модификации (при грамотном анализе и проектировании)
* Возможность отката при наличии версий
* Более легкая расширяемость
* «Более естественная» декомпозиция программного обеспечения, которая существенно облегчает его разработку
* Сокращение количества межмодульных вызовов и уменьшение объемов информации, передаваемой̆ между модулями
* Увеличивается показатель повторного использования кода

== Какие недостатки у ООП?

* Требуется другая квалификация
* Резко увеличивается время на анализ и проектирование систем
* Увеличение времени выполнения
* Размер кода увеличивается
* Неэффективно с точки зрения памяти (мертвый код - тот, который не используется)
* Сложность распределения работ на начальном этапе
* Себестоимость больше

== Назовите основные принципы ООП

* Абстракция
* Инкапсуляция
* Наследование
* Полиморфизм

== Что такое инкапсуляция? (С примером)

Инкапсуляция – это свойство системы, позволяющее объединить данные и методы, работающие с ними, в классе и скрыть детали реализации от пользователя.

Инкапсуляция – это механизм «обёртывания» данных или кода, который работает с этими данными в отдельный модуль. Инкапсулированные, таким образом, переменные, отделены от других классов и доступ к ним возможен только с помощью методов класса, который содержит эти переменные.

Пример: нажимая на педаль газа, мы не знаем и не понимаем что происходит под капотом, класс Автомобиль скрыл от нас реализацию и дал нам инструменты (методы) для работы с этой реализацией.

== Что такое наследование? (С примером)

Наследование – это свойство системы, позволяющее описать новый класс на основе уже существующего, частично или полностью заимствуя функциональность родителя. Класс, от которого производится наследование, называется базовым или родительским. Новый класс – потомком, наследником или производным классом.

Пример: есть человек родитель, его потомок наследует от него его характеристики, добавляя что-то свое.

== Что такое полиморфизм? (С примером)

Полиморфизм – это свойство системы использовать объекты с общим интерфейсом или классом родителем, без информации о типе и внутренней структуре объекта.

Пример: человек может есть еду в общем, будь-то ягоды, овощи или мясо.

== Что такое ассоциация, агрегация и композиция?

Реализуют has-a (имеет) отношения.

has-a отношения основаны на использовании. Выделяют три варианта отношения has-a: ассоциация, агрегация и композиция.

*Ассоциация* - это когда объекты двух классов могут ссылаться друг на друга. Например, класс Horse has-a Halter если код в классе Horse содержит ссылку на экземпляр класса Halter.

Агрегация и композиция являются частными случаями ассоциации.

*Агрегация* - отношение, когда один объект является частью другого.

*Композиция *- еще более тесная связь, когда объект не только является частью другого объекта, но и вообще не может принадлежать другому объекту.

*Агрегация*: объект класса Halter создается извне Horse и передается в конструктор для установления связи, если объект класса Horse будет удален, объект класса Halter может и дальше использоваться, если, конечно, на него останется ссылка.

*Композиция*: объект класса Halter создается в конструкторе, что означает более тесную связь между объектами, объект класса Halter не может существовать без создавшего его объекта Horse.</div>

== "Что значит является - ""is a"", имеет - ""has a""?"

«является» подразумевает наследование.

«имеет» подразумевает ассоциацию (агрегацию или композицию).

== Расскажите про раннее (статическое) и позднее (динамическое) связывание

Присоединение вызова метода к телу метода называется связыванием. Если связывание проводится компилятором (компоновщиком) перед запуском программы, то оно называется статическим или ранним связыванием (early binding).

В свою очередь, позднее связывание (late binding) это связывание, проводимое непосредственно во время выполнения программы, в зависимости от типа объекта. Позднее связывание также называют динамическим (dynamic) или связыванием на стадии выполнения (runtime binding). В языках, реализующих позднее связывание, должен существовать механизм определения фактического типа объекта во время работы программы, для вызова подходящего метода. Иначе говоря, компилятор не знает тип объекта, но механизм вызова методов определяет его и вызывает соответствующее тело метода. Механизм позднего связывания зависит от конкретного языка, но нетрудно предположить, что для его реализации в объекты должна включаться какая-то дополнительная информация.

Для всех методов Java используется механизм позднего (динамического) связывания, если только метод не статический и не был объявлен как final (приватные методы являются final по умолчанию).

== Расскажите про SOLID

*Принцип единственной ответственности* - класс должен быть ответственен лишь за что-то одно. Если класс отвечает за решение нескольких задач, его подсистемы, реализующие решение этих задач, оказываются связанными друг с другом. Изменения в одной такой подсистеме ведут к изменениям в другой.

*Принцип открытости-закрытости*- программные сущности (классы, модули, функции) должны быть открыты для расширения, но не для модификации.

*Принцип подстановки Барбары Лисков* - необходимо, чтобы подклассы могли служить заменой для своих суперклассов.

Цель этого принципа заключаются в том, чтобы классы-наследники могли бы использоваться вместо родительских классов, от которых они образованы, не нарушая работу программы. Если оказывается, что в коде проверяется тип класса, значит принцип подстановки нарушается.

*Принцип разделения интерфейса* - создавайте узкоспециализированные интерфейсы, предназначенные для конкретного клиента. Клиенты не должны зависеть от интерфейсов, которые они не используют. Этот принцип направлен на устранение недостатков, связанных с реализацией больших интерфейсов.

*Принцип инверсии зависимостей*- объектом зависимости должна быть абстракция, а не что-то конкретное. Модули верхних уровней не должны зависеть от модулей нижних уровней. Оба типа модулей должны зависеть от абстракций.

Абстракции не должны зависеть от деталей. Детали должны зависеть от абстракций. В процессе разработки программного обеспечения существует момент, когда функционал приложения перестает помещаться в рамках одного модуля. Когда это происходит, нам приходится решать проблему зависимостей модулей. В результате, например, может оказаться так, что высокоуровневые компоненты зависят от низкоуровневых компонентов.

== Какова основная идея языка?

Кроссплатформенность - в основу Java положен принцип WORA «Write Once Run Anywhere», на русском «Написано один раз, работает везде».

== За счет чего обеспечивается кроссплатформенность?

Кроссплатформенность достигается за счет использования виртуальной машины «Java Virtual Machine» – JVM.

== Какие преимущества у Java?

* *Кроссплатформенность* - благодаря JVM
* *Безопасность* - напиример использование классов, имеющих цифровую подпись. Полные права предоставляются только при полном доверии автору класса
* *Простота* – первое техническое достоинство Java. У него чёткие синтаксические правила и понятная семантика. Рациональность и краткость очень полезны для обработки кода машинами с ограниченным объёмом ресурсов
* *Объектно-ориентированный подход - з*а 3 десятилетия он доказал свою эффективность. Суть состоит в том, что в центре внимания находятся данные (объекты), интерфейсы и алгоритмы вторичны. Другими словами, мы отталкиваемся от результата при выборе инструментов, способов их применения

== Какие недостатки у Java?

* *Производительность *-  в отличие от языков C или С++, вместо компилятора у Java применяется виртуальная машина JVM. Это несколько снижает скорость исполнения Java-кода, так как сначала процессору нужно запустить JVM, а потом она начинает выполнять код. Считается, что ПО на Java работает медленнее, чем такие же программы на C/C++
* *Количество кода *- помимо прочего, Java отличается от других популярных языков (например, Python) довольно длинными и объемными конструкциями кода. Это фактор может сделать язык весьма запутанным для начинающих программистов

== Что такое JDK? Что в него входит?

Java Development Kit - набор инструментов разработчика.

В JDK входят:

* Java Virtual Machine (JVM) - виртуальная машина для запуска байт кода
* Java Runtime Environment (JRE) - минимальная реализация виртуальной машины, необходимая для запуска Java приложений, не содержит инструментов разработки
* Java Development Tools - другие инструменты для разработки приложений

== Что такое byte code?

Набор инструкций, исполняемых виртуальной машиной Java.

== Что такое загрузчик классов «classloader»?

Загрузчик классов является частью JRE, которая динамически загружает Java классы в JVM. Обычно классы загружаются только по запросу. Система исполнения в Java не должна знать о файлах и файловых системах благодаря загрузчику классов. Делегирование является важной концепцией, которую выполняет загрузчик. Загрузчик классов отвечает за поиск библиотек, чтение их содержимого и загрузку классов, содержащихся в библиотеках. Эта загрузка обычно выполняется «по требованию», поскольку она не происходит до тех пор, пока программа не вызовет класс. Класс с именем может быть загружен только один раз данным загрузчиком классов.

При запуске JVM, используются три загрузчика классов:</div>

* *Bootstrap* class loader (Загрузчик класса Bootstrap)
* *Extensions* class loader (Загрузчик класса расширений)
* *System* class loader (Системный загрузчик классов)

- Загрузчик класса Bootstrap загружает основные библиотеки Java, расположенные в папке `&lt;JAVA_HOME&gt;/jre/lib`. Этот загрузчик является частью ядра JVM, написан на нативном коде.

- Загрузчик класса расширений загружает код в каталоги расширений (`&lt;JAVA_HOME&gt;/jre/lib/ext`, или любой другой каталог, указанный системным свойством `java.ext.dirs`).

- Системный загрузчик загружает код, найденный в `java.class.path`, который сопоставляется с переменной среды `CLASSPATH`. Это реализуется классом `sun.misc.Launcher$AppClassLoader`.

== Что такое JIT?

Just-in-time compilation, компиляция «на лету» – технология увеличения производительности программных систем, использующих байт-код, путём компиляции байт-кода в машинный код или в другой формат непосредственно во время работы программы.

== Что такое сборщик мусора? (Garbage collector)

Сборщик мусора - это программа, которая работает на виртуальной машине Java и избавляется от объектов, которые больше не используются приложением Java. Это форма автоматического управления памятью.

Сборщик мусора Garbage Collector выполняет всего две задачи, связанные с поиском мусора и его очисткой. Для обнаружения мусора существует два подхода:

* Reference counting – учет ссылок;
* Tracing – трассировка.

Суть подхода «Reference counting» связана с тем, что каждый объект имеет счетчик, который хранит информацию о количестве указывающих на него ссылок. При уничтожении ссылки счетчик уменьшается. При нулевом значении счетчика объект можно считать мусором.

Главным недостатком данного подхода является сложность обеспечения точности счетчика и «невозможность» выявлять циклические зависимости. Так, например, два объекта могут ссылаться друг на друга, но ни на один из них нет внешней ссылки. Это сопровождается утечками памяти. В связи с этим данный подход не получил распространения.

Главная идея «Tracing» связана с тем, что до «живого» объекта можно добраться из корневых точек (GC Root). Всё, что доступно из «живого» объекта, также является «живым». Если представить все объекты и ссылки между ними как дерево, то необходимо пройти от корневых узлов GC Roots по всем узлам. При этом узлы, до которых нельзя добраться, являются мусором.

Данный подход, обеспечивающий выявление циклических ссылок, используется в виртуальной машине HotSpot VM.

JVM HotSpot использует алгоритм сборки мусора типа «Generational Garbage Collection», который позволяет применять разные модули для разных этапов сборки мусора. Всего в HotSpot реализовано четыре сборщика мусора:

* *Serial (последовательный)*  - Первый, примитивный. Прямой как палка. Для сборки мусора полностью останавливает JVM и собирает мусор в один поток.
* *Parallel (параллельный)* - Попытка сделать сборку быстрой и многопоточной. На многоядерных процессорах это хорошо работает. Но все равно для сборки он требует полного останова JVM. Использовался по умолчанию до Java 9. В новых версиях Java он продолжает совершенствоваться и дополняться новыми опциями, так что для каких-то особых приложений можно не обращаться к новым сборщикам мусора. Справится и улучшенный Parallel GC.
* *Concurrent Mark Sweep (CMS)* - Цель — отсрочить полную сборку мусора с остановом JVM путем маленьких и коротких операций по сбору сведений о мусоре, а потом путём быстрых и коротких операций — убрать, что можно. Если достигается определенный процент использованного heap, т.е. CMS-сборщик видит, что не справляется, то JVM останавливается и происходит полная сборка мусора.
* *Garbage-First (G1)* - Впервые появился как экспериментальный в JDK6u14, а начиная с JDK7 Update 4 — как официальный. В Java 9 он теперь включен по умолчанию. Мейнстрим на несколько релизов Java вперед. Поколенческий, как и все предыдущие сборщики, но зоны поколений реализованы несколько иначе. Постоянно совершенствуется. В новых версиях Java 11 и Java 12 добавляются новые функции.

== Что такое поколения объектов?

Для оптимизации сборки мусора память кучи дополнительно разделена на четыре области. В эти области объекты помещаются в зависимости от их возраста (как долго они используются в приложении).</div>

*  *Young Generation (молодое поколение)*. Здесь создаются новые объекты. Область young generation разделена на три части раздела: Eden (Эдем), S0 и S1 (Survivor Space — область для выживших).</div>
*  *Old Generation (старое поколение)*. Здесь хранятся давно живущие объекты.</div>

== Что такое finalize()? Зачем он нужен?

Через вызов метода finalize() JVM реализуется функциональность аналогичная функциональности деструкторов в С++, используемых для очистки памяти перед возвращением управления операционной системе. Данный метод вызывается при уничтожении объекта сборщиком мусора (garbage collector) и переопределяя finalize() можно запрограммировать действия необходимые для корректного удаления экземпляра класса - например, закрытие сетевых соединений, соединений с базой данных, снятие блокировок на файлы и т.д.

После выполнения этого метода объект должен быть повторно собран сборщиком мусора (и это считается серьезной проблемой метода finalize() т.к. он мешает сборщику мусора освобождать память). Вызов этого метода не гарантируется, т.к. приложение может быть завершено до того, как будет запущена сборка мусора. Объект не обязательно будет доступен для сборки сразу же - метод finalize() может сохранить куда-нибудь ссылку на объект. Подобная ситуация называется «возрождением» объекта и считается антипаттерном. Главная проблема такого трюка - в том, что «возродить» объект можно только 1 раз.

== Что такое Heap и Stack память в Java? Чем они отличаются?

Heap (куча) используется Java Runtime для выделения памяти под объекты и классы. Создание нового объекта также происходит в куче. Это же является областью работы сборщика мусора. Любой объект, созданный в куче, имеет глобальный доступ и на него могут ссылаться из любой части приложения.

Stack (стек) это область хранения данных также находящееся в общей оперативной памяти (RAM). Всякий раз, когда вызывается метод, в памяти стека создается новый блок, который содержит примитивы и ссылки на другие объекты в методе. Как только метод заканчивает работу, блок также перестает использоваться, тем самым предоставляя доступ для следующего метода. Размер стековой памяти намного меньше объема памяти в куче. Стек в Java работает по схеме LIFO (Последний-зашел-Первый-вышел)

Различия между Heap и Stack памятью:

* Куча используется всеми частями приложения в то время как стек используется только одним потоком исполнения программы
* Всякий раз, когда создается объект, он всегда хранится в куче, а в памяти стека содержится лишь ссылка на него. Память стека содержит только локальные переменные примитивных типов и ссылки на объекты в куче
* Объекты в куче доступны с любой точке программы, в то время как стековая память не может быть доступна для других потоков
* Стековая память существует лишь какое-то время работы программы, а память в куче живет с самого начала до конца работы программы
* Если память стека полностью занята, то Java Runtime бросает исключение java.lang.StackOverflowError. Если заполнена память кучи, то бросается исключение java.lang.OutOfMemoryError: Java Heap Space
* Размер памяти стека намного меньше памяти в куче
* Из-за простоты распределения памяти, стековая память работает намного быстрее кучи

Для определения начального и максимального размера памяти в куче используются -Xms и -Xmx опции JVM. Для стека определить размер памяти можно с помощью опции -Xss.

*Верно ли утверждение, что примитивные типы данных всегда хранятся в стеке, а экземпляры ссылочных типов данных в куче?*

Не совсем. Примитивное поле экземпляра класса хранится не в стеке, а в куче. Любой объект (всё, что явно или неявно создаётся при помощи оператора new) хранится в куче.

== Какие примитивные типы данных есть в Java?

В Java есть 8 примитивных типов, которые делят на 4 группы, вот они:

* Целые числа - byte, short, int, long
* Числа с плавающей точкой (иначе вещественные) - float, double
* Логический - boolean
* Символьный - char

== Что такое char?

Символьный тип char: хранит одиночный символ в кодировке UTF-16 и занимает 2 байта, поэтому диапазон хранимых значений от 0 до 65535.

== Сколько памяти занимает boolean?

boolean занимает 4 байта, но когда находится в массиве 1 байт.

== Что такое классы-обертки?

Если требуется создать ссылку на один из примитивных типов данных, необходимо использовать соответствующий класс-обертку. Также в таких классах есть некоторые полезные методы и константы. Оборачивание примитива в объект называется упаковкой (boxing), а обратный процесс распаковкой (unboxing).

== Что такое автоупаковка и автораспаковка?

Автоупаковка (autoboxing) — это процесс автоматической инкапсуляции данных простого типа, такого как int или double, в эквивалентную ему оболочку типа, как только понадобится объект этого типа. При этом нет необходимости в явном создании объекта нужного типа.

Автоупаковка происходит при прямом присваивании примитива классу-обертке (с помощью оператора “=”), либо при передаче примитива в параметры метода (типа класса-обертки).

Автораспаковка (auto-unboxing) — это процесс автоматического извлечения из упакованного объекта значения, когда оно потребуется.

== Что такое явное и неявное приведение типов? В каких случаях в java нужно использовать явное приведение?

Когда в одной операции вовлечены данные разных типов, не всегда необходимо использовать операцию преобразования типов. Некоторые виды преобразований выполняются неявно, автоматически.

Автоматически без каких-либо проблем производятся расширяющие преобразования (widening) - они расширяют представление объекта в памяти:

<i>byte -&gt; short -&gt; int -&gt; long
int -&gt; double
short -&gt; float -&gt; double
char -&gt; int


</i>

Некоторые преобразования могут производиться автоматически между типами данных одинаковой разрядности или даже от типа данных с большей разрядностью к типу с меньшей разрядностью. Это следующие цепочки преобразований:

int -&gt; float, long -&gt; float и long -&gt; double

Они производятся без ошибок, но при преобразовании мы можем столкнуться с потерей информации.

Во всех остальных преобразованиях примитивных типов явным образом применяется операция преобразования типов. Обычно это сужающие преобразования (narrowing) от типа с большей разрядностью к типу с меньшей разрядностью.

== Что такое пул интов?

"Integer pool - это пул где хранятся значения от -128 до 127, когда классу обертке Integer присваивается значения через «=», двум разным ссылкам присваивается один и тот же кэшированный объект:

[source, java]
----
Integer a = 120;

Integer b = 120;

Integer c = 130;

Integer d = 130;

System.<span style=""font-style: italic;"">out</span>.println(a == b); -&gt; true

System.<span style=""font-style: italic;"">out</span>.println(c == d); -&gt; false
----
"

== Какие нюансы у строк в Java?

* String неизменяемый класс, то есть однажды созданную строку нельзя изменить
* Когда объект String создается через строковый литерал, он помещается в String Pool, строки созданные через ключевое слово «new» не помещаются в пул строк, а хранятся просто в куче (heap)
* Созданную через «new» строку можно интернировать методом Intern()
* Строки можно конкатенировать через оператор +
* С Java 7 строки можно использовать в конструкции «switch»

== Что такое пул строк?

*String Pool* - это область памяти в куче (heap), где хранятся интернированные строки или строки которые созданы через строковый литерал.

== Почему не рекомендуется изменять строки в цикле? Что рекомендуется использовать?

Потому что при каждом изменени строки, создается новый объект String и по итогу создается столько объектов, сколько итераций в цикле. Рекомендуется использовать StringBuilder или StringBuffer.

== Почему строки не рекомендуется использовать для хранения паролей?

Класс String неизменяемый и хранится в пуле строк. Строка остается в пуле строк, пока не будет удалена сборщиком мусора, поэтому, когда мы думаем, что закончили работу с паролем, он остается доступным в памяти некоторое время, и нет способа избежать этого. Это риск безопасности, поскольку кто-либо, имеющий доступ к дампу памяти сможет найти пароль в виде чистого текста.

Если мы используем массив символов для хранения пароля, мы можем очистить его после того, как закончим с ним работать. Таким образом, мы можем контролировать, как долго он находится в памяти, что позволяет избежать риска безопасности, свойственного строке.

== Почему String неизменяемый и финализированный класс?

* Неизменяемость строки дала возможность создать String Pool, который сохраняет больше памяти в куче (heap)
* Неизменяемость строки обеспечила безопасность данных, если бы строка была mutable, у злоумышленников была бы возможность изменять значения строки по ссылке
* Неизменяемость строки сделала безопасным её использования в работе с несколькими потоками
* Из-за неизменяемости строки, её hashCode кэшируется в момент создания и нет необходимости рассчитывать его снова, это сделал String идеальным кандидатом на роль ключа в HashMap

== Почему строка является популярным ключом в HashMap в Java?

Поскольку строки неизменны, их хэшкод кэшируется в момент создания и не требует повторного пересчета. Они обрабатываются быстрее, чем другие объекты-ключи.

== Что делает метод intern() в классе String?

Помещает строку из кучи в String Pool, если в пуле нет строк с таким значением, иначе возвращает ссылку на строку из String Pool.

== Можно ли использовать строки в конструкции switch?

Да, начиная с Java 7 в операторе switch можно использовать строки.

При этом:

* участвующие строки чувствительны к регистру
* используется метод equals() для сравнения полученного значения со значениями case, поэтому во избежание NullPointerException стоит предусмотреть проверку на null
* согласно документации, Java 7 для строк в switch, компилятор Java формирует более эффективный байткод для строк в конструкции switch, чем для сцепленных условий if-else

== Какая основная разница между String, StringBuffer, StringBuilder?

Класс `String` является неизменяемым (immutable) - модифицировать объект такого класса нельзя, можно лишь заменить его созданием нового экземпляра.

Класс `StringBuffer` изменяемый - использовать `StringBuffer` следует тогда, когда необходимо часто модифицировать содержимое.

Класс `StringBuilder` был добавлен в Java 5 и он во всем идентичен классу `StringBuffer` за исключением того, что он не синхронизирован и поэтому его методы выполняются значительно быстрей.

== Существуют ли в java многомерные массивы?

Да, это массив массивов.

[source, java]
----
int[][] numbers = new int[3][3];
----

== Какими значениями инициируются переменные по умолчанию?

В рамках класса поля (fields) инициализируются значениями по умолчанию (0, 0.0, null, false).

В рамках метода локальные переменные (local variables) обязательно должны быть инициализированы до использования.

== Что такое сигнатура метода?

Сигнатура метода — это имя метода и его параметры (порядок параметров имеет значение). В сигнатуру метода не входит возвращаемое значение и бросаемые им исключения.

<i>Контракт метода:</i>

*public void doSome(int x, int y) throw IOException{};*

<i>


Его сигнатура:</i>

*doSome(int x, int y)*

== Расскажите про метод main

* Точка входа в программу
* Может находиться в любом обычном классе
* Статический
* Принимает входной параметр – массив строк
* В приложении может быть несколько таких методов
* Если метод отсутствует, то компиляция возможна, но при запуске будет получена ошибка «Error: Main method not found»

== Каким образом переменные передаются в методы, по значению или по ссылке?

* Премитивные типы по значению
* Объекты по ссылке

То есть если изменить значение поля какого-то объекта в методе, то оно изменится и за пределами метода, если же изменить значение премитивного типа в методе, за пределами метода оно останется каким было.

== Какие виды классов есть в java?

* Обычный класс - public class * {}
* Абстракнтный класс - public abstract class * {}
* Финальный класс - public final class * {}
* Интерфейс - public interface * {}
* Enum - public enum * {}
* Вложенный класс - public class Outer { class Inner {} }
* Статический вложенный класс - public class Outer { static class Inner {} }
* Локальный внутренний класс -  public class Outer { public void doSome() { class Inner {} } }
* Анонимный класс :

Thread thread = new Thread() {[source, java]
----
    @Override

    public void run() {

 System.<span style=""font-style: italic;"">out</span>.println(""sd"");

    }

};
----


== Расскажите про вложенные классы. В каких случаях они применяются?

Класс называется вложенным (Nested class), если он определен внутри другого класса. Вложенный класс должен создаваться только для того, чтобы обслуживать обрамляющий его класс. Если вложенный класс оказывается полезен в каком-либо ином контексте, он должен стать классом верхнего уровня. Вложенные классы имеют доступ ко всем (в том числе приватным) полям и методам внешнего класса, но не наоборот. Из-за этого разрешения использование вложенных классов приводит к некоторому нарушению инкапсуляции.

Если связь между объектом внутреннего класса и объектом внешнего класса не нужна, можно сделать внутренний класс статическим (static). Такой класс называют вложенным (nested).

Существуют четыре категории вложенных классов: + Static nested class (Статический вложенный класс); + Member inner class (Простой внутренний класс); + Local inner class (Локальный класс); + Anonymous inner class (Анонимный класс).

Такие категории классов, за исключением первого, также называют внутренними (Inner class). Внутренние классы ассоциируются не с внешним классом, а с экземпляром внешнего.

Inner classes — внутренние классы (они же — non static nested classes, нестатические вложенные классы). Static nested classes - вложенные статические классы.</div>

== Что такое «локальный класс»? Каковы его особенности?

Local inner class (Локальный класс) - это вложенный класс, который может быть декларирован в любом блоке, в котором разрешается декларировать переменные. Как и простые внутренние классы (Member inner class) локальные классы имеют имена и могут использоваться многократно. Как и анонимные классы, они имеют окружающий их экземпляр только тогда, когда применяются в нестатическом контексте.

Локальные классы имеют следующие особенности:

* Видны только в пределах блока, в котором объявлены
* Не могут быть объявлены как private/public/protected или static
* Не могут иметь внутри себя статических объявлений (полей, методов, классов)
* Имеют доступ к полям и методам обрамляющего класса
* Могут обращаться к локальным переменным и параметрам метода, если они объявлены с модификатором final

== Что такое «анонимные классы»? Где они применяются?

Это вложенный локальный класс без имени, который разрешено декларировать в любом месте обрамляющего класса, разрешающем размещение выражений. Создание экземпляра анонимного класса происходит одновременно с его объявлением. В зависимости от местоположения анонимный класс ведет себя как статический либо как нестатический вложенный класс - в нестатическом контексте появляется окружающий его экземпляр.

Анонимные классы имеют несколько ограничений:

* Их использование разрешено только в одном месте программы - месте его создания
* Применение возможно только в том случае, если после порождения экземпляра нет необходимости на него ссылаться
* Реализует лишь методы своего интерфейса или суперкласса, т.е. не может объявлять каких-либо новых методов, так как для доступа к ним нет поименованного типа

Анонимные классы обычно применяются для:

* создания объекта функции (function object), например реализация интерфейса Comparator
* создания объекта процесса (process object), такого как экземпляры классов Thread, Runnable и подобных
* в статическом методе генерации
* инициализации открытого статического поля final, которое соответствует сложному перечислению типов, когда для каждого экземпляра в перечислении требуется отдельный подкласс

== Каким образом из вложенного класса получить доступ к полю внешнего класса?

Статический вложенный класс имеет прямой доступ только к статическим полям обрамляющего класса.

Простой внутренний класс, может обратиться к любому полю внешнего класса напрямую. В случае, если у вложенного класса уже существует поле с таким же литералом, то обращаться к такому полю следует через ссылку на его экземпляр.

Например: Outer.this.field

== Что такое перечисления (enum)?

enum – это класс перечислений. При объявлении переменной типа enum неявно создается класс производный от java.lang.Enum.

enum – это список именованных констант. Но в Java перечисления имеют более сложный функционал, чем в других языках программирования. Они могут иметь конструкторы, методы и переменные экземпляра.

Особенности enum классов:

* Конструктор всегда private или default
* Могут имплементировать интерфейсы
* Не могут наследовать класс
* Можем переопределить toString()
* Нет public конструктора, поэтому нельзя создать экземпляр вне Enum
* При equals() выполняется ==
* ordinal() возвращает порядковый номер элемента
* Может использоваться в TreeSet и TreeMap так как enum имплементирует Comparable
* compareTo() имитирует порядок элементов предоставляемый ordinal()
* Можно использовать в Switch Case
* values() возвращает массив всех констант

== Как проблема ромбовидного наследования решена в Java?

Множественное наследование может привести к проблеме ромба – когда один класс наследуется от двух, а те наследуются от одного предка. В Java не поддерживается множественное наследование классов, но допустимо множественное наследование интерфейсов. Интерфейсы только объявляют методы, а фактическая реализация будет сделана в конкретных классах, которые реализуют интерфейсы, так что нет никакой возможности двусмысленно трактовать множественное наследование в интерфейсе.

== Что такое конструктор по умолчанию?

Конструктор по умолчанию (default constructor) – это конструктор, который не имеет параметров. Конструктор по умолчанию может объявляться в классе явным образом или генерироваться автоматически.

== Могут ли быть приватные конструкторы? Для чего они нужны?

Да, такие конструкторы используются при реализации паттерна «Фабрика» или «Синглтон».

Сделав конструктор приватным, можно запретить возможность создания экземпляра (полезно для утилитных классов).

== Расскажите про классы-загрузчики и про динамическую загрузку классов

Основа работы с классами в Java — классы-загрузчики, обычные Java-объекты, предоставляющие интерфейс для поиска и создания объекта класса по его имени во время работы приложения.

В начале работы программы создается 3 основных загрузчика классов:

 * базовый загрузчик (bootstrap/primordial). Загружает основные системные и внутренние классы JDK (Core API - пакеты java.* (rt.jar и i18n.jar) . Важно заметить, что базовый загрузчик является «Изначальным» или «Корневым» и частью JVM, вследствие чего его нельзя создать внутри кода программы.

 * загрузчик расширений (extention). Загружает различные пакеты расширений, которые располагаются в директории &lt;JAVA_HOME&gt;/lib/ext или другой директории, описанной в системном параметре java.ext.dirs. Это позволяет обновлять и добавлять новые расширения без необходимости модифицировать настройки используемых приложений. Загрузчик расширений реализован классом sun.misc.Launcher$ExtClassLoader.

 * системный загрузчик (system/application). Загружает классы, пути к которым указаны в переменной окружения CLASSPATH или пути, которые указаны в командной строке запуска JVM после ключей -classpath или -cp. Системный загрузчик реализован классом sun.misc.Launcher$AppClassLoader.

Динамическая загрузка классов в Java имеет ряд особенностей:

 * отложенная (lazy) загрузка и связывание классов. Загрузка классов производится только при необходимости, что позволяет экономить ресурсы и распределять нагрузку.

 * проверка корректности загружаемого кода (type safeness). Все действия связанные с контролем использования типов производятся только во время загрузки класса, позволяя избежать дополнительной нагрузки во время выполнения кода.

 * программируемая загрузка. Пользовательский загрузчик полностью контролирует процесс получения запрошенного класса — самому ли искать байт-код и создавать класс или делегировать создание другому загрузчику. Дополнительно существует возможность выставлять различные атрибуты безопасности для загружаемых классов, позволяя таким образом работать с кодом из ненадежных источников.

 * множественные пространства имен. Каждый загрузчик имеет своё пространство имён для создаваемых классов. Соответственно, классы, загруженные двумя различными загрузчиками на основе общего байт-кода, в системе будут различаться.

Рассмотрим процесс загрузки более детально. Пусть в систем исполнения встретилась декларация переменной пользовательского класс Student.

. Системный загрузчик попытается поискать в кеше класс Student.
.. Если класс найден, загрузка окончена.
.. Если класс не найден, загрузка делегируется загрузчику расширений.

. Загрузчик расширений попытается поискать в кеше класс Student.
.. Если класс найден, загрузка окончена.
.. Если класс не найден, загрузка делегируется базовому загрузчику.

. Базовый загрузчик попытается поискать в кеше класс Student.
.. Если класс найден, загрузка окончена.
.. Если класс не найден, базовый загрузчик попытается его загрузить.
... Если загрузка прошла успешно, она закончена ;)
... Иначе управление предается загрузчику раширений.
.. Загрузчик расширений пытается загрузить класс.
... Если загрузка прошла успешно, она закончена ;)
... Иначе управление предается системному загрузчику.
.. Системный загрузчик пытается загрузить класс.
... Если загрузка прошла успешно, она закончена ;)
... Иначе генерируется исключение java.lang.ClassNotFoundException.

Динамическая загрузка классов производится через метод Class.forName(String className) или с использованием ClassLoader-а. Динамическая загрузка классов имеет смысл, когда требуется загрузить класс во время выполнения программы, когда нужно заменить класс, изменив, например, какую-то логику, не рестартуя приложения.

== Чем отличаются конструктор по-умолчанию, конструктор копирования и конструктор с параметрами?

Конструктор по умолчанию существует у всех объектов(явно или неявно) и не имеет никаких аргументов.

Конструктор копирования в качестве аргумента принимает свой же тип данных.

Конструктор копирования. В классе описывается конструктор, который принимает объект этого же класса и инициализирует значениями его полей поля нового объекта. О реализации инициализации полей полностью должен позаботиться разработчик класса.

Конструктор с параметрами принимает в качестве аргумента разные параметры и в разном количестве.

== Какие модификаторы доступа есть в Java? Какие применимы к классам?

* *public*: публичный, общедоступный класс или член класса. Поля и методы, объявленные с модификатором public, видны другим классам из текущего пакета и из внешних пакетов
* *private*: закрытый класс или член класса, противоположность модификатору public. Закрытый класс или член класса доступен только из кода в том же классе
* *protected*: такой класс или член класса доступен из любого места в текущем классе или пакете или в производных классах, даже если они находятся в других пакетах
* *default:* отсутствие модификатора у поля или метода класса предполагает применение к нему модификатора по умолчанию. Такие поля или методы видны всем классам в текущем пакете

*Для класса: public и модификатор по умолчанию.*

== Что означает модификатор static?

`static` — модификатор, применяемый к полю, блоку, методу или внутреннему классу. Данный модификатор указывает на привязку субъекта классу, а не к экземпляру класса.

== Может ли статический метод быть переопределён или перегружен?

Перегружен - да. Всё работает точно так же, как и с обычными методами - 2 статических метода могут иметь одинаковое имя, если количество их параметров или типов различается.

Переопределен - нет. Выбор вызываемого статического метода происходит при раннем связывании (на этапе компиляции, а не выполнения) и выполняться всегда будет родительский метод, хотя синтаксически переопределение статического метода - это вполне корректная языковая конструкция.

В целом, к статическим полям и методам рекомендуется обращаться через имя класса, а не объект.

== Могут ли нестатические методы перегрузить статические?

Да. В итоге получится два разных метода. Статический будет принадлежать классу и будет доступен через его имя, а нестатический будет принадлежать конкретному объекту и доступен через вызов метода этого объекта.

[source, java]
----
public static int plus(int a, int b) {
    return a + b;
}

public int plus(int a, int b, int c) {
    return a + b + c;
}
----

== Можно ли сузить уровень доступа/тип возвращаемого значения при переопределении метода?

Сузить модификатор доступа нелья, но можно расширить.

Сузить тип возвращаемого значения можно, если они совместимы:

[source, java]
----
public Object plus(int a, int b, int c) {
    return a + b + c;
}
----

[source, java]
----
@Override
public Integer plus(int a, int b, int c) {
    return a + b + c;
}
----

== Что можно изменить в сигнатуре метода при переопределении? Можно ли менять модификаторы (throws и тп)?

При переопределении метода сужать модификатор доступа не разрешается, т.к. это приведет к нарушению принципа подстановки Барбары Лисков. Расширение уровня доступа возможно.

Можно изменять все, что не мешает компилятору понять какой метод родительского класса имеется в виду:

* Изменять тип возвращаемого значения при переопределении метода разрешено только в сторону сужения типа (вместо родительского класса - наследника)
* При изменении типа, количества, порядка следования аргументов вместо переопределения будет происходить overloading (перегрузка) метода
* Секцию throws метода можно не указывать, но стоит помнить, что она остаётся действительной, если уже определена у метода родительского класса. Так же, возможно добавлять новые исключения, являющиеся наследниками от уже объявленных или исключения RuntimeException. Порядок следования таких элементов при переопределении значения не имеет

== Могут ли классы быть статическими?

Да, только вложенный. Вложенный статический класс имеет доступ только к статическим полям внешнего класса.

== Что означает модификатор final? К чему он может быть применим?

* `final` на полях - создает константу (переменная может быть проинициализирована только 1 раз)
* `final` на методах - нельзя переопределить метод
* `final` на классах - нельзя наследоваться от класса

== Могут ли быть конструкторы у абстрактных классов? Для чего они нужны?

Да, в абстрактном классе в Java можно объявить и определить конструкторы. Поскольку создавать экземпляры абстрактных классов нельзя, вызвать такой конструктор можно только при формировании цепочки конструкторов, то есть при создании экземпляра конкретного класса-реализации. Его можно использовать для задания начальных значений общих переменных, объявленных в абстрактном классе и используемых различными реализациями.

Даже если вы не объявили никакого конструктора, компилятор добавит в абстрактный класс конструктор по умолчанию без аргументов. Без него ваш подкласс не скомпилируется, поскольку первый оператор в любом конструкторе представляет собой неявный вызов super() – конструктора суперкласса по умолчанию в языке Java.

== Что такое интерфейсы? Какие модификаторы по умолчанию имеют поля и методы интерфейсов?

Ключевое слово interface используется для создания полностью абстрактных классов. Основное предназначение интерфейса - определять каким образом мы можем использовать класс, который его реализует. Создатель интерфейса определяет имена методов, списки аргументов и типы возвращаемых значений, но не реализует их поведение. Все методы неявно объявляются как public.

Начиная с Java 8 в интерфейсах разрешается размещать реализацию методов по умолчанию default и статических static методов.

Интерфейс также может содержать и поля. В этом случае они автоматически являются публичными public, статическими static и неизменяемыми final.

== Чем интерфейсы отличаются от абстрактных классов? В каких случаях следует использовать абстрактный класс, а в каких интерфейс?

* В Java класс может одновременно реализовать несколько интерфейсов, но наследоваться только от одного класса
* Абстрактные классы используются только тогда, когда присутствует тип отношений «is a» (является). Интерфейсы могут реализоваться классами, которые не связаны друг с другом
* Абстрактный класс - средство, позволяющее избежать написания повторяющегося кода, инструмент для частичной реализации поведения. Интерфейс - это средство выражения семантики класса, контракт, описывающий возможности
* Все методы интерфейса неявно объявляются как public abstract или (начиная с Java 8) default - методами с реализацией по-умолчанию, а поля - public static final
* Интерфейсы позволяют создавать структуры типов без иерархии
* Наследуясь от абстрактного, класс «растворяет» собственную индивидуальность. Реализуя интерфейс, он расширяет собственную функциональность

Абстрактные классы содержат частичную реализацию, которая дополняется или расширяется в подклассах. При этом все подклассы схожи между собой в части реализации, унаследованной от абстрактного класса, и отличаются лишь в части собственной реализации абстрактных методов родителя. Поэтому абстрактные классы применяются в случае построения иерархии однотипных, очень похожих друг на друга классов. В этом случае наследование от абстрактного класса, реализующего поведение объекта по умолчанию может быть полезно, так как позволяет избежать написания повторяющегося кода. Во всех остальных случаях лучше использовать интерфейсы.

== Как решается проблема ромбовидного наследования при наследовании интерфейсов при наличии default методов?

Если некий класс реализует несколько интерфейсов, которые имеют одинаковый метод по умолчанию, то класс должен реализовать метод с совпадающей сигнатурой самостоятельно. Ситуация аналогична, если один интерфейс имеет метод по умолчанию, а в другом этот же метод является абстрактным - никакой реализации по умолчанию классом не наследуется.

== Расскажите особенности default методов в интерфейсе и для чего они нужны?

* Метод по умолчанию не может переопределить метод класса java.lang.Object
* Помогают реализовывать интерфейсы без страха нарушить работу других классов
* Позволяют избежать создания служебных классов, так как все необходимые методы могут быть представлены в самих интерфейсах
* Дают свободу классам выбрать метод, который нужно переопределить
* Одной из основных причин внедрения методов по умолчанию является возможность коллекций в Java 8 использовать лямбда-выражения

== Каков порядок вызова конструкторов и блоков инициализации с учётом иерархии классов?

Сначала вызываются все статические блоки от первого предка до последнего наследника. Потом попарно вызываются динамический блок инициализации и конструктор в той же последовательности (от предка до последнего потомка).

Parent static block(s) → Child static  block(s) →

Grandchild static block(s) → Parent non-static block(s) → Parent  constructor →

→ Child non-static block(s) → Child  constructor →

→ Grandchild non-static block(s) →  Grandchild constructor

== Зачем нужны и какие бывают блоки инициализации?

Нестатические блоки инициализации (instance initializers) позволяют проводить инициализацию объектов вне зависимости от того, какой конструктор был вызван или, например, вести журналирование.

Блоки инициализации представляют собой код, заключенный в фигурные скобки и размещаемый внутри класса вне объявления методов или конструкторов.

* Существуют статические и нестатические блоки инициализации.
* Блок инициализации выполняется перед инициализацией класса загрузчиком классов или созданием объекта класса с помощью конструктора.
* Несколько блоков инициализации выполняются в порядке следования в коде класса.
* Блок инициализации способен генерировать исключения, если их объявления перечислены в throws всех конструкторов класса.
* Блок инициализации возможно создать и в анонимном классе.

== Для чего в Java используются статические блоки инициализации?

Статические блоки инициализация используются для выполнения кода, который должен выполняться один раз при инициализации класса загрузчиком классов, в момент, предшествующий созданию объектов этого класса при помощи конструктора. Такой блок (в отличие от нестатических, принадлежащих конкретном объекту класса) принадлежит только самому классу (объекту метакласса Class).

== Что произойдёт, если в блоке инициализации возникнет исключительная ситуация?

Для нестатических блоков инициализации, если выбрасывание исключения прописано явным образом требуется, чтобы объявления этих исключений были перечислены в throws всех конструкторов класса. Иначе будет ошибка компиляции. Для статического блока выбрасывание исключения в явном виде, приводит к ошибке компиляции.

В остальных случаях, взаимодействие с исключениями будет проходить так же, как и в любом другом месте. Класс не будет инициализирован, если ошибка происходит в статическом блоке и объект класса не будет создан, если ошибка возникает в нестатическом блоке.

== Какое исключение выбрасывается при возникновении ошибки в блоке инициализации класса?

Если возникшее исключение - наследник `RuntimeException`:

* для статических блоков инициализации будет выброшено `java.lang.ExceptionInInitializerError`;
* для нестатических будет проброшено исключение-источник.

Если возникшее исключение - наследник `Error`, то в обоих случаях будет выброшено `java.lang.Error`. Исключение: `java.lang.ThreadDeath` - смерть потока. В этом случае никакое исключение выброшено не будет.

== Каким образом реализованы методы `hashCode()` и `equals()` в классе `Object`?

Реализация метода Object.equals() сводится к проверке на равенство двух ссылок:

<i>public boolean equals(Object obj) {</i></div><i>
return (this == obj);</i></div><i>
}</i>

Реализация метода `Object.hashCode()` описана как `native`, т.е. определенной не с помощью Java кода и обычно возвращает адрес объекта в памяти:

<i>public native int hashCode();</i>

== Зачем нужен equals(). Чем он отличается от операции ==?

Метод equals() - определяет отношение эквивалентности объектов.

При сравнении объектов с помощью == сравнение происходит лишь между ссылками. При сравнении по переопределённому разработчиком equals() - по внутреннему состоянию объектов.

== Что будет, если переопределить equals() не переопределяя hashCode()? Какие могут возникнуть проблемы?

<i>- equals есть, hashCode </i>нет

C точки зрения метода equals два объекта будут логически равны, в то время как с точки зрения метода hashCode они не будут иметь ничего общего. И, таким образом, помещая некий объект в хэш-таблицу, мы рискуем не получить его обратно по ключу.

- <i>hashCode </i>есть, <i>equals </i>нет

Как известно метод equals по умолчанию просто сравнивает указатели на объекты, определяя, ссылаются ли они на один и тот же объект. Предположим, что метод hashCode мы сгенерировали средствами IDE, и он будет возвращать одинаковые хэш-значения для логически одинаковых объектов. Очевидно, что тем самым мы уже определили некоторый механизм сравнения двух объектов.

Мы по-прежнему не сможем найти наш объект в хэш-таблице. Хотя будем уже близки к этому, потому что как минимум найдем корзину хэш-таблицы, в которой объект будет лежать.

Для успешного поиска объекта в хэш-таблице помимо сравнения хэш-значений ключа используется также определение логического равенства ключа с искомым объектом. Т. е. без переопределения метода equals никак не получится обойтись.

== Какой контракт между hashCode() и equals()?

При переопределении метода `equals` разработчик должен придерживаться основных правил, определенных в спецификации языка Java.

* *Рефлексивность *- для любого заданного значения `x`, выражение `x.equals(x)` должно возвращать `true`.</li><em>Заданного</em> — имеется в виду такого, что `x != null`<li>*Симметричность *- для любых заданных значений `x` и `y`, `x.equals(y)` должно возвращать `true` только в том случае, когда `y.equals(x)` возвращает `true`.
* *Транзитивность *- для любых заданных значений `x`, `y` и `z`, если `x.equals(y)` возвращает `true` и `y.equals(z)` возвращает `true`, `x.equals(z)` должно вернуть значение `true`.
* *Согласованность *-* *для любых заданных значений `x` и `y` повторный вызов `x.equals(y)` будет возвращать значение предыдущего вызова этого метода при условии, что поля, используемые для сравнения этих двух объектов, не изменялись между вызовами.
* *Сравнение null *-* *для любого заданного значения `x` вызов `x.equals(null)` должен возвращать `false`.

<h3>Контракт hashCode</h3>Для реализации хэш-функции в спецификации языка определены следующие правила:

* вызов метода `hashCode` один и более раз над одним и тем же объектом должен возвращать одно и то же хэш-значение, при условии что поля объекта, участвующие в вычислении значения, не изменялись.
* вызов метода `hashCode` над двумя объектами должен всегда возвращать одно и то же число, если эти объекты равны (вызов метода `equals` для этих объектов возвращает `true`).
* вызов метода `hashCode` над двумя неравными между собой объектами должен возвращать разные хэш-значения. Хотя это требование и не является обязательным, следует учитывать, что его выполнение положительно повлияет на производительность работы хэш-таблиц.

== Для чего нужен метод `hashCode()`?

Метод `hashCode()` необходим для вычисления хэш кода переданного в качестве входного параметра объекта. В Java это целое число, в более широком смысле - битовая строка фиксированной длины, полученная из массива произвольной длины. Этот метод реализован таким образом, что для одного и того же входного объекта, хэш код всегда будет одинаковым.

Следует понимать, что в Java множество возможных хэш кодов ограничено типом int, а множество объектов ничем не ограничено. Из-за этого, вполне возможна ситуация, что хэш коды разных объектов могут совпасть:

* если хэш коды разные, то и объекты гарантированно разные;
* если хэш коды равны, то объекты могут не обязательно равны.

== Правила переопределения метода hashcode()?

При реализации hashCode используется несколько простых правил. Прежде всего, при вычислении хеш-кода следует использовать те же поля, которые сравниваются в equals. Это, во-первых, даст равенство хеш-кодов для равных объектов, во-вторых, распределено полученное значение будет точно так же, как и исходные данные. Теоретически, можно сделать так, чтобы хеш-код всегда был равен 0, и это будет абсолютно легальная реализация. Другое дело, что ее ценность будет равна тому же самому нулю.

== Есть ли какие-либо рекомендации о том, какие поля следует использовать при подсчете hashCode()?

Общий совет: выбирать поля, которые с большой долью вероятности будут различаться. Для этого необходимо использовать уникальные, лучше всего примитивные поля, например, такие как id, uuid. При этом нужно следовать правилу, если поля задействованы при вычислении hashCode(), то они должны быть задействованы и при выполнении equals().

== Почему нельзя реализовать hashcode() который будет гарантированно уникальным для каждого объекта?

Невозможность написания идеального алгоритма. И потому что hashcode() возвращает int, то есть, рано или поздно все инты могут закончиться.

== Чем a.getClass().equals(A.class) отличается от a instanceOf A.class?

* instanceof проверяет, является ли ссылка на объект с левой стороны (LHS) экземпляром типа с правой стороны (RHS) или каким-либо подтипом. Возвращает boolean
* getClass() == ... проверяет, идентичны ли типы. Возвращает класс

== Что такое исключения?

Исключение в Java — это объект, который описывает исключительное состояние, возникшее в каком-либо участке программного кода. Когда возникает исключительное состояние, создается объект класса `Exception`. Этот объект пересылается в метод, обрабатывающий данный тип исключительной ситуации. Исключения могут пробрасываться и «вручную» для того, чтобы сообщить о некоторых нештатных ситуациях.

== Опишите иерархию исключений

"<img src=""paste-3f0ef2d169d8fea22b7bc34b09a913907dc696e3.png"">"

== Расскажите про обрабатываемые и необрабатываемые исключения

* Checked исключения, это те, которые должны обрабатываться блоком catch или описываться в сигнатуре метода. Unchecked могут не обрабатываться и не быть описанными.
* Unchecked исключения в Java - наследованные от RuntimeException, checked - от Exception (не включая unchecked).

Пример unchecked исключения - NullPointerException, checked исключения - IOException

== Расскажите про механизм обработки исключений в java (Try-catch-finally)

<i>try{ </i>

//здесь код, который потенциально может привести к ошибке

<i>} catch(SomeException e) {</i>   //в скобках указывается класс конкретной ожидаемой ошибки

//здесь описываются действия, направленные на обработку исключений

<i>} finally{ </i>

//выполняется в любом случае ( блок finally  не обязателен)

<i>}</i>

== Возможно ли использование блока try-finally (без catch)?

`try` может быть в паре с `finally`, без `catch`. Работает это точно так же - после выхода из блока try выполняется блок finally. Это может быть полезно, например, в следующей ситуации. При выходе из метода вам надо произвести какое-либо действие. А return в этом методе стоит в нескольких местах. Писать одинаковый код перед каждым return нецелесообразно. Гораздо проще и эффективнее поместить основной код в try, а код, выполняемый при выходе - в finally.

== Может ли один блок catch отлавливать сразу несколько исключений?

В Java 7 стала доступна новая конструкция, с помощью которой можно перехватывать несколько исключений одним блоком catch:

<i>try {
...
} catch( IOException | SQLException ex ) {
...
}</i>

== Всегда ли исполняется блок finally? Существуют ли ситуации, когда блок finally не будет выполнен?

* Если вы вызываете System.exit();
* Если JVM выйдет из строя первым;
* Если JVM достигает бесконечного цикла (или другого не прерывающегося, не заканчивающегося оператора) в блоке try или catch;
* Если ОС принудительно завершает процесс JVM; например, kill -9 &lt;pid&gt; на UNIX.
* Если хост-система умирает; например, сбой питания, аппаратная ошибка и т.д.
* Если, наконец, блок будет выполняться потоком демона, а все остальные, не являющиеся демонами, выйдут до вызова finally

== Может ли метод `main()` выбросить исключение во вне и если да, то где будет происходить обработка данного исключения?

Может и оно будет передано в виртуальную машину Java (JVM).

== В каком порядке следует обрабатывать исключения в catch блоках?

Тут всегда нужно помнить одну особенность. При использовании множественных операторов catch обработчики подклассов исключений должные находиться выше, чем обработчики их суперклассов. Иначе, суперкласс будет перехватывать все исключения, имея большую область перехвата. Иными словами, `Exception` не должен находиться выше `ArithmeticException` и `ArrayIndexOutOfBoundsException`.

== Что такое механизм try-with-resources?

Она дает возможность объявлять один или несколько ресурсов в блоке try, которые будут закрыты автоматически без использования finally блока.

В качестве ресурса можно использовать любой объект, класс которого реализует интерфейс `java.lang.AutoCloseable` или `java.io.Closable`.

== Что произойдет если исключение будет выброшено из блока catch после чего другое исключение будет выброшено из блока finally?

Это плохая практика, потому что исключение из finally перекроет исключение из catch и потеряется исходная ошибка.

== Что такое дженерики?

Generics — это параметризованные типы. С их помощью можно объявлять классы, интерфейсы и методы, где тип данных указан в виде параметра. Обобщения добавили в язык безопасность типов. Самый простой пример - List&lt;String&gt; myList = new ArrayList&lt;&gt;();

== Для чего нужны дженерики?

Обобщения позволяют нам уйти от жесткого определения используемых типов.

== Что такое сырые типы (raw type)?

Raw type — это класс-дженерик, из которого удалили его тип.

Raw type — это использование универсального класса без указания аргумента(ОВ) типа для его параметризованного типа(ов), например, использование List вместо List&lt;String&gt; . Когда дженерики были введены в Java, несколько классов были обновлены для использования дженериков. Использование этого класса в качестве raw type (без указания аргумента типа) позволило унаследованному коду все еще компилироваться.

Raw types используются для обратной совместимости. Их использование в новом коде не рекомендуется, поскольку использование универсального класса с аргументом типа позволяет усилить типизацию, что, в свою очередь, может улучшить понятность кода и привести к более раннему обнаружению потенциальных проблем.

== Что такое вайлдкарды?

Wildcard — это дженерик вида &lt;?&gt;, что означает, что тип может быть чем угодно. Используется, например, в коллекциях, где для всех коллекций базовым типом является Сollection&lt;?&gt;.

Чтобы наложить ограничение на wildcard необходимо использовать конструкции типа:

? extends SomeClass — означает, что может быть использован любой класс-наследник SomeClass

? super SomeClass — означает, что может быть использован класс SomeClass, либо класс-родитель (или интерфейс) SomeClass

Это называется bounded wildcard.

Для того, чтобы определиться с выбором между extends и super был придуман принцип PECS.

== Расскажите про принцип PECS

Producer Extends Consumer Super

Если метод имеет аргументы с параметризованным типом (например, Collection или Predicate), то в случае, если аргумент - производитель (producer), нужно использовать ? extends T, а если аргумент - потребитель (consumer), нужно использовать ? super T.

Если метод читает данные из аргумента, то этот аргумент - производитель, а если метод передает данные в аргумент, то аргумент является потребителем.

Пример:

public static &lt;T&gt; T max(Collection&lt;? extends T&gt; coll, Comparator&lt;? super T&gt; comp)

Collections.max(List&lt;Integer&gt;, Comparator&lt;Number&gt;);

== Что такое «коллекция»?

Коллекция - это структура данных, основная цель которого – хранить набор других элементов.

== Расскажите про иерархию коллекций

"<img src=""paste-e54d1e3eb13428d640c4c32fc404b6fa82ace3a1.png"">"

== Почему Map — это не Collection, в то время как List и Set являются Collection?

Map реализовывает принцип «ключ — значение», в то время как List и Set - простые последовательные наборы элементов.

== В чем разница между классами java.util.Collection и java.util.Collections?

* java.util.Collections - набор статических методов для работы с коллекциями
* java.util.Collection - один из основных интерфейсов Java Collections Framework

== Какая разница между итераторами с fail-fast и fail-safe поведением? (С примерами)

Fail-fast поведение означает, что при возникновении ошибки или состояния, которое может привести к ошибке, система немедленно прекращает дальнейшую работу и уведомляет об этом. Использование fail-fast подхода позволяет избежать недетерминированного поведения программы в течение времени.

В Java Collections API некоторые итераторы ведут себя как fail-fast и выбрасывают ConcurrentModificationException, если после его создания была произведена модификация коллекции, т.е. добавлен или удален элемент напрямую из коллекции, а не используя методы итератора.

Реализация такого поведения осуществляется за счет подсчета количества модификаций коллекции (modification count):

* при изменении коллекции счетчик модификаций также изменяется;
* при создании итератора ему передается текущее значение счетчика;
* при каждом обращении к итератору сохраненное значение счетчика сравнивается с текущим, и, если они не совпадают, возникает исключение.

В противоположность fail-fast, итераторы fail-safe не вызывают никаких исключений при изменении структуры, потому что они работают с клоном коллекции вместо оригинала.

Итератор коллекции CopyOnWriteArrayList и итератор представления keySet коллекции ConcurrentHashMap являются примерами итераторов fail-safe.

== Чем различаются `Enumeration` и `Iterator`?

Хотя оба интерфейса и предназначены для обхода коллекций между ними имеются существенные различия:

* с помощью Enumeration нельзя добавлять/удалять элементы
* в Iterator исправлены имена методов для повышения читаемости кода (Enumeration.hasMoreElements() соответствует Iterator.hasNext(), Enumeration.nextElement() соответствует Iterator.next() и т.д)
* Enumeration присутствуют в устаревших классах, таких как Vector/Stack, тогда как Iterator есть во всех современных классах-коллекциях

== Как между собой связаны `Iterable`, `Iterator` и «for-each»?

Классы, реализующие интерфейс Iterable, могут применяться в конструкции for-each, которая использует Iterator.

== Можно ли итерируясь по ArrayList удалить элемент? Какое вылетит исключение?

Итератор ArrayList является fail-fast, то есть не поддерживает итерацию с параллельной модификацией. А параллельная модификация случается даже в одном потоке. Следующий шаг итератора после удаления элемента выбросит ConcurrentModificationException.

== Как поведёт себя коллекция, если вызвать iterator.remove()?

Единственный способ удалить элемент из коллекции при обходе, не получив при этом ConcurrentModificationException или неопределенное поведение – удалить с помощью remove() того же инстанса итератора.

== Чем Set отличается от List?

Оба унаследованы от Collection, а значит имеют одинаковый набор и сигнатуры методов. List хранит объекты в порядке вставки, элемент можно получить по индексу. Set не может хранить одинаковых элементов и не имеет порядка.

== Расскажите про интерфейс Set

"<img src=""paste-8b0b5338f64da3caf170f7222a739d6dcbfbb055.png"">

Интерфейс Set расширяет интерфейс Collection и представляет набор уникальных элементов. Set не добавляет новых методов, только вносит изменения унаследованные.

В коллекции этого типа разрешено наличие только одной ссылки типа null.

== Расскажите про реализации интерфейса `Set`

`HashSet` — реализация интерфейса Set, базирующаяся на `HashMap`. Внутри использует объект HashMap для хранения данных. В качестве ключа используется добавляемый элемент, а в качестве значения — объект-пустышка (new Object()). Из-за особенностей реализации порядок элементов не гарантируется при добавлении.

`LinkedHashSet` — отличается от HashSet только тем, что в основе лежит LinkedHashMap вместо HashMap. Благодаря этому отличию порядок элементов при обходе коллекции является идентичным порядку добавления элементов.

`TreeSet` — аналогично другим классам-реализациям интерфейса Set содержит в себе объект NavigableMap, что и обуславливает его поведение. Предоставляет возможность управлять порядком элементов в коллекции при помощи объекта Comparator, либо сохраняет элементы с использованием ""natural ordering"".

== В чем отличия `TreeSet` и `HashSet`?

`TreeSet` обеспечивает упорядоченное хранение элементов в виде красно-черного дерева. Сложность выполнения основных операций не хуже O(log(N)) (Логарифмическое время).

`HashSet` использует для хранения элементов такой же подход, что и HashMap, за тем отличием, что в HashSet в качестве ключа и значения выступает сам элемент, кроме того, HashSet не поддерживает упорядоченное хранение элементов и обеспечивает временную сложность выполнения операций аналогично HashMap.

== Чем `LinkedHashSet` отличается от `HashSet`?

`LinkedHashSet` отличается от HashSet только тем, что в его основе лежит `LinkedHashMap` вместо HashMap. Благодаря этому порядок элементов при обходе коллекции является идентичным порядку добавления элементов (insertion-order). При добавлении элемента, который уже присутствует в Linked`HashSet (т.е. с одинаковым ключом), порядок обхода элементов не изменяется.

== Что будет, если добавлять элементы в `TreeSet` по возрастанию?

В основе `TreeSet` лежит красно-черное дерево, которое умеет само себя балансировать. В итоге, `TreeSet` все равно в каком порядке вы добавляете в него элементы, преимущества этой структуры данных будут сохраняться.

== Как устроен HashSet, сложность основных операций.

"<img src=""clip_image002.gif"">

Класс HashSet реализует интерфейс Set, поддерживаемый хеш-таблицей, которая на самом деле является экземпляром HashMap. Не дается никаких гарантий относительно порядка итераций набора, что означает, что класс не гарантирует постоянный порядок элементов во времени. Этот класс допускает нулевой элемент. Класс также обеспечивает постоянную производительность по времени для основных операций, таких как сложение, удаление, удержание и размер, при условии, что хеш-функция правильно распределяет элементы между сегментами, что мы увидим далее в статье.

Несколько важных функций `HashSet`:

* Реализует Set Interface .
* Базовая структура данных для HashSet является хеш-таблицей.
* Поскольку он реализует интерфейс Set, повторяющиеся значения не допускаются.
* Объекты, которые вы вставляете в HashSet, не обязательно будут вставлены в том же порядке. Объекты вставляются на основе их хэш-кода.
* Элементы NULL разрешены в HashSet.
* `HashSet` также реализует интерфейсы `Serializable` и `Cloneable`.

Теперь для поддержания постоянной производительности по времени итерация по HashSet требует времени, пропорционального сумме размера экземпляра HashSet (количество элементов) плюс «емкость» резервного экземпляра HashMap (количество сегментов). Таким образом, очень важно не устанавливать слишком высокую начальную емкость (или слишком низкий коэффициент загрузки), если важна производительность итерации.

<i>Начальная емкость:</i> Начальная емкость означает число сегментов, когда создается хеш-таблица (HashSet внутренне использует структуру данных хеш-таблицы). Количество сегментов будет автоматически увеличено, если текущий размер заполнится.

<i>Коэффициент загрузки:</i> Коэффициент загрузки является мерой того, насколько полно HashSet может получить до того, как его емкость будет автоматически увеличена. Когда количество записей в хеш-таблице превышает произведение коэффициента загрузки и текущей емкости, хеш-таблица перефразируется (то есть внутренние структуры данных перестраиваются), так что хеш-таблица имеет приблизительно вдвое больше сегментов.

Пример: если внутренняя емкость равна 16, а коэффициент нагрузки равен 0,75, то количество сегментов автоматически увеличивается, если в таблице 12 элементов.

Внутренняя работа `HashSet`

Все классы интерфейса Set внутренне поддерживаются Map. HashSet использует HashMap для внутреннего хранения своего объекта. Вам должно быть интересно, что для ввода значения в HashMap нам нужна пара ключ-значение, но в HashSet мы передаем только одно значение.

Хранение в `HashMap`

На самом деле значение, которое мы вставляем в HashSet, действует как ключ к объекту карты, и для его значения java использует постоянную переменную. Таким образом, в паре ключ-значение все ключи будут иметь одинаковое значение.

Сложность времени операций HashSet: Базовая структура данных для HashSet является хеш-таблицей. Таким образом, амортизировать (в среднем или обычном случае) сложность времени для операций добавления, удаления и поиска (содержит метод) операции HashSet занимает O (1) времени.

== Как устроен LinkedHashSet, сложность основных операций

"<img src=""clip_image002.gif"">

LinkedHashSet — это упорядоченная версия HashSet, которая поддерживает двусвязный список для всех элементов. Когда необходимо поддерживать порядок итераций, используется этот класс.

* Содержит уникальные элементы, такие как HashSet . Он расширяет класс HashSet и реализует интерфейс Set.
* Поддерживает порядок вставки.

== Как устроен TreeSet, сложность основных операций

"<img src=""clip_image002.gif"">

TreeSet обеспечивает реализацию интерфейса SortedSet, а SortedSet расширяет интерфейс Set. Он ведет себя как простой набор, за исключением того, что он хранит элементы в отсортированном формате. Следующими являются функции TreeSet.

TreeSet использует древовидную структуру данных для хранения.

* Объекты хранятся в отсортированном порядке возрастания. Но мы можем выполнять итерацию в порядке убывания, используя метод TreeSet.descendingIterator ()
* Время доступа и поиска очень быстрое, что делает TreeSet отличным выбором для хранения большого объема данных в отсортированном формате
* TreeSet не использует методы hashCode () и equals () для сравнения своих элементов. Он использует метод compare () (или compareTo ()) для определения равенства двух элементов

== Расскажите про интерфейс List

List – это упорядоченный список. Объекты хранятся в порядке их добавления в список. Доступ к элементам списка осуществляется по индексу.

== Как устроен ArrayList, сложность основных операций

"<img src=""clip_image002-18a075a02332e9dc5c081810380c7dfd9c7829ee.gif"">

ВАЖНО! Вставка и удаление не включают в себя поиск элемента, поэтому у них сложность алгоритма O(1).

Класс ArrayList реализует интерфейс List и может менять свой размер во время исполнения программы, при этом не обязательно указывать размерность при создании объекта. Элементы ArrayList могут быть абсолютно любых типов в том числе и null.

== Как устроен LinkedList, сложность основных операций

"<img src=""clip_image002-18a075a02332e9dc5c081810380c7dfd9c7829ee.gif"">

ВАЖНО! Вставка и удаление не включают в себя поиск элемента, поэтому у них сложность алгоритма O(1).

LinkedList — класс, реализующий два интерфейса — List и Deque. Это обеспечивает возможность создания двунаправленной очереди из любых (в том числе и null) элементов. Каждый объект, помещенный в связанный список, является узлом (нодом). Каждый узел содержит элемент, ссылку на предыдущий и следующий узел. Фактически связанный список состоит из последовательности узлов, каждый из которых предназначен для хранения объекта определенного при создании типа.

== Почему `LinkedList` реализует и `List`, и `Deque`?

Это обеспечивает возможность создания двунаправленной очереди из любых (в том числе и null) элементов

== Чем отличаются `ArrayList` и `LinkedList`?

`ArrayList` это список, реализованный на основе массива, а LinkedList — это классический двусвязный список, основанный на объектах с ссылками между ними.

`ArrayList`:

* доступ к произвольному элементу по индексу за константное время O(1);
* доступ к элементам по значению за линейное время O(N);
* вставка в конец в среднем производится за константное время O(1);
* удаление произвольного элемента из списка занимает значительное время т.к. при этом все элементы, находящиеся «правее» смещаются на одну ячейку влево (реальный размер массива (capacity) не изменяется);
* вставка элемента в произвольное место списка занимает значительное время т.к. при этом все элементы, находящиеся «правее» смещаются на одну ячейку вправо;
* минимум накладных расходов при хранении.

`LinkedList`:

* на получение элемента по индексу или значению потребуется линейное время O(N);
* на добавление и удаление в начало или конец списка потребуется константное O(1);
* вставка или удаление в/из произвольного место константное O(1);
* требует больше памяти для хранения такого же количества элементов, потому что кроме самого элемента хранятся еще указатели на следующий и предыдущий элементы списка.

В целом, `LinkedList` в абсолютных величинах проигрывает `ArrayList` и по потребляемой памяти, и по скорости выполнения операций. `LinkedList` предпочтительно применять, когда нужны частые операции вставки/удаления или в случаях, когда необходимо гарантированное время добавления элемента в список.

== Что такое Queue?

Обобщенный интерфейс `Queue`&lt;E&gt; расширяет базовый интерфейс Collection и определяет поведение класса в качестве однонаправленной очереди.

== Что такое Deque? Чем отличается от Queue?

Интерфейс Deque расширяет интерфейс Queue и определяет поведение двунаправленной очереди, которая работает как обычная однонаправленная очередь, либо как стек, действующий по принципу LIFO (последний вошел - первый вышел).

== Какая коллекция реализует FIFO?

*FIFO*, *First-In-First-Out* («первым пришел-первым ушел») - по этому принципу построена коллекция `Queue`.

== Какая коллекция реализует LIFO?

*FILO*, *First-In-Last-Out* («первым пришел, последним ушел») - по этому принципу построена коллекция `Stack`, `ArrayDeque`.

== Оцените количество памяти на хранение одного примитива типа byte в LinkedList?

Каждый элемент `LinkedList` хранит ссылку на предыдущий элемент, следующий элемент и ссылку на данные.

<i>private static class Node&lt;E&gt; {
 E item;
 Node&lt;E&gt; next;
 Node&lt;E&gt; prev;
//...
}</i>

Для 32-битных систем каждая ссылка занимает 32 бита (4 байта). Сам объект (заголовок) вложенного класса Node занимает 8 байт. 4 + 4 + 4 + 8 = 20 байт, а т.к. размер каждого объекта в Java кратен 8, соответственно получаем 24 байта. Примитив типа byte занимает 1 байт памяти, но в JCF примитивы упаковываются: объект типа Byte занимает в памяти 16 байт (8 байт на заголовок объекта, 1 байт на поле типа byte и 7 байт для кратности 8). Также напомню, что значения от -128 до 127 кэшируются и для них новые объекты каждый раз не создаются. Таким образом, в x32 JVM 24 байта тратятся на хранение одного элемента в списке и 16 байт - на хранение упакованного объекта типа Byte. Итого 40 байт.

Для 64-битной JVM каждая ссылка занимает 64 бита (8 байт), размер заголовка каждого объекта составляет 16 байт (два машинных слова). Вычисления аналогичны: 8 + 8 + 8 + 16 = 40 байт и 24 байта. Итого 64 байта.

== Оцените количество памяти на хранение одного примитива типа byte в ArrayList?

ArrayList основан на массиве, для примитивных типов данных осуществляется автоматическая упаковка значения, поэтому 16 байт тратится на хранение упакованного объекта и 4 байта (8 для x64) - на хранение ссылки на этот объект в самой структуре данных. Таким образом, в x32 JVM 4 байта используются на хранение одного элемента и 16 байт - на хранение упакованного объекта типа Byte. Для x64 - 8 байт и 24 байта соответственно.

== Какие существуют реализации `Map`?

* `HashMap`
* `TreeMap`
* `LinkedHashMap`
* `WeakHashMap`

== Как устроена `HashMap`, сложность основных операций? (Расскажите про принцип корзин)

"<img src=""paste-bdee2b64aaf86ecd6d5a4c4ce85f29a980441403.png"">

HashMap состоит из «корзин» (bucket). С технической точки зрения «корзины» — это элементы массива, которые хранят ссылки на списки элементов. При добавлении

новой пары «ключ-значение», вычисляет хэш-код ключа, на основании которого вычисляется номер корзины (номер ячейки массива), в которую попадет новый элемент.

Если корзина пустая, то в нее сохраняется ссылка на вновь добавляемый элемент, если же там уже есть элемент, то происходит последовательный переход по ссылкам между элементами в цепочке, в поисках последнего элемента, от которого и ставится ссылка на вновь добавленный элемент. Если в списке был найден элемент с таким же ключом, то он заменяется.

== Что такое `LinkedHashMap`?

`LinkedHashMap` — хранит ключи в порядке их вставки в мапу. Работает немного медленнее чем HashMap.

== Как устроена `TreeMap`, сложность основных операций?

"<img src=""paste-bdee2b64aaf86ecd6d5a4c4ce85f29a980441403.png"">

`TreeMap` — хранит ключи в отсортированном порядке. Работает медленнее чем хэшмап.

== `Iterator` vs `ListIterator`

* `ListIterator` расширяет интерфейс `Iterator`
* `ListIterator` может быть использован только для перебора элементов коллекции `List`;
* `Iterator` позволяет перебирать элементы только в одном направлении, при помощи метода `next()`. Тогда как `ListIterator` позволяет перебирать список в обоих направлениях, при помощи методов `next()` и `previous()`;
* `ListIterator` не указывает на конкретный элемент: его текущая позиция располагается между элементами, которые возвращают методы `previous()` и `next()`.
* При помощи `ListIterator` вы можете модифицировать список, добавляя/удаляя элементы с помощью методов `add()` и `remove()`. Iterator не поддерживает данного функционала.

== Что такое WeakHashMap?

`WeakHashMap` - это структура данных, реализующая интерфейс `Map` и основанная на использовании WeakReference для хранения ключей. Таким образом, пара «ключ-значение» будет удалена из `WeakHashMap`, если на объект-ключ более не имеется сильных ссылок.

== Как работает HashMap при попытке сохранить в него два элемента по ключам с одинаковым hashCode(), но для которых equals() == false?

По значению hashCode вычисляется индекс ячейки массива, в список которой будет происходить добавление элемента. Перед добавлением осуществляется проверка на наличие уже элементов в этой ячейке. Если элементов нет, то происходит добавление. Если возникает коллизия, то итеративно осуществляется обход списка в поисках элемента с таким же ключом и хэш-кодом. Если такой элемент найден, то его значение перезаписывается, а старое - возвращается. Поскольку в условии сказано, что добавляемые ключи - разные, то второй элемент будет добавлен в начало списка.

== Что будет, если мы кладем в HashMap ключ, у которого equals и hashCode определены некорректно?

Объект неправильно рассчитает hash и попадет в случайную корзину.

== Возможна ли ситуация, когда HashMap выродится в список даже с ключами имеющими разные hashCode()?

Это возможно в случае, если метод, определяющий номер ячейки массива по hashCode будет возвращать одинаковое значение.

== Почему нельзя использовать byte[] в качестве ключа в HashMap?

Хэш-код массива не зависит от хранимых в нем элементов, а присваивается при создании массива (метод вычисления хэш-кода массива не переопределен и вычисляется по стандартному Object.hashCode() на основании адреса массива). Также у массивов не переопределен equals и выполняется сравнение указателей. Это приводит к тому, что обратиться к сохраненному с ключом-массивом элементу не получится при использовании другого массива такого же размера и с такими же элементами, доступ можно осуществить лишь в одном случае — при использовании той же самой ссылки на массив, что использовалась для сохранения элемента.

== Будет ли работать HashMap, если все добавляемые ключи будут иметь одинаковый hashCode()?

Да, будет, но в этом случае HashMap вырождается в связный список и теряет свои преимущества.

== Какое худшее время работы метода get(key) для ключа, которого нет в HashMap?

O(N). Худший случай - это поиск ключа в таблице, вырожденной в список, перебор ключей которой занимает линейно пропорциональное время количеству хранимых элементов.

== Какое худшее время работы метода get(key) для ключа, который есть в HashMap?

O(N). Аналогичные рассуждения, что и для предыдущего вопроса.

== Что такое функциональный интерфейс?

Функциональный интерфейс в Java – это интерфейс, который содержит только 1 абстрактный метод, однако, методов по умолчанию (default) такой интерфейс может содержать сколько угодно. Основное назначение – использование в лямбда выражениях и method reference.

== Для чего нужна аннотация @FunctionalInterface?

Это позволит использовать интерфейс в лямбда выражениях, не остерегаясь того, что кто-то добавит в интерфейс новый абстрактный метод и он перестанет быть функциональным.</div> <div style=""text-align: justify; "">Предназначение аннотации — сообщить компилятору, что данный интерфейс функциональный и должен содержать не более одного абстрактного метода.</div> <div style=""text-align: justify; "">Это не обязательное условие, так как JVM считает функциональным любой интерфейс с одним абстрактным методом.

== Какие встроенные функциональные интерфейсы вы знаете?

Они размещены в пакете java.util.function.

Наиболее часто используются:

* Consumer&lt;T&gt; - интерфейс, с помощью которого реализуется функция, которая получает на вход экземпляр класса T, производит с ним некоторое действие и ничего не возвращает:

//</div><i><i>    </i>Consumer&lt;String&gt; hello = (name) -&gt; System.out.println(""Hello, "" + name);</div></i><i><i>    </i>hello.accept(""world"");</div></i>//
* Function&lt;T,R&gt; - интерфейс, с помощью которого реализуется функция, получающая на вход экземпляр класса T и возвращающая на выходе экземпляр класса R:

//</div><i><i>    Function&lt;String, Integer&gt; toInteger = Integer::valueOf;
    Function&lt;String, String&gt; backToString = toInteger.andThen(String::valueOf);
    backToString.apply(""123""); // ""123""</i></div></i>//





Predicate&lt;T&gt; - интерфейс, с помощью которого реализуется функция, получающая на вход экземпляр класса T и возвращающая на выходе значение типа boolean.

Интерфейс содержит различные методы по умолчанию, позволяющие строить сложные условия (and, or, negate):

//</div><i><i>    Predicate&lt;String&gt; predicate = (s) -&gt; s.length() &gt; 0;
    predicate.test(""foo""); // true </i><i>- это как return ""foo"".length() &gt; 0</i></div></i><i><i>    predicate.negate().test(""foo""); // false - это как return *!*""foo"".length() &gt; 0</i></div></i>//

* Supplier&lt;T&gt; - интерфейс, с помощью которого реализуется функция, ничего не принимающая на вход, но возвращающая на выход результат класса T:

//</div><i><i>    </i>Supplier&lt;LocalDateTime&gt; now = LocalDateTime::now;</div></i><i><i>    </i>now.get();</div></i>//

* UnaryOperator&lt;T&gt; - (унарный оператор) принимает в качестве параметра объект типа T, выполняет над ними операции и возвращает результат операций в виде объекта типа T:

//

<i>    UnaryOperator&lt;Integer&gt; operator = x -&gt; x * x;</i></div><i><i>    System.out.println(operator.apply(5)); // 25</i></div></i></div><div style=""text-align: justify; "">//</div><div style=""text-align: justify; "">

</div><div style=""text-align: justify; "">BinaryOperator&lt;T&gt; - BinaryOperator&lt;T&gt; (бинарный оператор) - интерфейс, с помощью которого реализуется функция, получающая на вход два экземпляра класса T и возвращающая на выходе экземпляр класса T:</div><div style=""text-align: justify; "">//</div><i><i>    BinaryOperator&lt;Integer&gt; operator = (a, b) -&gt; a + b;
    System.out.println(operator.apply(1, 2)); // 3</i></div></i>//

*И ИХ BI ВЕРСИИ (BiFunction и т.д.)*

== Что такое ссылка на метод?

Ссылка на метод – это сокращенный синтаксис выражения лямбда, который выполняет только один метод.

Если существующий в классе метод уже делает все, что необходимо, то можно воспользоваться механизмом method reference (ссылка на метод) для непосредственной передачи этого метода. Такая ссылка передается в виде:

* имя_класса::имя_статического_метода для статического метода
* объект_класса::имя_метода для метода экземпляра
* название_класса::new для конструктора

Результат будет в точности таким же, как в случае определения лямбда-выражения, которое вызывает этот метод.

<i>


private interface Measurable {

 public int length(String string);

}

public static void main(String[] args) {</i><i>

 </i><i>Measurable a = String::length;</i><i>

 </i><i>System.out.println(a.length(""abc""));

}</i>



<i>

</i>

Виды ссылок на методы:

* на статический метод
* на метод экземпляра
* на конструктор

== Что такое лямбда-выражение? Чем его можно заменить?

Лямбда представляет собой набор инструкций, которые можно выделить в отдельную переменную и затем многократно вызвать в различных местах программы.

Основу лямбда-выражения составляет лямбда-оператор, который представляет стрелку  *-&gt;*. Этот оператор разделяет лямбда-выражение на две части: левая часть содержит список параметров выражения, а правая собственно представляет тело лямбда-выражения, где выполняются все действия.

Лямбда-выражение или просто лямбда в Java — упрощённая запись анонимного класса, реализующего функциональный интерфейс.

Лямбда-выражения, по сути, это анонимный класс или метод. Лямбда-выражение не выполняется само по себе. Вместо этого, оно используется для реализации метода, определенного в функциональном интерфейсе.

Как уже было написано, лямбда-выражения могут заменить анонимные классы, которые реализуют функциональные интерфейсы, но в остальных случаях анонимные классы не теряют актуальности.

Если одно и то же лямбда-выражение (или анонимный класс) используется в нескольких случаях, то появляется смысл сделать его членом класса или объекта, или и вовсе написать полноценный класс, реализующий необходимый интерфейс.

Но в большинстве случаев, там, где можно применять лямбда-выражения, например, в Stream, Optional или CompletableFuture, логичнее применять именно лямбды.

Лямбды имеют доступ к переменным внешней области действия из лямбда-выражения очень схож к доступу из анонимных объектов. Можно ссылаться на:

* неизменяемые (effectively final - не обязательно помеченные как final) локальные переменные;
* поля класса;
* статические переменные.

</div>   <div style=""text-align: justify; "">К методам по умолчанию реализуемого функционального интерфейса обращаться внутри лямбда-выражения запрещено.

== Что такое Stream API? Для чего нужны стримы?

Stream API — это новый способ работать со структурами данных в функциональном стиле. Stream (поток) API — это по своей сути поток данных.

Java Stream API был создан для того, чтобы помочь пользователям ускорить и упростить обработку данных. Сам по себе API предоставляет инструмент, который позволяет нам дать рецепт того как обрабатывать объекты.

Операции над стримами бывают или промежуточными (intermediate) или конечными (terminal). Конечные операции возвращают результат определенного типа, а промежуточные операции возвращают тот же стрим. Таким образом вы можете строить цепочки из несколько операций над одним и тем же стримом.

У стрима может быть сколько угодно вызовов промежуточных операций и последним вызов конечной операции. При этом все промежуточные операции выполняются лениво и пока не будет вызвана конечная операция никаких действий на самом деле не происходит (похоже на создание объекта Thread или Runnable, без вызова start()).

Операции над стримами могут выполняться как последовательно, так и параллельно.

Кроме универсальных объектных существуют особые виды стримов для работы с примитивными типами данных int, long и double: IntStream, LongStream и DoubleStream. Эти примитивные стримы работают так же, как и обычные объектные, но со следующими отличиями:

используют специализированные лямбда-выражения, например IntFunction или IntPredicate вместо Function и Predicate;</div> <div style=""text-align: justify; "">поддерживают дополнительные конечные операции sum(), average(), mapToObj().

== Почему Stream называют ленивым?

Потому что стрим не начнет работать, пока не выполнится терминальная операция.</div>

== Какие существуют способы создания стрима?

"<img src=""Снимок экрана (606).png"">"

== Какие промежуточные методы в стримах вы знаете?

* filter(Predicate predicate)
* map(Function mapper)
* flatMap(Function&lt;T, Stream&lt;R&gt;&gt; mapper)
* limit(long maxSize)
* skip(long n)
* sorted()
* sorted(Comparator comparator)
* distinct()
* peek(Consumer action)
* takeWhile(Predicate predicate) - возвращает элементы до тех пор, пока они удовлетворяют условию, то есть функция-предикат возвращает true. Это как limit, только не с числом, а с условием
* dropWhile(Predicate predicate) - пропускает элементы до тех пор, пока они удовлетворяют условию, затем возвращает оставшуюся часть стрима. Если предикат вернул для первого элемента false, то ни единого элемента не будет пропущено. Оператор подобен skip, только работает по условию
*  boxed() - преобразует примитивный стрим в объектный

== Расскажите про метод peek()

Возвращает тот же стрим, но применяет функцию к каждому элементу стрима.

Пример:

<i>collection.stream()</i></div><i>
 .map(String::toUpperCase)</i></div><i>
 .peek((e) -&gt; System.out.print("","" + e))</i></div><i>
 .collect(Collectors.toList());</i>

== Расскажите про метод map()

Метод map() является промежуточной операцией, которая заданным образом преобразует каждый элемент стрима.

Пример:</div><i>
collection.stream()</i></div><i>
 .map((s) -&gt; s + ""_1"") // к каждой стркое в стриме прибавляется ""_1""
 </i><i>.collect(Collectors.toList());</i>

== Расскажите про метод flatMap()

Похоже на map, но может создавать из одного элемента несколько.

Пример: </div><i>
1) collection.stream()</i></div><i>
 .flatMap((p) -&gt; Arrays.asList(p.split("","")) // из строки ""1,2,3,4,5"" делает массив [""1"",""2"",""3"",""4"",""5""]
 .stream())
 .toArray(String[]::new);
2) Stream</i></div><i> </i><i>.of(""H e l l o"", ""w o r l d !"")

</i><i> </i><i>.flatMap((p) -&gt; Arrays.stream(p.split("" ""))) </i><i>// [""H"", ""e"", ""l"", ""l"", ""o"", ""w"", ""o"", ""r"", ""l"", ""d"", ""!""]</i><i>

</i><i> </i><i>.toArray(String[]::new); </i>"

== Расскажите про метод filter()

Метод filter() является промежуточной операцией принимающей предикат, который фильтрует все элементы, возвращая только те, что соответствуют условию.

Пример:

<i>collection.stream()</i></div><i>
 .filter(«a1»::equals) // ссылка на метод equals класс String</i></div><i>
 .count();</i>

== Расскажите про метод limit()

Метод limit() является промежуточной операцией, которая позволяет ограничить выборку определенным количеством первых элементов.

Пример:

collection.stream()

 .limit(2)

 .collect(Collectors.toList());

== Расскажите про метод skip()

Позволяет пропустить N первых элементов.

Пример:

<i>collection.stream()
 </i><i>.skip(collection.size() - 1)
 </i><i>.findFirst()</i></div><i>
 .orElse(«1»);</i>

== Расскажите про метод sorted()

Метод sorted() является промежуточной операцией, которая позволяет сортировать значения либо в натуральном порядке, либо задавая Comparator.

Порядок элементов в исходной коллекции остается нетронутым - sorted() всего лишь создает его отсортированное представление, по которому можно получить новый ArrayList.

Пример:

<i>collection.stream()
 </i><i>.sorted()</i></div><i>
 .collect(Collectors.toList());</i>

== Расскажите про метод distinct()

Возвращает стрим без дубликатов (для метода equals).

Пример:</div><i>
collection.stream()
 </i><i>.distinct()</i></div><i>
 .collect(Collectors.toList());</i>

== Какие терминальные методы в стримах вы знаете?

* void forEach(Consumer action) - выполняет указанное действие для каждого элемента стрима
* long count () - возвращает количество элементов стрима
* R collect(Collector collector) - один из самых мощных операторов Stream API. С его помощью можно собрать все элементы в список, множество или другую коллекцию, сгруппировать элементы по какому-нибудь критерию, объединить всё в строку и т.д.
* R collect(Supplier supplier, BiConsumer accumulator, BiConsumer combiner) - то же, что и collect (collector), только параметры разбиты для удобства. Если нужно быстро сделать какую-то операцию, нет нужды реализовывать интерфейс Collector, достаточно передать три лямбда-выражения.

Supplier должен поставлять новые объекты (контейнеры), например new ArrayList(), accumulator добавляет элемент в контейнер, combiner необходим для параллельных стримов и объединяет части стрима воедино.

Пример:

List&lt;String&gt; list = Stream.of(""a"", ""b"", ""c"", ""d"")

 .collect(ArrayList::new, ArrayList::add, ArrayList::addAll); // list: [""a"", ""b"", ""c"", ""d""]

* Object[] toArray() - возвращает нетипизированный массив с элементами стрима
* A[] toArray(IntFunction&lt;A[]&gt; generator) - аналогично, только возвращает типизированный массив
* T reduce(T identity, BinaryOperator accumulator) и U reduce(U identity, BiFunction accumulator, BinaryOperator combiner) - позволяет преобразовать все элементы стрима в один объект. Например, посчитать сумму всех элементов, либо найти минимальный элемент
* Optional reduce (BinaryOperator accumulator) - этот метод отличается тем, что у него нет начального объекта identity. В качестве него служит первый элемент стрима. Поскольку стрим может быть пустой и тогда identity объект не присвоится, то результатом функции служит Optional, позволяющий обработать и эту ситуацию, вернув Optional.empty()
* Optional min(Comparator comparator)
* Optional max(Comparator comparator) - поиск минимального/максимального элемента, основываясь на переданном компараторе. Внутри вызывается reduce
* Optional findAny() - возвращает первый попавшийся элемент стрима. В параллельных стримах это может быть действительно любой элемент, который лежал в разбитой части последовательности
* Optional findFirst() - гарантированно возвращает первый элемент стрима, даже если стрим параллельный

Если нужен любой элемент, то для параллельных стримов быстрее будет работать findAny()

* boolean allMatch(Predicate predicate) - возвращает true, если все элементы стрима удовлетворяют условию predicate. Если встречается какой-либо элемент, для которого результат вызова функции-предиката будет false, то оператор перестаёт просматривать элементы и возвращает false
* boolean anyMatch (Predicate predicate) - возвращает true, если хотя бы один элемент стрима удовлетворяет условию predicate
* boolean noneMatch (Predicate predicate) - возвращает true, если, пройдя все элементы стрима, ни один не удовлетворил условию predicate
* OptionalDouble average() - только для примитивных стримов. Возвращает среднее арифметическое всех элементов. Либо Optional.empty, если стрим пуст
* sum() - возвращает сумму элементов примитивного стрима
* IntSummaryStatistics summaryStatistics() - полезный метод примитивных стримов. Позволяет собрать статистику о числовой последовательности стрима, а именно: количество элементов, их сумму, среднее арифметическое, минимальный и максимальный элемент

== Расскажите про метод collect()

Представление результата в виде коллекций и других структур данных.

Пример:

</div><i>
collection.stream()</i></div><i>
  .filter((s) -&gt; s.contains(«1»))</i></div><i>
  .collect(Collectors.toList());</i></div>

== Расскажите про метод reduce()

Позволяет выполнять агрегатные функции над всей коллекцией и возвращать один результат.

Пример:

</div><i>
collection.stream()</i></div><i>
  .reduce((s1, s2) -&gt; s1 + s2) // в случае array листа Integer {1,2,3,4,5}, это работает так: 1 + 2 + 3 + 4 + 5 = 15</i></div><i>
  .orElse(0);</i>

== Расскажите про класс Collectors и его методы

Коллекторы, это специальные классы, использующиеся для преобразования стрима в другую структуру данных.

Например, в list:

<i>List&lt;Integer&gt; list = Stream.of(1,2,3).collect(Collectors.toList());</i></div><i> </i>

В Java 8 в классе Collectors реализовано несколько распространённых коллекторов:

* toList(), toCollection(), toSet() - представляют стрим в виде списка, коллекции или множества
* toConcurrentMap(), toMap() - позволяют преобразовать стрим в Map
* averagingInt(), averagingDouble(), averagingLong() - возвращают среднее значение
* summingInt(), summingDouble(), summingLong() - возвращает сумму
* summarizingInt(), summarizingDouble(), summarizingLong() - возвращают SummaryStatistics с разными агрегатными значениями
* partitioningBy() - разделяет коллекцию на две части по соответствию условию и возвращает их как Map&lt;Boolean, List&gt;
* joining() - склеивает элементы потока в одну строку
* groupingBy() - разделяет коллекцию на несколько частей и возвращает Map&lt;N, List&lt;T&gt;&gt;
* mapping() - дополнительные преобразования значений для сложных Collector-ов

Также существует возможность создания собственного коллектора через Collector.of():

<i>Collector&lt;String, List&lt;String&gt;, List&lt;String&gt;&gt; toList = Collector.of(</i>

  <i>ArrayList::new,</i>

  <i>List::add,</i>

  <i>(l1, l2) -&gt; { l1.addAll(l2); return l1; }</i></div><i>
);</i>

== Расскажите о параллельной обработке (параллельных стримах) в Java 8

Стримы могут быть последовательными и параллельными. Операции над последовательными стримами выполняются в одном потоке процессора, над параллельными — используя несколько потоков процессора. Параллельные стримы используют общий ForkJoinPool доступный через статический ForkJoinPool.commonPool() метод. При этом, если окружение не является многоядерным, то поток будет выполняться как последовательный. Фактически применение параллельных стримов сводится к тому, что данные в стримах будут разделены на части, каждая часть обрабатывается на отдельном ядре процессора, и в конце эти части соединяются, и над ними выполняются конечные операции.

Для создания параллельного потока из коллекции можно также использовать метод parallelStream() интерфейса Collection.

Чтобы сделать обычный последовательный стрим параллельным, надо вызвать у объекта Stream метод parallel(). Метод isParallel() позволяет узнать является ли стрим параллельным.

С помощью, методов parallel() и sequential() можно определять какие операции могут быть параллельными, а какие только последовательными. Также из любого последовательного стрима можно сделать параллельный и наоборот:

  <i>collection</i><i>.stream()</i>

  <i>.peek(...) // операция последовательна</i>

  <i>.parallel()</i>

  <i>.map(...) // операция может выполняться параллельно,</i>

  <i>.sequential()</i>

  <i>.reduce(...) // операция снова последовательна</i></div><i> </i>

Как правило, элементы передаются в стрим в том же порядке, в котором они определены в источнике данных. При работе с параллельными стримами система сохраняет порядок следования элементов. Исключение составляет метод forEach(), который может выводить элементы в произвольном порядке. И чтобы сохранить порядок следования, необходимо применять метод forEachOrdered().

Критерии, которые могут повлиять на производительность в параллельных стримах:

* Размер данных - чем больше данных, тем сложнее сначала разделять данные, а потом их соединять.
* Количество ядер процессора. Теоретически, чем больше ядер в компьютере, тем быстрее программа будет работать. Если на машине одно ядро, нет смысла применять параллельные потоки.
* Чем проще структура данных, с которой работает поток, тем быстрее будут происходить операции. Например, данные из ArrayList легко использовать, так как структура данной коллекции предполагает последовательность несвязанных данных. А вот коллекция типа LinkedList - не лучший вариант, так как в последовательном списке все элементы связаны с предыдущими/последующими. И такие данные трудно распараллелить.
* Над данными примитивных типов операции будут производиться быстрее, чем над объектами классов.

Крайне не рекомендуется использовать параллельные стримы для скольких-нибудь долгих операций (например, сетевых соединений), так как все параллельные стримы работают c одним ForkJoinPool, то такие долгие операции могут остановить работу всех параллельных стримов в JVM из-за отсутствия доступных потоков в пуле, т.е. параллельные стримы стоит использовать лишь для коротких операций, где счет идет на миллисекунды, но не для тех где счет может идти на секунды и минуты;

Сохранение порядка в параллельных стримах увеличивает издержки при выполнении и если порядок не важен, то имеется возможность отключить его сохранение и тем самым увеличить производительность, использовав промежуточную операцию unordered():

  <i>collection.parallelStream()</i></div><i>
  .sorted()</i></div><i>
  .unordered()</i></div><i>
  .collect(Collectors.toList());</i>

== Что такое IntStream и DoubleStream?

Кроме универсальных объектных существуют особые виды стримов для работы с примитивными типами данных int, long и double: IntStream, LongStream и DoubleStream. Эти примитивные стримы работают так же, как и обычные объектные, но со следующими отличиями:

* используют специализированные лямбда-выражения, например IntFunction или IntPredicate вместо Function и Predicate
* поддерживают дополнительные конечные операции sum(), average(), mapToObj()

== Какие нововведения появились в Java 8?

* Методы интерфейсов по умолчанию (default методы)
* Лямбда-выражения
* Функциональные интерфейсы
* Ссылки на методы и конструкторы
* Предикаты (predicate), Функции (function), Поставщики (suppliers), Потребители (consumers)
* Опциональные значения (класс Optional)
* Стримы
* LocalTime, LocalDate, LocalDateTime

== Какие новые классы для работы с датами появились в Java 8?

* LocalDate – неизменяемый класс, который представляет объекты Date в формате по умолчанию yyyy-MM-dd.
* LocalDateTime – представляет собой дату и время в формате по умолчанию: yyyy-MM-dd-HH-mm-ss.zzz.
* java.time.Instant – используется для работы с машиночитаемым форматом времени — он сохраняет дату и время в так называемый «unix timestamp (отметку времени)»
* ZonedDateTime - что-то связанное с часовым поясом, позже поискать поподробнее

== Расскажите про класс Optional

Опциональное значение Optional — это контейнер для объекта, который может содержать или не содержать значение null. Такая обёртка является удобным средством предотвращения NullPointerException, т.к. имеет некоторые функции высшего порядка, избавляющие от добавления повторяющихся if null/notNull проверок:

Методы:

* Optional.orElse - возвращает переданное значение, если Optional пустой
* Optional.orElseGet - возвращает переданное значение из лямда-выражение , если Optional пустой
* Optional.orElseThrow - бросает переданное исключение , если Optional пустой

== Что такое Nashorn?

Nashorn - это движок JavaScript, разрабатываемый на Java компанией Oracle. Призван дать возможность встраивать код JavaScript в приложения Java. В сравнении с Rhino, который поддерживается Mozilla Foundation, Nashorn обеспечивает от 2 до 10 раз более высокую производительность, так как он компилирует код и передает байт-код виртуальной машине Java непосредственно в памяти. Nashorn умеет компилировать код JavaScript и генерировать классы Java, которые загружаются специальным загрузчиком. Так же возможен вызов кода Java прямо из JavaScript.

== Что такое jjs?

Для движка Nashorn JAVA 8 представляет новый инструмент командной строки, jjs, для выполнения JavaScript-кодов на консоли.

== Какой класс появился в Java 8 для кодирования/декодирования данных?

Base64 - потокобезопасный класс, который реализует кодировщик и декодировщик данных, используя схему кодирования base64 согласно RFC 4648 и RFC 2045.

== Как создать Base64 кодировщик и декодировщик?

Base64 содержит 6 основных методов:

* getEncoder()/getDecoder() - возвращает кодировщик/декодировщик base64, соответствующий стандарту RFC 4648;
* getUrlEncoder()/getUrlDecoder() - возвращает URL-safe кодировщик/декодировщик base64, соответствующий стандарту RFC 4648;
* getMimeEncoder()/getMimeDecoder() - возвращает MIME кодировщик/декодировщик, соответствующий стандарту RFC 2045.

== Какие дополнительные методы для работы с ассоциативными массивами (maps) появились в Java 8?

* putIfAbsent() добавляет пару «ключ-значение», только если ключ отсутствовал.

Пример:

<i>  map.putIfAbsent(""a"", ""Aa"");</i>


* forEach() принимает функцию, которая производит операцию над каждым элементом.

Пример:

  map.forEach((k, v) -&gt; System.out.println(v));


* compute() создаёт или обновляет текущее значение на полученное в результате вычисления (возможно использовать ключ и текущее значение).

Пример:

  map.compute(""a"", (k, v) -&gt; String.valueOf(k).concat(v)); //[""a"", ""aAa""]


* computeIfPresent() если ключ существует, обновляет текущее значение на полученное в результате вычисления (возможно использовать ключ и текущее значение).

Пример:

  map.computeIfPresent(""a"", (k, v) -&gt; k.concat(v));


* computeIfAbsent() если ключ отсутствует, создаёт его со значением, которое вычисляется (возможно использовать ключ).

Пример:

  map.computeIfAbsent(""a"", k -&gt; ""A"".concat(k)); //[""a"",""Aa""]


* getOrDefault() в случае отсутствия ключа, возвращает переданное значение по-умолчанию.

Пример:

  map.getOrDefault(""a"", ""not found"");


* merge() принимает ключ, значение и функцию, которая объединяет передаваемое и текущее значения. Если под заданным ключем значение отсутствует, то записывает туда передаваемое значение.

Пример:

  map.merge(""a"", ""z"", (value, newValue) -&gt; value.concat(newValue)); //[""a"",""Aaz""]

== Что такое LocalDateTime?

java.time.LocalDateTime объединяет вместе LocaleDate и LocalTime, содержит дату и время в календарной системе ISO-8601 без привязки к часовому поясу. Время хранится с точностью до наносекунды. Содержит множество удобных методов, таких как plusMinutes, plusHours, isAfter, toSecondOfDay и т.д.

== Что такое ZonedDateTime?

java.time.ZonedDateTime — аналог java.util.Calendar, класс с самым полным объемом информации о временном контексте в календарной системе ISO-8601. Включает временную зону, поэтому все операции с временными сдвигами этот класс проводит с её учётом.

Не путать ZoneId и ZonedDateTime!

== Чем процесс отличается от потока?

Процесс (process) - это объект, который создается операционной системой, когда пользователь запускает приложение. Процессу выделяется отдельное адресное пространство, причем это пространство физически недоступно для других процессов. Процесс может работать с файлами или с каналами связи локальной или глобальной сети. Когда вы запускаете текстовый процессор или программу калькулятора, вы создаете новый процесс.

Поток. Для каждого процесса операционная система создает один главный поток (thread*-), который является потоком выполняющихся по очереди команд центрального процессора. При необходимости главный поток может создавать другие потоки, пользуясь для этого программным интерфейсом операционной системы.

Все потоки, созданные процессом, выполняются в адресном пространстве этого процесса и имеют доступ к ресурсам процесса. Однако поток одного процесса не имеет никакого доступа к ресурсам потока другого процесса, так как они работают в разных адресных пространствах. При необходимости организации взаимодействия между процессами или потоками, принадлежащими разным процессам, следует пользоваться системными средствами, специально предназначенными для этого.

Вариант 2:

Процесс это некоторая единица операционной системы, которой выделена память и другие ресурсы. Поток это единица исполнения кода. Поток имеет стэк - некоторую свою память для исполнения. Остальная память процесса - общая для всех его потоков. Потоки исполняются на ядрах процессора.</div> <div style=""text-align: justify; "">В некоторых OS разница между процессами и потоками сведена к минимуму.

== Чем Thread отличается от Runnable?

Когда нужно использовать Thread, а когда Runnable? (Ответ что тред - это класс, а ранбл интерфейс – считается не полным, нужно рассказать подробно)

Thread - это класс, некоторая надстройка над физическим потоком.

Runnable - это интерфейс, представляющий абстракцию над выполняемой задачей.

Есть два способа создать новый поток выполнения. Один из них - объявить класс подклассом Thread. Этот подкласс должен переопределить метод запуска класса Thread. Затем можно выделить и запустить экземпляр подкласса.

Другой способ создать поток - объявить класс, реализующий интерфейс Runnable. Затем этот класс реализует метод запуска. Затем можно выделить экземпляр класса, передать его в качестве аргумента при создании потока и запустить.

Помимо того, что Runnable помогает разрешить проблему множественного наследования, несомненный плюс от его использования состоит в том, что он позволяет логически отделить логику выполнения задачи от непосредственного управления потоком.

== Что такое монитор? Как монитор реализован в java?

*Монитор* – это специальный механизм (кусок кода) – надстройка над мютексом, который обеспечивает правильную работу с ним. Ведь мало пометить, что объект – занят, надо еще обеспечить, чтобы другие нити не пробовали воспользоваться занятым объектом.  В Java монитор реализован с помощью ключевого слова `synchronized`.  Когда мы пишем блок synchronized, то компилятор Java заменяет его тремя кусками кода:

* В начале блока `synchronized` добавляется код, который отмечает мютекс как занятый.
* В конце блока `synchronized` добавляется код, который отмечает мютекс как свободный.
* Перед блоком `synchronized` добавляется код, который смотрит, если мютекс занят – то нить должна ждать его освобождения.

== Что такое синхронизация? Какие способы синхронизации существуют в java?

Синхронизация - это процесс, который позволяет выполнять потоки параллельно.

В Java все объекты имеют одну блокировку, благодаря которой только один поток одновременно может получить доступ к критическому коду в объекте. Такая синхронизация помогает предотвратить повреждение состояния объекта. Если поток получил блокировку, ни один другой поток не может войти в синхронизированный код, пока блокировка не будет снята. Когда поток, владеющий блокировкой, выходит из синхронизированного кода, блокировка снимается. Теперь другой поток может получить блокировку объекта и выполнить синхронизированный код. Если поток пытается получить блокировку объекта, когда другой поток владеет блокировкой, поток переходит в состояние Блокировки до тех пор, пока блокировка не снимется.

Ниже приведены некоторые способы синхронизации в Java:

* Системная синхронизация с использованием wait()/notify().

Поток, который ждет выполнения каких-либо условий, вызывает у этого объекта метод wait(), предварительно захватив его монитор. На этом его работа приостанавливается. Другой поток может вызвать на этом же самом объекте метод notify() (опять же, предварительно захватив монитор объекта), в результате чего, ждущий на объекте поток ""просыпается"" и продолжает свое выполнение.

* Системная синхронизация с использованием join().

Метод join(), вызванный у экземпляра класса Thread, позволяет текущему потоку остановиться до того момента, как поток, связанный с этим экземпляром, закончит работу.

* Использование классов из пакета java.util.concurrent, который предоставляет набор классов для организации межпоточного взаимодействия. Примеры таких классов - Lock, семафор (Semaphore), etc. Концепция данного подхода заключается в использовании атомарных операций и переменных.


== Как работают методы wait(), notify() и notifyAll()?

Эти методы определены у класса Object и предназначены для взаимодействия потоков между собой при межпоточной синхронизации.

wait(): освобождает монитор и переводит вызывающий поток в состояние ожидания до тех пор, пока другой поток не вызовет метод notify()/notifyAll();

notify(): продолжает работу потока, у которого ранее был вызван метод wait();

notifyAll(): возобновляет работу всех потоков, у которых ранее был вызван метод wait().

Когда вызван метод wait(), поток освобождает блокировку на объекте и переходит из состояния Работающий (Running) в состояние Ожидания (Waiting). Метод notify() подаёт сигнал одному из потоков, ожидающих на объекте, чтобы перейти в состояние Работоспособный (Runnable). При этом невозможно определить, какой из ожидающих потоков должен стать работоспособным. Метод notifyAll() заставляет все ожидающие потоки для объекта вернуться в состояние Работоспособный (Runnable). Если ни один поток не находится в ожидании на методе wait(), то при вызове notify() или notifyAll() ничего не происходит.

Поток может вызвать методы wait() или notify() для определенного объекта, только если он в данный момент имеет блокировку на этот объект. wait(), notify() и notifyAll() должны вызываться только из синхронизированного кода.

== В каких состояниях может находиться поток?

Потоки могут находиться в одном из следующих состояний:

* Новый (New). После создания экземпляра потока, он находится в состоянии Новый до тех пор, пока не вызван метод start(). В этом состоянии поток не считается живым.
* Работоспособный (Runnable). Поток переходит в состояние Работоспособный, когда вызывается метод start(). Поток может перейти в это состояние также из состояния Работающий или из состояния Блокирован. Когда поток находится в этом состоянии, он считается живым.
* Работающий (Running). Поток переходит из состояния Работоспособный в состояние Работающий, когда Планировщик потоков выбирает его как работающий в данный момент.
* Живой, но не работоспособный (Alive, but not runnable). Поток может быть живым, но не работоспособным по нескольким причинам:

- Ожидание (Waiting). Поток переходит в состояние Ожидания, вызывая метод wait(). Вызов notify() или notifyAll() может перевести поток из состояния Ожидания в состояние Работоспособный.
- Сон (Sleeping). Метод sleep() переводит поток в состояние Сна на заданный промежуток времени в миллисекундах.
- Блокировка (Blocked). Поток может перейти в это состояние, в ожидании ресурса, такого как ввод/вывод или из-за блокировки другого объекта. В этом случае поток переходит в состояние
- Работоспособный, когда ресурс становится доступен.
- Мёртвый (Dead). Поток считается мёртвым, когда его метод run() полностью выполнен. Мёртвый поток не может перейти ни в какое другое состояние, даже если для него вызван метод start().

== Что такое семафор? Как он реализован в Java?

Semaphore – это новый тип синхронизатора: семафор со счётчиком, реализующий шаблон синхронизации Семафор. Доступ управляется с помощью счётчика: изначальное значение счетчика задается в конструкторе при создании синхронизатора, когда поток заходит в заданный блок кода, то значение счетчика уменьшается на единицу, когда поток его покидает, то увеличивается. Если значение счетчика равно нулю, то текущий поток блокируется, пока кто-нибудь не выйдет из защищаемого блока. Semaphore используется для защиты дорогих ресурсов, которые доступны в ограниченном количестве, например подключение к базе данных в пуле.

== Что обозначает ключевое слово volatile? Почему операции над volatile переменными не атомарны?

volatile - этот модификатор вынуждает потоки отключить оптимизацию доступа (кеширование переменных) и использовать единственный экземпляр переменной из общей памяти. Если переменная примитивного типа – этого будет достаточно для обеспечения потокобезопасности. Если же переменная является ссылкой на объект – синхронизировано будет исключительно значение этой ссылки. Все же данные, содержащиеся в объекте, синхронизированы не будут!

Если переменная объявлена как volatile, это означает, что ожидается ее изменение несколькими потоками. Естественно, вы думаете, что JRE наложит какие-то формы синхронизации для volatile переменных. Хорошо это или плохо, JRE неявно обеспечивает синхронизацию при доступе к volatile переменным, но с одной очень большой оговоркой: чтение volatile переменных синхронизировано и запись в volatile переменные синхронизирована, а неатомарные операции – нет.

Что означает, что следующий код не безопасен для потоков: <i>myVolatileVar++;</i></div>

== Для чего нужны Atomic типы данных? Чем отличаются от volatile?

Пакет java.util.concurrent.atomic содержит девять классов для выполнения атомарных операций. Операция называется атомарной, если ее можно безопасно выполнять при параллельных вычислениях в нескольких потоках, не используя при этом ни блокировок, ни синхронизацию synchronized.

Если переменная объявлена как volatile, это означает, что ожидается ее изменение несколькими потоками. Естественно, вы думаете, что JRE наложит какие-то формы синхронизации для volatile переменных. Хорошо это или плохо, JRE неявно обеспечивает синхронизацию при доступе к volatile переменным, но с одной очень большой оговоркой: чтение volatile переменных синхронизировано и запись в volatile переменные синхронизирована, а неатомарные операции – нет.

Что означает, что следующий код не безопасен для потоков: <i>myVolatileVar++;</i>

== Что такое потоки демоны? Для чего они нужны? Как создать поток-демон?

Потоки-демоны работают в фоновом режиме вместе с программой, но не являются неотъемлемой частью программы. Если какой-либо процесс может выполняться на фоне работы основных потоков выполнения и его деятельность заключается в обслуживании основных потоков приложения, то такой процесс может быть запущен как поток-демон с помощью метода setDaemon(boolean value), вызванного у потока до его запуска. Метод boolean isDaemon() позволяет определить, является ли указанный поток демоном или нет. Базовое свойство потоков-демонов заключается в возможности основного потока приложения завершить выполнение потока-демона (в отличие от обычных потоков) с окончанием кода метода main(), не обращая внимания на то, что поток-демон еще работает.

== Что такое приоритет потока? На что он влияет? Какой приоритет у потоков по умолчанию?

Каждому потоку исполнения в Java присваивается свой приоритет, который определяет поведение данного потока по отношению к другим потокам. Приоритеты потоков исполнения задаются целыми числами (обычно от 1 до 10), определяющими относительный приоритет одного потока над другими.

Приоритет потока исполнения используется для принятия решения при переходе от одного потока исполнения к другому. Это так называемое переключение контекста. Задается с помощью метода public final void setPriority(int newPriority).

По умолчанию приоритет потока 5.

Существуют следующие константы для определения приоритета потока:

* Thread.MIN_PRIORITY (1)
* Thread.NORM_PRIORITY (5)
* Thread.MAX_PRIORITY (10)

НЕ полагайтесь на приоритет потоков при проектировании многопоточных приложений! Скорее всего планировщик потоков будет использовать приоритеты при выборе следующего потока на выполнение, но это НЕ гарантируется.

== Как работает Thread.join()? Для чего он нужен?

Когда поток вызывает join() для другого потока, текущий работающий поток будет ждать, пока другой поток, к которому он присоединяется, не будет завершён:

* void join()
* void join(long millis)
* void join(long millis, int nanos)

== Чем отличаются методы yield () и sleep()?

Метод yield() служит причиной того, что поток переходит из состояния работающий (running) в состояние работоспособный (runnable), давая возможность другим потокам активизироваться. Но следующий выбранный для запуска поток может и не быть другим.

Метод sleep() вызывает засыпание текущего потока на заданное время, состояние изменяется с работающий (running) на ожидающий (waiting).

== Как правильно остановить поток? Для чего нужны методы .stop(), .interrupt(), .interrupted(), .isInterrupted().

На данный момент в Java принят уведомительный порядок остановки потока (хотя JDK 1.0 и имеет несколько управляющих выполнением потока методов, например stop(), suspend() и resume() - в следующих версиях JDK все они были помечены как deprecated из-за потенциальных угроз взаимной блокировки).

Для корректной остановки потока можно использовать метод класса Thread - interrupt(). Этот метод выставляет некоторый внутренний флаг-статус прерывания. В дальнейшем состояние этого флага можно проверить с помощью метода isInterrupted() или Thread.interrupted() (для текущего потока). Метод interrupt() также способен вывести поток из состояния ожидания или спячки. Т.е. если у потока были вызваны методы sleep() или wait() – текущее состояние прервется и будет выброшено исключение InterruptedException. Флаг в этом случае не выставляется.

Схема действия при этом получается следующей:q

* Реализовать поток.
* В потоке периодически проводить проверку статуса прерывания через вызов isInterrupted().
* Если состояние флага изменилось или было выброшено исключение во время ожидания/спячки, следовательно поток пытаются остановить извне.
* Принять решение – продолжить работу (если по каким-то причинам остановиться невозможно) или освободить заблокированные потоком ресурсы и закончить выполнение.

</div>    Возможная проблема, которая присутствует в этом подходе – блокировки на потоковом вводе-выводе. Если поток заблокирован на чтении данных - вызов interrupt() из этого состояния его не выведет. Решения тут различаются в зависимости от типа источника данных. Если чтение идет из файла – долговременная блокировка крайне маловероятна и тогда можно просто дождаться выхода из метода read(). Если же чтение каким-то образом связано с сетью – стоит использовать неблокирующий ввод-вывод из Java NIO.

Второй вариант реализации метода остановки (а также и приостановки) – сделать собственный аналог interrupt(). Т.е. объявить в классе потока флаги – на остановку и/или приостановку и выставлять их путем вызова заранее определённых методов извне. Методика действия при этом остаётся прежней – проверять установку флагов и принимать решения при их изменении. Недостатки такого подхода. Во-первых, потоки в состоянии ожидания таким способом не «оживить». Во-вторых, выставление флага одним потоком совсем не означает, что второй поток тут же его увидит. Для увеличения производительности виртуальная машина использует кеш данных потока, в результате чего обновление переменной у второго потока может произойти через неопределенный промежуток времени (хотя допустимым решением будет объявить переменную-флаг как volatile).

== Чем отличаются методы interrupt, interrupted, isInterrupted?

* Метод interrupt() – устанавливает флаг прерывания потока.
* Метод bool isInterrupted() – возвращает состояние флага прерывания и оставляет этот флаг нетронутым.
* Статический метод bool Thread.interrupted() – возвращает состояние флага и сбрасывает его.

== Чем Runnable отличается от Callable?

Интерфейс Runnable появился в Java 1.0, а интерфейс Callable был введен в Java 5.0 в составе библиотеки java.util.concurrent;

Классы, реализующие интерфейс Runnable для выполнения задачи должны реализовывать метод run(). Классы, реализующие интерфейс Callable - метод call();

Метод Runnable.run() не возвращает никакого значения, Callable.call() возвращает объект Future, который может содержать результат вычислений;</div> <div style=""text-align: justify; "">Метод run() не может выбрасывать проверяемые исключения, в то время как метод call() может.

== Что такое FutureTask?

FutureTask представляет собой отменяемое асинхронное вычисление в параллельном Java приложении. Этот класс предоставляет базовую реализацию Future, с методами для запуска и остановки вычисления, методами для запроса состояния вычисления и извлечения результатов. Результат может быть получен только когда вычисление завершено, метод получения будет заблокирован, если вычисление ещё не завершено. Объекты FutureTask могут быть использованы для обёртки объектов Callable и Runnable. Так как FutureTask реализует Runnable, его можно передать в Executor на выполнение.

== Что такое deadlock?

Взаимная блокировка (deadlock) - явление, при котором все потоки находятся в режиме ожидания. Происходит, когда достигаются состояния:</div>

* взаимного исключения - по крайней мере один ресурс занят в режиме неделимости и, следовательно, только один поток может использовать ресурс в любой данный момент времени.
* удержания и ожидания - поток удерживает как минимум один ресурс и запрашивает дополнительные ресурсы, которые удерживаются другими потоками.
* отсутствия предочистки - операционная система не переназначивает ресурсы: если они уже заняты, они должны отдаваться удерживающим потокам сразу же.
* цикличного ожидания - поток ждёт освобождения ресурса, другим потоком, который в свою очередь ждёт освобождения ресурса заблокированного первым потоком.

Простейший способ избежать взаимной блокировки – не допускать цикличного ожидания. Этого можно достичь, получая мониторы разделяемых ресурсов в определённом порядке и освобождая их в обратном порядке.

== Что такое livelock?

livelock – тип взаимной блокировки, при котором несколько потоков выполняют бесполезную работу, попадая в зацикленность при попытке получения каких-либо ресурсов. При этом их состояния постоянно изменяются в зависимости друг от друга. Фактической ошибки не возникает, но КПД системы падает до 0. Часто возникает в результате попыток предотвращения deadlock.

Реальный пример livelock, – когда два человека встречаются в узком коридоре и каждый, пытаясь быть вежливым, отходит в сторону, и так они бесконечно двигаются из стороны в сторону, абсолютно не продвигаясь в нужном им направлении.

== Что такое race condition?

Состояние гонки (race condition) - ошибка проектирования многопоточной системы или приложения, при которой эта работа напрямую зависит от того, в каком порядке выполняются потоки. Состояние гонки возникает, когда поток, который должен исполнится в начале, проиграл гонку и первым исполняется другой поток: поведение кода изменяется, из-за чего возникают недетерменированные ошибки.

Распространённые способы решения:

* Использование локальной копии — копирование разделяемой переменной в локальную переменную потока. Этот способ работает только тогда, когда переменная одна и копирование производится атомарно (за одну машинную команду), использование volatile.
* Синхронизация - операции над разделяемым ресурсом происходят в синхронизированном блоке (при использовании ключевого слова synchronized).
* Комбинирование методов - вышеперечисленные способы можно комбинировать, копируя «опасные» переменные в синхронизированном блоке. С одной стороны, это снимает ограничение на атомарность, с другой — позволяет избавиться от слишком больших синхронизированных блоков.
*  Очевидных способов выявления и исправления состояний гонки не существует. Лучший способ избавиться от гонок — правильное проектирование многозадачной системы.

== Что такое Фреймворк fork/join? Для чего он нужен?

Фреймворк Fork/Join, представленный в JDK 7, - это набор классов и интерфейсов позволяющих использовать преимущества многопроцессорной архитектуры современных компьютеров. Он разработан для выполнения задач, которые можно рекурсивно разбить на маленькие подзадачи, которые можно решать параллельно.

* Этап Fork: большая задача разделяется на несколько меньших подзадач, которые в свою очередь также разбиваются на меньшие. И так до тех пор, пока задача не становится тривиальной и решаемой последовательным способом.
* Этап Join: далее (опционально) идёт процесс «свёртки» - решения подзадач некоторым образом объединяются пока не получится решение всей задачи.

Решение всех подзадач (в т.ч. и само разбиение на подзадачи) происходит параллельно.

Для решения некоторых задач этап Join не требуется. Например, для параллельного QuickSort — массив рекурсивно делится на всё меньшие и меньшие диапазоны, пока не вырождается в тривиальный случай из 1 элемента. Хотя в некотором смысле Join будет необходим и тут, т.к. всё равно остаётся необходимость дождаться пока не закончится выполнение всех подзадач.

Ещё одно замечательное преимущество этого фреймворка заключается в том, что он использует work-stealing алгоритм: потоки, которые завершили выполнение собственных подзадач, могут «украсть» подзадачи у других потоков, которые всё ещё заняты.

== Что означает ключевое слово synchronized? Где и для чего может использоваться?

Synchronized (с англ. ""синхронизированный"") - это ключевое слово, которое позволяет заблокировать доступ к методу или части кода, если его уже использует другой поток.

Синхронизировать прикладной код можно двумя способами:

* С помощью синхронизированных методов. Метод объявляется с использованием ключевого слова synchronized:

<i>public synchronized void someMethod(){}</i>


* Заключить вызовы методов в блок оператора synchronized:

<i>synchronized(объект) {} </i>

Только методы и блоки могут быть синхронизированы, но не переменные и классы.

== Что является монитором у статического синхронизированного класса?

Для статического метода – объекта типа Class, соответствующий классу, в котором определен этот метод.

== Что является монитором у нестатического синхронизированного класса?

Для нестатического метода – текущий объект this.

== Stream API &amp; ForkJoinPool Как связаны, что это такое.

https://habr.com/ru/company/otus/blog/338770/

== Что такое DDL? Какие операции в него входят? Рассказать про них.

Data Definition Language (DDL) – это группа операторов определения данных. Другими словами, с помощью операторов, входящих в эту группы, мы определяем структуру базы данных и работаем с объектами (таблицами) этой базы, т.е. создаем, изменяем и удаляем их.

В эту группу входят следующие операторы:

* *CREATE *– используется для создания объектов базы данных
* *ALTER *– используется для изменения объектов базы данных
*  *DROP *– используется для удаления объектов базы данных
* *TRUNCATE *- операция мгновенного удаления всех строк в таблице. Логически схожа с операцией delete без оператора *WHERE*, но в ситуациях на практике имеет отличия
* *COMMENT*
* *RENAME*

== Что такое DML? Какие операции в него входят? Рассказать про них

Data Manipulation Language (DML) – это группа операторов для манипуляции данными. С помощью этих операторов мы можем добавлять, изменять, удалять и выгружать данные из базы, т.е. манипулировать ими.

В эту группу входят самые распространенные операторы языка SQL:

* *SELECT *– осуществляет выборку данных
* *INSERT* – добавляет новые данные
* *UPDATE *– изменяет существующие данные
*  *DELETE *– удаляет данные

Так же DML команды, но таких глубоких знаний от Java разраба требовать не будут (по идее), добавил их для общего понятия.</div>

* *MERGE *– оператор языка SQL, который позволяет слить данные одной таблицы с данными другой таблицы. При слиянии таблиц проверяется условие, и если оно истинно, то выполняется Update, а если нет - Insert. Причём нельзя изменять поля таблицы в секции Update, по которым идет связывание двух таблиц
* *CALL* – вызывает процедуру. Если у процедуры есть выходные параметры, возвращается строка результата, содержащая значения этих параметров
* *EXPLAIN PLAN*
* *LOCK TABLE *

== Что такое TCL? Какие операции в него входят? Рассказать про них

Transaction Control Language (TCL) – группа операторов для управления транзакциями. Транзакция – это команда или блок команд (инструкций), которые успешно завершаются как единое целое, при этом в базе данных все внесенные изменения фиксируются на постоянной основе или отменяются, т.е. все изменения, внесенные любой командой, входящей в транзакцию, будут отменены.

Группа операторов TCL предназначена как раз для реализации и управления транзакциями. Сюда можно отнести:

* BEGIN – служит для определения начала транзакции
* COMMIT – применяет транзакцию
* ROLLBACK – откатывает все изменения, сделанные в контексте текущей транзакции
* SAVEPOINT – устанавливает промежуточную точку сохранения внутри транзакции
* SET TRANSACTION – начинает транзакцию и устанавливает ее базовые характеристики

== Что такое DCL? Какие операции в него входят? Рассказать про них

Data Control Language (DCL) – группа операторов определения доступа к данным. Иными словами, это операторы для управления разрешениями, с помощью них мы можем разрешать или запрещать выполнение определенных операций над объектами базы данных.

Сюда входят:

* GRANT – предоставляет пользователю или группе разрешения на определённые операции с объектом
* REVOKE – отзывает выданные разрешения
* DENY– задаёт запрет, имеющий приоритет над разрешением

== Нюансы работы с NULL в SQL. Как проверить поле на NULL?

NULL - специальное значение (псевдозначение), которое может быть записано в поле таблицы базы данных. соответствует понятию «пустое поле», то есть «поле, не содержащее никакого значения».

NULL означает отсутствие, неизвестность информации. Значение не является значением в полном смысле слова: по определению оно означает отсутствие значения и не принадлежит ни одному типу данных. Поэтому не равно ни логическому значению FALSE, ни пустой строке, ни 0. При сравнении с любым значением будет получен результат NULL, а не false и не 0 Более того, не равно NULL!

Команды для проверки поля на null: IS NULL, IS NOT

== Виды Join’ов?

* (INNER) JOIN Результатом объединения таблиц являются записи, общие для левой и правой таблиц. Порядок таблиц для оператора не важен, поскольку оператор является симметричным
* LEFT (OUTER) JOIN Производит выбор всех записей первой таблицы и соответствующих им записей второй таблицы. Если записи во второй таблице не найдены, то вместо них подставляется пустой результат (NULL). Порядок таблиц для оператора важен, поскольку оператор не является симметричным
* RIGHT (OUTER) JOIN LEFT JOIN с операндами, расставленными в обратном порядке. Порядок таблиц для оператора важен, поскольку оператор не является симметричным
* FULL (OUTER) JOIN Результатом объединения таблиц являются все записи, которые присутствуют в таблицах. Порядок таблиц для оператора не важен, поскольку оператор является симметричным
* CROSS JOIN (декартово произведение) При выборе каждая строка одной таблицы объединяется с каждой строкой второй таблицы, давая тем самым все возможные сочетания строк двух таблиц. Порядок таблиц для оператора не важен, поскольку оператор является симметричным.

== Что лучше использовать join или вложенные запросы? Почему?

Обычно лучше использовать JOIN, поскольку в большинстве случаев он более понятен и лучше оптимизируется СУБД (но 100% этого гарантировать нельзя). Также JOIN имеет заметное преимущество над подзапросами в случае, когда список выбора SELECT содержит столбцы более чем из одной таблицы.

Подзапросы лучше использовать в случаях, когда нужно вычислять агрегатные значения и использовать их для сравнений во внешних запросах.

== Что делает UNION?

В языке SQL ключевое слово UNION применяется для объединения результатов двух SQL-запросов в единую таблицу, состоящую из схожих записей. Оба запроса должны возвращать одинаковое число столбцов и совместимые типы данных в соответствующих столбцах. Необходимо отметить, что UNION сам по себе не гарантирует порядок записей.

Записи из второго запроса могут оказаться в начале, в конце или вообще перемещаться с записями из первого запроса. В случаях, когда требуется определенный порядок, необходимо использовать ORDER BY.

== Чем WHERE отличается от HAVING? (ответа про то, что используются в разных частях запроса - недостаточно)

Оператор SQL HAVING аналогичен оператору SQL WHERE за тем исключением, что применяется не для всего набора столбцов таблицы, а для набора созданного оператором SQL GROUP BY и применяется всегда строго после него.

Основное отличие WHERE от HAVING заключается в том, что WHERE сначала выбирает строки, а затем группирует их и вычисляет агрегатные функции (таким образом, она отбирает строки для вычисления агрегатов), тогда как HAVING отбирает строки групп после группировки и вычисления агрегатных функций. Как следствие, предложение WHERE не должно содержать агрегатных функций; не имеет смысла использовать агрегатные функции для определения строк для вычисления агрегатных функций. Предложение HAVING, напротив, всегда содержит агрегатные функции. (Строго говоря, вы можете написать предложение HAVING, не используя агрегаты, но это редко бывает полезно. То же самое условие может работать более эффективно на стадии WHERE.)

WHERE - это ограничивающее выражение. Оно выполняется до того, как будет получен результат операции.

HAVING - фильтрующее выражение. Оно применяется к результату операции и выполняется уже после того как этот результат будет получен, в отличии от where.

Выражения WHERE используются вместе с операциями SELECT, UPDATE, DELETE, в то время как HAVING только с SELECT и предложением GROUP BY.

Например, WHERE нельзя использовать таким образом:

<i>SELECT name, SUM(salary) FROM Employees WHERE SUM(salary) &gt; 1000 GROUP BY name </i></div><i> </i>

В данном случае больше подходит HAVING:

<i>SELECT name, SUM(salary) FROM Employees GROUP BY name HAVING SUM(salary) &gt; 1000 </i></div><i> </i>

То есть, использовать WHERE в запросах с агрегатными функциями нельзя, для этого и был введен HAVING.

== Что такое ORDER BY?

ORDER BY упорядочивает вывод запроса согласно значениям в том или ином количестве выбранных столбцов. Многочисленные столбцы упорядочиваются один внутри другого. Возможно определять возрастание ASC или убывание DESC для каждого столбца. По умолчанию установлено - возрастание.

== Что такое GROUP BY?

Оператор SQL GROUP BY служит для распределения строк - результата запроса - по группам, в которых значения некоторого столбца, по которому происходит группировка, являются одинаковыми. Группировку можно производить как по одному столбцу, так и по нескольким.

Часто оператор SQL GROUP BY применяется вместе с агрегатными функциями (COUNT, SUM, AVG, MAX, MIN). В этих случаях агрегатные функции служат для вычисления соответствующего агрегатного значения ко всему набору строк, для которых некоторый столбец - общий.

== Что такое DISTINCT?

Оператор DISTINCT используется для указания на то, что следует работать только с уникальными значениями столбца.

== Что такое LIMIT?

LIMIT служит для извлечения диапазона строк из таблицы базы данных. В зависимости от того, как эта конструкция прописана в запросе, можно извлечь либо определённое число начальных строк, либо определённое число строк, следующих за пропущенными начальными строками.

 </div><i>
LIMIT 2 - // вывести первые 2 строки</i></div><i>
LIMIT 3, 2  - // пропустить первые 3 строки и вывести следующие за ними 2 строки</i>

Конструкция LIMIT располагается в конце запроса.

== Что такое EXISTS?

Предикат EXISTS выполняет логическую задачу. В запросах SQL этот предикат используется в выражениях вида: EXISTS (SELECT * FROM ИМЯ_ТАБЛИЦЫ...)

Это выражение возвращает истину, когда по запросу найдена одна или более строк, соответствующих условию, и ложь, когда не найдено ни одной строки.

Обычно предикат EXISTS применяется в случаях, когда необходимо найти значения, соответствующие основному условию, заданному в секции WHERE, и дополнительному условию, заключенному в подзапрос, являющийся аргументом предиката.

Для NOT EXISTS всё наоборот.

== Расскажите про операторы IN, BETWEEN, LIKE

Предикат IN в запросах на выборку данных применяется для извлечения из таблицы только тех строк, значения определенных столбцов в которых соответствуют набору значений, указываемых в скобках после IN.

<i>SELECT * FROM Persons WHERE name IN ('Ivan','Petr','Pavel');</i>

Запрос с конструкцией NOT IN извлечет строки, значения определенных столбцов в которых не соответствуют набору указанных значений.

С помощью предиката BETWEEN можно извлечь из таблицы строки, в которых значения некоторого проверяемого столбца находятся в интервале, границы которого обозначены некоторым выражением. Границы интервала также включены в него.

<i>

SELECT * FROM Persons WHERE age BETWEEN 20 AND 25;</i></div><i> </i>

Если перед предикатом BETWEEN поставить ключевое слово NOT, то в выборку попадут строки, в которых значение проверяемого столбца находится за пределами интервала: до 20 и после 25.

Предикат LIKE применим только к полям типа CHAR или VARCHAR, с которыми он используется чтобы находить подстроки. В качестве условия используются символы шаблонизации (wildcards) - специальные символы, которые могут соответствовать чему-нибудь:

* ""_"" замещает любой одиночный символ.

Например: 'b_t' будет соответствовать словам 'bat' или 'bit', но не будет соответствовать 'brat'.
* ""%"" замещает последовательность любого числа символов. Например '%p%t' будет соответствовать словам 'put', 'posit', или 'opt', но не 'spite'.

<i>SELECT * FROM UNIVERSITY WHERE NAME LIKE '%o';</i>

== Что делает оператор MERGE? Какие у него есть ограничения?

MERGE позволяет осуществить слияние данных одной таблицы с данными другойsql таблицы. При слиянии таблиц проверяется условие, и если оно истинно, то выполняется UPDATE, а если нет - INSERT.

При этом изменять поля таблицы в секции UPDATE, покоторым идет связывание двух таблиц, нельзя.

== Какие агрегатные функции вы знаете?

Агрегатные функции производят одиночное значение для всей группы таблицы.

* COUNT - производит номера строк или не-NULL значения полей которые выбрал запрос.
* SUM - производит арифметическую сумму всех выбранных значений данного пол.
* AVG - производит усреднение всех выбранных значений данного пол.
* MAX - производит наибольшее из всех выбранных значений данного пол.
* MIN - производит наименьшее из всех выбранных значений данного пол.

== Что такое ограничения (constraints)? Какие вы знаете?

Ограничения SQL — это правила, применяемые к столбцам данных таблицы. Они используются, чтобы ограничить типы данных, которые могут храниться в таблице. Это обеспечивает точность и надежность данных в базе данных.

Ограничения могут применяться либо на уровне столбцов, либо на уровне таблицы. Ограничения на уровне столбца применяются только к одному столбцу, тогда как ограничения уровне таблицы применяются ко всей таблице.

* NOT NULL — столбец не может иметь значение NULL
* DEFAULT — задает значение по умолчанию для столбца, если оно не указано
* UNIQUE — все значения в столбце должны быть разными
* PRIMARY Key — уникальная идентификация каждой строки/записи в таблице базы данных
* FOREIGN Key — уникально идентифицирует строку/запись в любой другой таблице базы данных
* CHECK — ограничение CHECK обеспечивает, чтобы все значения в столбце удовлетворяли определенным условиям
* INDEX — используется для быстрого создания данных базы данных

== Что такое суррогатные ключи?

Суррогатный Ключ (СК) – автоматически сгенерированное поле, никак не связанное с информационным содержанием записи. Обычно в роли СК выступает автоинкрементное поле типа INTEGER.

== Что такое индексы? Какие они бывают?

Индекс (index) — объект базы данных, создаваемый с целью повышения производительности выборки данных. Наборы данных могут иметь большое количество записей, которые хранятся в произвольном порядке, и их поиск по заданному критерию будет путем последовательного просмотра набора данных запись за записью может занимать много времени.

Индекс формируется из значений одного или нескольких полей и указателей на соответствующие записи набора данных, - таким образом, достигается значительный прирост скорости выборки из этих данных.

Преимущества

* ускорение поиска и сортировки по определенному полю или набору полей
* обеспечение уникальности данных

Недостатки

* требование дополнительного места на диске и в оперативной памяти и чем больше/длиннее ключ, тем больше размер индекса
* замедление операций вставки, обновления и удаления записей, поскольку при этом приходится обновлять сами индексы

Индексы предпочтительней для:

* Поля-счетчика, чтобы в том числе избежать и повторения значений в этом поле
* Поля, по которому проводится сортировка данных
* Полей, по которым часто проводится соединение наборов данных. Поскольку в этом случае данные располагаются в порядке возрастания индекса и соединение происходит значительно быстрее
* Поля, которое объявлено первичным ключом (primary key)

== Чем TRUNCATE отличается от DELETE?

DELETE - оператор DML, удаляет записи из таблицы, которые удовлетворяют критерию WHERE при этом задействуются триггеры, ограничения и т.д.

Можно сделать ROLLBACK.

TRUNCATE - DDL оператор (удаляет таблицу и создает ее заново. Причем если на эту таблицу есть ссылки FOREIGN KEY или таблица используется в репликации, то пересоздать такую таблицу не получится).

Нельзя сделать ROLLBACK.

== Что такое хранимые процедуры? Для чего они нужны?

Хранимая процедура — объект базы данных, представляющий собой набор SQL-инструкций, который хранится на сервере. Хранимые процедуры очень похожи на обыкновенные процедуры языков высокого уровня, у них могут быть входные и выходные параметры и локальные переменные, в них могут производиться числовые вычисления и операции над символьными данными, результаты которые могут присваиваться переменным и параметрам. В хранимых процедурах могут выполняться стандартные операции с базами данных (как DDL, так и DML). Кроме того, в хранимых процедурах возможны циклы и ветвления, то есть в них могут использоваться инструкции управления процессом исполнения.

Хранимые процедуры позволяют повысить производительность, расширяют возможности программирования и поддерживают функции безопасности данных. В большинстве СУБД при первом запуске хранимой процедуры она компилируется (выполняется синтаксический анализ и генерируется план доступа к данным) и в дальнейшем её обработка осуществляется быстрее.

Например, пусть в базе данных есть таблица, которая хранит данные о товарах:

`CREATE` `TABLE` `Products`

`(`

`    ``Id ``INT` `IDENTITY ``PRIMARY` `KEY``,`

`    ``ProductName NVARCHAR(30) ``NOT` `NULL``,`

`    ``Manufacturer NVARCHAR(20) ``NOT` `NULL``,`

`    ``ProductCount ``INT` `DEFAULT` `0,`

`    ``Price MONEY ``NOT` `NULL`

`);`</div>

Создадим хранимую процедуру для извлечения данных из этой таблицы:

`{`

`<span style=""font-family: Arial;"">    </span>USE productsdb;`

`<span style=""font-family: Arial;"">    </span>GO`

`<span style=""font-family: Arial;"">    </span>CREATE` `PROCEDURE` `ProductSummary ``AS`

`<span style=""font-family: Arial;"">    </span>SELECT` `ProductName ``AS` `Product, Manufacturer, Price`

`<span style=""font-family: Arial;"">    </span>FROM` `Products`

`};`</div>

== Что такое представления (VIEW)? Для чего они нужны?

Представление (VIEW) — объект базы данных, являющийся результатом выполнения запроса к базе данных, определенного с помощью оператора SELECT, в момент обращения к представлению.

Представления иногда называют «виртуальными таблицами». Такое название связано с тем, что представление доступно для пользователя как таблица, но само оно не содержит данных, а извлекает их из таблиц в момент обращения к нему. Если данные изменены в базовой таблице, то пользователь получит актуальные данные при обращении к представлению, использующему данную таблицу; кэширования результатов выборки из таблицы при работе представлений не производится. При этом, механизм кэширования запросов (query cache) работает на уровне запросов пользователя безотносительно к тому, обращается ли пользователь к таблицам или представлениям.

Представления могут основываться как на таблицах, так и на других представлениях, т.е. могут быть вложенными (до 32 уровней вложенности).

Например, пусть у нас есть три связанных таблицы:

</div>

`CREATE` `TABLE` `Products`

`(`

`    ``Id ``INT` `IDENTITY ``PRIMARY` `KEY``,`

`    ``ProductName NVARCHAR(30) ``NOT` `NULL``,`

`    ``Manufacturer NVARCHAR(20) ``NOT` `NULL``,`

`    ``ProductCount ``INT` `DEFAULT` `0,`

`    ``Price MONEY ``NOT` `NULL`

`);`

`CREATE` `TABLE` `Customers`

`(`

`    ``Id ``INT` `IDENTITY ``PRIMARY` `KEY``,`

`    ``FirstName NVARCHAR(30) ``NOT` `NULL`

`);`

`CREATE` `TABLE` `Orders`

`(`

`    ``Id ``INT` `IDENTITY ``PRIMARY` `KEY``,`

`    ``ProductId ``INT` `NOT` `NULL` `REFERENCES` `Products(Id) ``ON` `DELETE` `CASCADE``,`

`    ``CustomerId ``INT` `NOT` `NULL` `REFERENCES` `Customers(Id) ``ON` `DELETE` `CASCADE``,`

`    ``CreatedAt ``DATE` `NOT` `NULL``,`

`    ``ProductCount ``INT` `DEFAULT` `1,`

`    ``Price MONEY ``NOT` `NULL`

`);`

Теперь добавим в базу данных, в которой содержатся данные таблицы, следующее представление (VIEW):

----
`{`

`<span style=""font-family: Arial;""> </span>`    `<span style=""font-family: Arial;"">   </span>CREATE` `VIEW` `OrdersProductsCustomers ``AS`

`<span style=""font-family: Arial;""> </span>`    `<span style=""font-family: Arial;"">   </span>SELECT` `Orders.CreatedAt ``AS` `OrderDate,`

`<span style=""font-family: Arial;"">    </span>`    ` ``Customers.FirstName ``AS` `Customer,`

`<span style=""font-family: Arial;"">    </span>  `    ` ``Products.ProductName ``As` `Product `

`<span style=""font-family: Arial;"">    </span>`    `FROM` `Orders

`INNER` `JOIN` `Products ``ON` `Orders.ProductId = Products.Id`

`<span style=""font-family: Arial;"">    </span>`    `    `    `INNER` `JOIN` `Customers ``ON` `Orders.CustomerId = Customers.Id`

`};
----

== Что такое временные таблицы? Для чего они нужны?

Некоторые RDBMS (Relational Database Management System) поддерживают механизм временных таблиц.

Они позволяют нам хранить и обрабатывать промежуточные результаты используя все возможности SQL сервера.

Временные таблицы могут быть крайне полезными, когда нам необходимо хранить различные временные данные (например, список товаров в чеке, до момента осуществления оплаты). Главное преимущество таких таблиц заключается в том, что они будет удалены сразу же после завершения клиентской сессии.

== Что такое транзакции? Расскажите про принципы ACID

Транзакция - это воздействие на базу данных, переводящее её из одного целостного состояния в другое и выражаемое в изменении данных, хранящихся в базе данных.

Основные свойства транзакции:

* Атомарность (atomicity) - гарантирует, что никакая транзакция не будет зафиксирована в системе частично. Будут либо выполнены все её подоперации, либо не выполнено ни одной
* Согласованность (consistency) -  транзакция, достигающая своего нормального завершения и, тем самым, фиксирующая свои результаты, сохраняет согласованность базы данных
* Изолированность (isolation) - во время выполнения транзакции параллельные транзакции не должны оказывать влияние на ее результат
* Долговечность (durability) - независимо от проблем на нижних уровнях (к примеру, обесточивание системы или сбои в оборудовании) изменения, сделанные успешно завершённой транзакцией, должны остаться сохраненными после возвращения системы в работу

== Расскажите про уровни изолированности транзакций

В порядке увеличения изолированности транзакций и, соответственно, надежности работы с данными:

* Чтение неподтверждённых данных (грязное чтение) (read uncommitted, dirty read) — чтение незафиксированных изменений как своей транзакции, так и параллельных транзакций. Нет гарантии, что данные, измененные другими транзакциями, не будут в любой момент изменены в результате их отката, поэтому такое чтение является потенциальным источником ошибок.

Невозможны потерянные изменения, возможны неповторяемое чтение и фантомы.

* Чтение подтвержденных данных (read committed) — чтение всех изменений своей транзакции и зафиксированных изменений параллельных транзакций.

Потерянные изменения и грязное чтение не допускается, возможны неповторяемое чтение и фантомы.

* Повторяемость чтения (repeatable read, snapshot) — чтение всех изменений своей транзакции, любые изменения, внесенные параллельными транзакциями после начала своей, недоступны. Потерянные изменения, грязное и неповторяемое чтение невозможны, возможны фантомы.

* Упорядочиваемость (serializable) — результат параллельного выполнения сериализуемой транзакции с другими транзакциями должен быть логически эквивалентен результату их какого-либо последовательного выполнения. Проблемы синхронизации не возникают.

== Что такое нормализация и денормализация? Расскажите про 3 нормальные формы?

Подробно с примерами: <a href=""https://habr.com/ru/post/254773/"">https://habr.com/ru/post/254773/</a>

Нормализация - это процесс преобразования отношений базы данных к виду, отвечающему нормальным формам (пошаговый, обратимый процесс замены исходно схемы другой схемой, в которой наборы данных имеют более простую и логичную структуру).

Нормализация предназначена для приведения структуры базы данных к виду, обеспечивающему минимальную логическую избыточность, и не имеет целью уменьшение или увеличение производительности работы или же уменьшение или увеличение физического объема базы данных. Конечной целью нормализации является уменьшение потенциальной противоречивости хранимой в базе данных информации.

Денормализация базы данных — это процесс осознанного приведения базы данных к виду, в котором она не будет соответствовать правилам нормализации. Обычно это необходимо для повышения производительности и скорости извлечения данных, за счет увеличения избыточности данных.

* Первая нормальная форма (1NF) - отношение находится в 1NF, если все его атрибуты являются простыми, все используемые домены должны содержать только скалярные значения. Не должно быть повторений строк в таблице. Значение в столбце должно быть атомарным, то есть не должно содержать несколько значений.

- Устраните повторяющиеся группы в отдельных таблицах.
- Создайте отдельную таблицу для каждого набора связанных данных.
- Идентифицируйте каждый набор связанных данных с помощью первичного ключа.

* Вторая нормальная форма (2NF) - Отношение находится в 2NF, если оно находится в 1NF, и при этом все неключевые атрибуты зависят только от ключа целиком, а не от какой-то его части.

- Создайте отдельные таблицы для наборов значений, относящихся к нескольким записям.
- Свяжите эти таблицы с помощью внешнего ключа


* Третья нормальная форма (3NF) - Отношение находится в 3NF, если оно находится в 2NF и все неключевые атрибуты не зависят друг от друга.

- Устраните поля, не зависящие от ключа

== Что такое TIMESTAMP?

`DATETIME` - предназначен для хранения целого числа: YYYYMMDDHHMMSS. И это время не зависит от временной зоны настроенной на сервере. Размер: 8 байт

`TIMESTAMP` - хранит значение равное количеству секунд, прошедших с полуночи 1 января 1970 года по усредненному времени Гринвича. При получении из базы отображается с учётом часового пояса. Размер: 4 байта

== Что такое ORM? Что такое JPA? Что такое Hibernate?

*Object Relational Mapping* - это концепция/процесс преобразования данных из объектно-ориентированного языка в реляционные БД и наоборот. Например, в Java это делается с помощью рефлексии и JDBC.

http://internetka.in.ua/orm-intro/ подробнее

*JPA* – это технология, обеспечивающая объектно-реляционное отображение простых JAVA объектов и предоставляющая API для сохранения, получения и управления такими объектами.

*JPA* – это спецификация (документ, утвержденный как стандарт, описывающий все аспекты технологии), часть EJB3 спецификации.

Сам JP*A не умеет ни сохранять, ни управлять объектами, JPA только определяет правила игры: как что-то будет действовать. JPA также определяет интерфейсы, которые должны будут быть реализованы провайдерами. Плюс к этому JPA определяет правила о том, как должны описываться метаданные отображения и о том, как должны работать провайдеры. Дальше, каждый провайдер, реализуя JPA определяет получение, сохранение и управление объектами. У каждого провайдера реализация разная.

*Hibernate* - это провайдер, реализующий спецификацию JPA. Hibernate полностью реализует JPA плюс добавляет функционал в виде своих классов и интерфейсов, расширяя свои возможности по работе с сущностями и БД.

== Что такое EntityManager? Какие функции он выполняет?

Это интерфейс JPA, используемый для взаимодействия с персистентным контекстом. EntityManager описывает API для всех основных операций над Entity, а также для получения данных и других сущностей JPA. По сути - главный API для работы с JPA.

Персистентный контекст - это набор экземпляров сущностей, загруженных из БД или только что созданных. Персистентный контекст является своего рода кэшем данных в рамках транзакции - это и есть кэш первого уровня.

Внутри контекста персистентности происходит управление экземплярами сущностей и их жизненным циклом. EntityManager автоматически сохраняет в БД все изменения, сделанные в его персистентном контексте, в момент коммита транзакции, либо при явном вызове метода flush().

Один или несколько EntityManager образуют или могут образовать persistence context.

Если проводить аналогию с обычным JDBC, то EntityManagerFactory будет аналогом DataSource, а EntityManager аналогом Connection.

Интерфейс Session из Hibernate представлен в JPA как раз интерфейсом EntityManager.

Основные функции EntityManager</div> Операции над Entity:

* persist (добавление Entity под управление JPA)
* merge (изменение)
* remove (удаление)
* refresh (обновление данных)
* detach (удаление из-под управления контекста персистентности)
* lock (блокирование Entity от изменений в других thread)

Получение данных:

* find (поиск и получение Entity)
* createQuery
* createNamedQuery
* createNativeQuery
* contains
* createNamedStoredProcedureQuery
* createStoredProcedureQuery

Получение других сущностей JPA:

* getTransaction
* getEntityManagerFactory
* getCriteriaBuilder
* getMetamodel
* getDelegate

Работа с EntityGraph:

* createEntityGraph
* getEntityGraph

Общие операции над EntityManager или всеми Entities:

* close
* isOpen
* getProperties
* setProperty
* clear

Объекты EntityManager не являются потокобезопасными. Это означает, что каждый поток должен получить свой экземпляр EntityManager, поработать с ним и закрыть его в конце.

== Каким условиям должен удовлетворять класс чтобы являться Entity?

Hibernate позволяет определить обычный Java класс, как часть модели реляционной реляционной базы данных, точнее соответствие определенного класса к таблице модели базы данных. Что необходимо определить на уровне Java кода рассмотрим в данном материале.

Для начала, остановимся на основных требованиях JPA спецификации, которые необходимо учитывать при создании Entity класса (выполнение следующих требований позволяет переносить Entity классы под иную реализацию JPA):

* Entity класс должен быть отмечен аннотацией @Entity или описан в XML файле конфигурации JPA
* Enity класс должен содержать первичный ключ (ID), то есть атрибут или группу атрибутов которые уникально определяют запись этого Enity класса в базе данных
* Entity класс должен содержать public или protected конструктор без аргументов (он также может иметь конструкторы с аргументами)
* Entity класс должен быть классом верхнего уровня (top-level class)
* Entity класс не может быть enum или интерфейсом
* Entity класс не может быть финальным классом (final class)
* Entity класс не может содержать финальные поля или методы, если они участвуют в маппинге (persistent final methods or persistent final instance variables)
* Если объект Entity класса будет передаваться по значению как отдельный объект (detached object), например через удаленный интерфейс (through a remote interface), он так же должен реализовывать Serializable интерфейс
* Поля Entity класс должны быть напрямую доступны только методам самого Entity класса и не должны быть напрямую доступны другим классам, использующим этот Entity. Такие классы должны обращаться только к методам (getter/setter методам или другим методам бизнес-логики в Entity классе)

== Может ли абстрактный класс быть Entity?

Абстрактный класс может быть Entity классом. Абстрактный Entity класс отличается от обычных Entity классов только тем, что нельзя создать объект этого класса. Имена абстрактных классов могут использоваться в запросах.

== Может ли Entity класс наследоваться от не Entity классов (non-entity classes)?

Да, сущности могут наследоваться от не Entity классов, которые, в свою очередь, могут быть как абстрактными, так и обычными. Состояние (поля) не Entity суперкласса не является персистентным, то есть не хранится в БД и не обрабатывается провайдером (Hibernate), поэтому любое такое состояние (поля), унаследованное Entity классом, также не будет отображаться в БД.

== Может ли Entity класс наследоваться от других Entity классов?

Да.

== Может ли не Entity класс наследоваться от Entity класса?

Да.

== Что такое встраиваемый (Embeddable) класс?  Какие требования JPA устанавливает к встраиваемым (Embeddable) классам?

Это класс, который не используется сам по себе, а только как часть одного или нескольких Entity классов. Hibernate называет эти классы компонентами. JPA называет их встраиваемыми. В любом случае, концепция одна и та же: композиция значений.

Встраиваемый класс помечается аннотацией @Embeddable.

Встраиваемый класс может быть встроен в несколько классов-сущностей, но встроенный объект с конкретным состоянием принадлежит исключительно владеющей им сущности и не может использоваться одновременно другими сущностями, он не является общим для нескольких сущностей. То есть, если класс Person с полями name и age встроен и в класс Driver, и в класс Baker, то у обоих последних классов появятся оба поля из класса Person. Но если у объекта Driver эти поля будут иметь значения “Иван” и “35”, то эти же поля у объекта Baker могут иметь совершенно иные значения, никак не связанные с объектом Driver.

В целом, встраиваемый класс служит для того, чтобы выносить определение общих атрибутов для нескольких сущностей, можно считать что JPA просто встраивает в сущность вместо объекта такого класса те атрибуты, которые он содержит.

Особенности встраиваемых классов:

* все поля встраиваемого класса, даже коллекции, станут полями класса, в который происходит встраивание
* встраиваемые классы могут быть встроены в одну и ту же сущность несколько раз, нужно только поменять имена полей
* экземпляры встраиваемых классов, в отличие от экземпляров сущностей, не имеют собственного персистентного состояния, вместо этого они существуют только как часть состояния объекта, которому они принадлежат

Встраиваемые классы могут использовать в качестве полей:

* базовые типы
* коллекции базовых типов (с аннотацией @ElementCollection)
* другие встраиваемые классы
* коллекции других встраиваемых классов (с аннотацией @ElementCollection)
* сущности
* коллекции сущностей
* сущность может использовать в качестве полей одиночные встраиваемые
* классы и коллекции встраиваемых классов
* встраиваемые классы могут использоваться в качестве ключей и значений Map

Требования к встраиваемым классам:

* Должны соответствовать требованиям для сущностей (раздел 2.1 Java Persistence API), за исключением того, что у встраиваемых классов не ставится аннотация @Entity и может отсутствовать первичный ключ (@Id).
* Должны быть аннотированы @Embeddable.

== Что такое Mapped Superclass?

Mapped Superclass (сопоставленный суперкласс) - это класс, от которого наследуются Entity, он может содержать аннотации JPA, однако сам такой класс не является Entity, ему не обязательно выполнять все требования, установленные для Entity (например, он может не содержать первичного ключа). Эти суперклассы чаще всего используются, когда у нас есть общая для нескольких классов сущностей информация о состоянии и отображении, которую можно вынести в Mapped Superclass.

Особенности Mapped Superclass:

* Должен быть помечен аннотацией @MappedSuperclass или описан в xml файле.
* Не может использоваться в операциях EntityManager или Query, вместо этого нужно использовать классы-наследники.
* Не может состоять в отношениях с другими сущностями (в сущности нельзя создать поле с типом сопоставленного суперкласса).
* Может быть абстрактным.
* Не имеет своей таблицы в БД.

Mapped Superclass vs. Embeddable class

Сходства:

* не являются сущностями и могут иметь все аннотации, кроме @Entity;
* не имеют своих таблиц в БД;
* не могут использоваться в операциях EntityManager или Query.

Различия:

* Mapped Superclass - наследование, Embeddable class - композиция;
* поля из Mapped Superclass могут быть у сущности в одном экземпляре, полей из Embeddable class может быть сколько угодно (встроив в сущность Embeddable class несколько раз и поменяв имена полей);
* в сущности нельзя создать поле с типом сопоставленного суперкласса, а с Embeddable можно и нужно.

== Какие три стратегии наследования маппинга (Inheritance Mapping Strategies) описаны в JPA?

Стратегии наследования нужны для того, чтобы дать понять провайдеру (Hibernate) как ему отображать в БД сущности-наследники. Для этого нам нужно декорировать родительский класс аннотацией @Inheritance и указать один из типов отображения: SINGLE_TABLE, TABLE_PER_CLASS, JOINED.

Следующие три стратегии используются для отображения данных сущности- наследника и родительской сущности:

* Одна таблица на всю иерархию классов
* Таблица для каждого конкретного класса сущностей
* Стратегия «соединения», при которой поля или свойства, специфичные для подклассов, отображаются в таблицах этих подклассов, а поля или свойства родительского класса отображаются в таблице родительского класса

* одна таблица на всю иерархию наследования (a single table per class hierarchy) — все entity, со всеми наследниками записываются в одну таблицу, для идентификации типа entity определяется специальная колонка “discriminator column”. Например, если есть entity Animals c классами-потомками Cats и Dogs, при такой стратегии все entity записываются в таблицу Animals, но при это имеют дополнительную колонку animalType в которую соответственно пишется значение «cat» или «dog».Минусом является то что в общей таблице, будут созданы все поля уникальные для каждого из классов-потомков, которые будет пусты для всех других классов-потомков. Например, в таблице animals окажется и скорость лазанья по дереву от cats и может ли пес приносить тапки от dogs, которые будут всегда иметь null для dog и cat соответственно.

* объединяющая стратегия (joined subclass strategy) — в этой стратегии каждый класс entity сохраняет данные в свою таблицу, но только уникальные колонки (не унаследованные от классов-предков) и первичный ключ, а все унаследованные колонки записываются в таблицы класса-предка, дополнительно устанавливается связь (relationships) между этими таблицами, например в случае классов Animals (см.выше), будут три таблицы animals, cats, dogs, причем в cats будет записана только ключ и скорость лазанья, в dogs — ключ и умеет ли пес приносить палку, а в animals все остальные данные cats и dogs c ссылкой на соответствующие таблицы. Минусом тут являются потери производительности от объединения таблиц (join) для любых операций.

* одна таблица для каждого класса (table per concrete class strategy) — тут все просто каждый отдельный класс-наследник имеет свою таблицу, т.е. для cats и dogs (см.выше) все данные будут записываться просто в таблицы cats и dogs как если бы они вообще не имели общего суперкласса. Минусом является плохая поддержка полиморфизма (polymorphic relationships) и то что для выборки всех классов иерархии потребуются большое количество отдельных sql запросов или использование UNION запроса.

== Как мапятся Enumы?

По порядковым номерам.

Если мы сохраняем в БД сущность, у которой есть поле-перечисление (Enum), то в таблице этой сущности создаётся колонка для значений этого перечисления и по умолчанию в ячейки сохраняется порядковый номер этого перечисления (ordinal).

В JPA типы Enum могут быть помечены аннотацией @Enumerated, которая может принимать в качестве атрибута EnumType.ORDINAL или EnumType.STRING, определяющий, отображается ли перечисление (enum) на столбец с типом Integer или String соответственно.

@Enumerated(EnumType.ORDINAL) - значение по умолчанию, говорит о том, что в базе будут храниться порядковые номера Enum (0, 1, 2…). Проблема с этим типом отображения возникает, когда нам нужно изменить наш Enum. Если мы добавим новое значение в середину или просто изменим порядок перечисления, мы сломаем существующую модель данных. Такие проблемы могут быть трудно уловимыми, и нам придется обновлять все записи базы данных.

По именам

@Enumerated(EnumType.STRING) - означает, что в базе будут храниться имена Enum. С @Enumerated(EnumType.STRING) мы можем безопасно добавлять новые значения перечисления или изменять порядок перечисления. Однако переименование значения enum все равно нарушит работу базы данных. Кроме того, даже несмотря на то, что это представление данных гораздо более читаемо по сравнению с параметром @Enumerated(EnumType.ORDINAL), оно потребляет намного больше места, чем необходимо. Это может оказаться серьезной проблемой, когда нам нужно иметь дело с большим объемом данных.

@PostLoad и @PrePersist

Другой вариант - использование стандартных методов обратного вызова из JPA. Мы можем смаппить наши перечисления в БД и обратно в методах с аннотациями @PostLoad и @PrePersist.

Идея состоит в том, чтобы в сущности иметь не только поле с Enum, но и вспомогательное поле. Поле с Enum аннотируем @Transient, а в БД будет храниться значение из вспомогательного поля.

Несмотря на то, что этот вариант дает нам бОльшую гибкость по сравнению с ранее описанными решениями, он не идеален. Просто кажется неправильным иметь в сущности целых два атрибута, представляющих одно перечисление. Кроме того, если мы используем этот вариант, мы не сможем использовать значение Enum в запросах JPQL.

Converter

В JPA с версии 2.1 можно использовать Converter для конвертации Enum’а в некое его значение для сохранения в БД и получения из БД. Все, что нам нужно сделать, это создать новый класс, который реализует javax.persistence.AttributeConverter и аннотировать его с помощью @Converter.

== Как мапятся даты (до Java 8 и после)?

При работе с датами рекомендуется установить определенный часовой пояс для драйвера JDBC. Таким образом, наше приложение будет независимым от текущего часового пояса системы.

Другой способ - настроить свойство hibernate.jdbc.time_zone в файле свойств Hibernate, который используется для создания фабрики сессий. Таким образом, мы можем указать часовой пояс один раз для всего приложения.

java.sql

Стандарт SQL определяет три типа даты/времени:</div>

*  DATE - Представляет календарную дату путем хранения лет, месяцев и дней. Эквивалентом JDBC является java.sql.Date.
* TIME - Представляет время дня и хранит часы, минуты и секунды. Эквивалентом JDBC является java.sql.Time.
* TIMESTAMP - Хранит как DATE, так и TIME плюс наносекунды. Эквивалентом JDBC является java.sql.Timestamp.

Поскольку эти типы соответствуют SQL, их сопоставление относительно простое. Мы можем использовать аннотацию @Basic или @Column.

java.sql не рекомендуют использовать, т.к. содержит устаревшие функции. Лучше использовать java.sql

java.sql

Так как классы из этого пакета не имели прямого соответствия типам данных SQL, приходилось использовать над полями java.util.Date аннотацию @Temporal, чтобы дать понять SQL, с каким конкретно типом данных она работает.

Для этого у аннотации @Temporal нужно было указать параметр TemporalType, который принимал одно из трёх значений: DATE, TIME или TIMESTAMP, что позволяло указать базе данных с какими конкретными типами данных она работает.

java.time

Начиная с Java 8, доступен новый API даты и времени для работы с временными значениями. Этот API-интерфейс устраняет многие проблемы классов java.util.Date и java.util.Calendar. Все классы в новом API неизменяемые (immutable) и, как следствие, потоко-безопасные. Точность представления времени составляет одну наносекунду, что в миллион раз точнее чем в пакете java.util. Типы данных из пакета java.time напрямую отображаются (маппятся) на соответствующие типы SQL. Поэтому нет необходимости явно указывать аннотацию @Temporal:</div>

*  LocalDate соответствует DATE.
* LocalTime и OffsetTime соответствуют TIME.
* Instant, LocalDateTime, OffsetDateTime и ZonedDateTime соответствуют TIMESTAMP.

Это означает, что мы можем пометить эти поля только аннотацией @Basic (или @Column).

== Как “смапить” коллекцию примитивов?

Для маппинга коллекции элементов используется аннотация @ElementCollection, которая указывается в классе сущности над полем коллекции базовых или встраиваемых типов. Все записи коллекции хранятся в отдельной таблице, то есть в итоге получаем две таблицы: одну дл сущности, вторую для коллекции элементов.

Конфигурация для таблицы коллекции элементов указывается с помощью аннотации @CollectionTable, которая используется для указания имени таблицы коллекции и JoinColumn, который ссылается на первичную таблицу.

Аннотация @ElementCollection похожа на отношение @OneToMany, за исключением того, что целью являются базовые и встраиваемые типы, а не сущности.

Можно использовать аннотации @AttributeOverrides и @AttributeOverride для настройки отображения в таблице полей базовых или встраиваемых типов.

Коллекции могут иметь тип java.util.Map, которые состоят из ключа и значения.

Для этого типа коллекций применяются следующие правила:</div>

*  Ключ или значение Map может быть базовым типом языка программирования Java, встраиваемым классом или сущностью.
* Если значение Map является встраиваемым классом или базовым типом, используйте аннотацию @ElementCollection.
* Если значение Map является сущностью, используйте аннотацию @OneToMany или @ManyToMany. Использовать тип Map только на одной стороне двунаправленной связи.

Аннотация @MapKeyColumn позволяет настроить столбец «ключ» в таблице Map. Аннотация @Column позволяет настроить столбец «значение» в таблице Map.

Работать в Hibernate с коллекциями не рекомендуется, потому что Hibernate не умеет работать с каждым элементом индивидуально и при удалении или вставке элемента Hibernate очищает всю таблицу и заполняет ее заново. Желательно работать только с коллекциями с малым количеством элементов

== Какие есть виды связей?

Существуют 4 типа связей:

* OneToOne - когда один экземпляр Entity может быть связан не больше чем с одним экземпляром другого Entity.
* OneToMany - когда один экземпляр Entity может быть связан с несколькими экземплярами других Entity.
* ManyToOne - обратная связь для OneToMany. Несколько экземпляров Entity могут быть связаны с одним экземпляром другого Entity.
* ManyToMany - экземпляры Entity могут быть связаны с несколькими экземплярами друг друга.

Каждую из которых можно разделить ещё на два вида:

* *Bidirectional *— ссылка на связь устанавливается у всех Entity, то есть в случае OneToOne A-B в Entity A есть ссылка на Entity B, в Entity B есть ссылка на Entity A. Entity A считается владельцем этой связи (это важно для случаев каскадного удаления данных, тогда при удалении A также будет удалено B, но не наоборот).
* *Undirectional *—  ссылка на связь устанавливается только с одной стороны, то есть в случае OneToOne A-B только у Entity A будет ссылка на Entity B, у Entity B ссылки на A не будет.

== Что такое владелец связи?

В отношениях между двумя сущностями всегда есть одна владеющая сторона, а владеемой может и не быть, если это однонаправленные отношения.

По сути, у кого есть внешний ключ на другую сущность - тот и владелец связи. То есть, если в таблице одной сущности есть колонка, содержащая внешние ключи от другой сущности, то первая сущность признаётся владельцем связи, вторая сущность - владеемой.

В однонаправленных отношениях сторона, которая имеет поле с типом другой сущности, является владельцем этой связи по умолчанию.

== Что такое каскады?

Каскадирование - это когда мы выполняем какое-то действие с целевой Entity, то же самое действие будет применено к связанной Entity.

JPA CascadeType:

* ALL -  гарантируют, что все персистентные события, которые происходят на родительском объекте, будут переданы дочернему объекту.
* PERSIST -  означает, что операции save () или persist () каскадно передаются связанным объектам.
* MERGE - означает, что связанные entity объединяются, когда объединяется entity-владелец.
* REMOVE - удаляет все entity, связанные с удаляемой entity.
* DETACH - отключает все связанные entity, если происходит «ручное отключение».
* REFRESH - повторно считывают значение данного экземпляра и связанных сущностей из базы данных при вызове refresh().

== Какие два типа fetch стратегии в JPA вы знаете?

В JPA описаны два типа fetch-стратегии:</div>

* LAZY — данные поля сущности будут загружены только во время первого обращения к этому полю.
* EAGER — данные поля будут загружены немедленно вместе с сущностью. FetchType.EAGER: Hibernate должен сразу загрузить соответствующее аннотированное поле или свойство. Это поведение по умолчанию для полей, аннотированных @Basic, @ManyToOne и @OneToOne.


FetchType.LAZY: Hibernate может загружать данные не сразу, а при первом обращении к ним, но так как это необязательное требование, то Hibernate имеет право изменить это поведение и загружать их сразу. Это поведение по умолчанию для полей, аннотированных @OneToMany, @ManyToMany и ElementCollection.

Раньше у Hibernate все поля были LAZY, но в последних версиях - всё как в JPA.

== Какие четыре статуса жизненного цикла Entity объекта (Entity Instance’s Life Cycle) вы можете перечислить?

Согласно JPA объект сущности может иметь один из четырех статусов жизненного цикла:

* new - объект создан, не имеет primary key, не является частью контекста персистентности (не управляется JPA)
* managed - объект создан, имеет primary key, является частью контекста персистентности (управляется JPA)
* detached - объект создан, имеет primary key, не является (или больше не является) частью контекста персистентности (не управляется JPA)
* removed - объект создан, является частью контекста персистентности (управляется JPA), будет удален при commit-е транзакции

== Как влияет операция persist на Entity объекты каждого из четырех статусов?

new → managed, и объект будет сохранен в базу при commit-е транзакции или в результате flush операций

managed → операция игнорируется, однако зависимые Entity могут поменять статус на managed, если у них есть аннотации каскадных изменений

detached → exception сразу или на этапе commit-а транзакции

removed → managed, но только в рамках одной транзакции.


new -&gt; managed

managed -&gt; ignore

detached -&gt; exeption

removed -&gt; managed

== Как влияет операция remove на Entity объекты каждого из четырех статусов?

new → операция игнорируется, однако зависимые Entity могут поменять статус на removed, если у них есть аннотации каскадных изменений и они имели статус managed

managed → removed и запись объект в базе данных будет удалена при commit-е транзакции (также произойдут операции remove для всех каскадно зависимых объектов)

detached → exception сразу или на этапе commit-а транзакции

removed → операция игнорируется

new -&gt; ignore

managed -&gt; removed

detached -&gt; exeption

removed -&gt; ignore

== Как влияет операция merge на Entity объекты каждого из четырех статусов?

new → будет создан новый managed entity, в который будут скопированы данные прошлого объекта

managed → операция игнорируется, однако операция merge сработает на каскадно зависимые Entity, если их статус не managed

detached → либо данные будут скопированы в существующий managed entity с тем же первичным ключом, либо создан новый managed в который скопируются данные

removed → exception сразу или на этапе commit-а транзакции

new -&gt; managed

managed -&gt; ignore

detached -&gt; managed

remove -&gt; exception

== Как влияет операция refresh на Entity объекты каждого из четырех статусов?

managed → будут восстановлены все изменения из базы данных данного Entity, также произойдет refresh всех каскадно зависимых объектов

new, removed, detached → exception

new, remove, detached -&gt; e

managed -&gt; update from db

== Как влияет операция detach на Entity объекты каждого из четырех статусов?

managed, removed → detached.

new, detached → операция игнорируется

new -&gt; ignore

managed -&gt; detached

removed -&gt; detached

detached -&gt; ignore

== Для чего нужна аннотация Basic?

@Basic — аннотация используется для сопоставления базового типа атрибута столбцу таблицы базы данных.

@Basic —  указывает на простейший тип маппинга данных на колонку таблицы базы данных. Также в параметрах аннотации можно указать fetch стратегию доступа к полю и является ли это поле обязательным или нет.

Может быть применена к полю любого из следующих типов:</div>

*  Примитивы и их обертки.
* java.lang.String
* java.math.BigInteger
* java.math.BigDecimal
* java.util.Date
* java.util.Calendar
* java.sql.Date
* java.sql.Time
* java.sql.Timestamp
* byte[] or Byte[] char[] or Character[]
* enums любые другие типы, которые реализуют Serializable.

Вообще, аннотацию @Basic можно не ставить, так как это происходит по умолчанию.

Аннотация @Basic определяет 2 атрибута:

1. optional - boolean (по умолчанию true) - определяет, может ли значение поля или свойства быть null. Игнорируется для примитивных типов. Но если тип поля не примитивного типа, то при попытке сохранения сущности будет выброшено исключение.

2. fetch - FetchType (по умолчанию EAGER) - определяет, должен ли этот атрибут извлекаться незамедлительно (EAGER) или лениво (LAZY). Однако, это необязательное требование JPA, и провайдерам разрешено незамедлительно загружать данные, даже для которых установлена ленивая загрузка.

Без аннотации @Basic при получении сущности из БД по умолчанию её поля базового типа загружаются принудительно (EAGER) и значения этих полей могут быть null

== Для чего нужна аннотация Column?

@Column — аннотирование используется для указания соответствия между атрибутом базовой сущности (Entity класса) и столбцом таблицы базы данных.

Спецификация JPA определяет правила для неявного определения имени столбцов (column). Для атрибутов базового типа правило неявного именования состоит в том, что имя столбца совпадает с именем атрибута. Если это неявное правило именования не удовлетворяет вашим требованиям, вы можете явно указать Hibernate (и другим провайдерам) имя столбца, которое будет использоваться явно.

@Basic vs @Column:</div> Атрибуты @Basic применяются к сущностям JPA, тогда как атрибуты @Column применяются к столбцам базы данных. @Basic имеет атрибут optional, который говорит о том, может ли поле объекта быть null или нет; с другой стороны атрибут nullable аннотации @Column указывает, может ли соответствующий столбец в таблице быть null. Мы можем использовать @Basic, чтобы указать, что поле должно быть загружено лениво. Аннотация @Column позволяет нам указать имя столбца в таблице и ряд других свойств:  insertable/updatable - можно ли добавлять/изменять данные в колонке, по умолчанию true;  length - длина, для строковых типов данных, по умолчанию 255.

Коротко, в Column мы задаем constraints (ограничения), а в Basic - ФЕТЧ ТАЙП.

== Для чего нужна аннотация Access?

Она определяет тип доступа (access type) для класса entity, суперкласса, embeddable или отдельных атрибутов, то есть как JPA будет обращаться к атрибутам entity, как к полям класса (FIELD) или как к свойствам класса (PROPERTY), имеющие гетеры (getter) и сетеры (setter).

В хибере автоматически выбирается по аннотации первичного ключа айди. Если айди над полем, то доступ через поля, а если над геттером, то через проперти.

== Для чего нужна аннотация Cacheable?

@Cacheable - необязательная аннотация JPA, используется для указания того, должна ли сущность храниться в кэше второго уровня.

Аннотация @Cacheable размещается над классом сущности. Ее действие распространяется на эту сущность и её наследников, если они не определили другое поведение.

== Для чего нужны аннотации @Embedded и @Embeddable?

* @Embeddable - аннотация JPA, размещается над классом для указания того, что класс является встраиваемым в другие классы.
* @Embedded - аннотация JPA, используется для размещения над полем в классе-сущности для указания того, что мы внедряем встраиваемый класс.

== Как смапить составной ключ?

Существует три стратегии использования составного первичного ключа:

* Отметьте его как @Embeddable и добавьте в свой класс сущности нормальное свойство для него, помеченное @Id.
* Добавьте к классу сущности нормальное свойство для него, помеченное @EmbeddedId.
* Добавить свойства в класс сущности для всех его полей, пометить их @Id и пометить класс сущности @IdClass, предоставив класс вашего основного класса ключей.

Использование @Id с классом, помеченным как @Embeddable, является наиболее естественным подходом. Тег @Embeddable может использоваться для вложенных значений не первичного ключа. Он позволяет обрабатывать составной первичный ключ как одно свойство и позволяет повторно использовать класс @Embeddable в других таблицах.

Следующим наиболее естественным подходом является использование тега @EmbeddedId. Здесь класс первичного ключа не может использоваться в других таблицах, поскольку он не является объектом @Embeddable, но он позволяет нам рассматривать ключ как единственный атрибут некоторого класса.

Наконец, использование аннотаций @IdClass и @Id позволяет нам отображать составной класс первичного ключа, используя свойства самого объекта, соответствующие именам свойств в классе первичного ключа. Имена должны соответствовать (нет механизма для переопределения этого), а класс первичного ключа должен выполнять те же обязательства, что и в отношении двух других методов. Единственным преимуществом этого подхода является его способность ""скрыть"" использование класса первичного ключа из интерфейса охватывающего объекта. Аннотация @IdClass принимает параметр значения типа Class, который должен быть классом, который будет использоваться в качестве составного первичного ключа. Поля, соответствующие свойствам класса первичного ключа, которые должны использоваться, должны быть аннотированы с помощью @Id.

@IdClass vs @EmbeddedId:

* с @IdClass нам пришлось указывать столбцы дважды - в AccountId и в Account. Но с @EmbeddedId мы этого не сделали;

* JPQL-запросы с @IdClass проще. С @EmbeddedId, чтобы получить доступ к полю, нам нужно из сущности обратиться к встраиваемому классу и потом к его полю:

<i>SELECT account.accountNumber FROM Account account // с @IdClass</i><i>

SELECT book.bookId.title FROM Book book // с @EmbeddedId

</i>
* @EmbeddedId более подробна, чем @IdClass, поскольку мы можем получить доступ ко всему объекту первичного ключа, используя метод доступа к полю в классе-сущности. Это также дает четкое представление о полях, которые являются частью составного ключа, поскольку все они агрегированы в классе, который доступен только через метод доступа к полям

* @IdClass может быть предпочтительным выбором по сравнению с @EmbeddedId в ситуациях, когда класс составного первичного ключа поступает из другого модуля или устаревшего кода, а также когда мы не можем его изменить, например, чтобы установить аннотацию @EmbeddedId. Для таких сценариев, где мы не можем изменить класс составного ключа, аннотация @IdClass является единственным выходом

* если мы собираемся получить доступ к частям составного ключа по отдельности, мы можем использовать @IdClass, но в тех местах, где мы часто используем полный идентификатор в качестве объекта, @EmbeddedId предпочтительнее

== Для чего нужна аннотация ID? Какие @GeneratedValue вы знаете?

Аннотация @Id определяет простой (не составной) первичный ключ, состоящий из одного поля. В соответствии с JPA, допустимые типы атрибутов для первичного ключа:

* примитивные типы и их обертки
* строки
* BigDecimal и BigInteger
* java.util.Date и java.sql.Date

Стратегии генерации Id

Если мы хотим, чтобы значение первичного ключа генерировалось для нас автоматически, мы можем добавить первичному ключу, отмеченному аннотацией @Id, аннотацию @GeneratedValue. Согласно спецификации JPA возможно 4 различных варианта: AUTO, IDENTITY, SEQUENCE, TABLE. Если мы не укажем значение явно, типом генерации по умолчанию будет AUTO. Спецификация JPA строго не определяет поведение этих стратегий.

* AUTO - указывает, что Hibernate должен выбрать подходящую стратегию для конкретной базы данных, учитывая её диалект, так как у разных БД разные способы по умолчанию.
* IDENTITY - для генерации значения первичного ключа будет использоваться столбец IDENTITY, имеющийся в базе данных. Значения в столбце автоматически увеличиваются вне текущей выполняемой транзакции(на стороне базы, так что этого столбца мы не увидим), что позволяет базе данных генерировать новое значение при каждой операции вставки. В промежутках транзакций сущность будет сохранена.
* SEQUENCE - тип генерации, рекомендуемый документацией Hibernate.

Для получения значений первичного ключа Hibernate должен использовать имеющиеся в базе данных механизмы генерации последовательных значений (Sequence). В бд можно будет увидеть дополнительную таблицу. Но если наша БД не поддерживает тип SEQUENCE, то Hibernate автоматически переключится на тип TABLE. В промежутках транзакций сущность не будет сохранена, так как хибер возьмет из таблицы id hibernate-sequence и вернётся обратно в приложение.

* SEQUENCE - это объект базы данных, который генерирует инкрементные целые числа при каждом последующем запросе.
* TABLE - Hibernate должен получать первичные ключи для сущностей из создаваемой для этих целей таблицы, способной содержать именованные сегменты значений для любого количества сущностей. Требует использования пессимистических блокировок, которые помещают все транзакции в последовательный порядок и замедляет работу приложения.

== Расскажите про аннотации @JoinColumn и @JoinTable? Где и для чего они используются?

Аннотация JoinColumn используется для указания столбца для присоединения ассоциированных сущностей или коллекции элементов.

В этой аннотации можно указать различные constraints для колонки, которая будет являться foreign key. Например unique, nullable, name, updatable, insertable и т.д.

@JoinColumn используется для указания столбца FOREIGN KEY, используемого при установлении связей между сущностями или коллекциями. Мы помним, что только сущность-владелец связи может иметь внешние ключи от другой сущности (владеемой). Однако, мы можем указать @JoinColumn как во владеющей таблице, так и во владеемой, но столбец с внешними ключами всё равно появится во владеющей таблице.

Особенности использования:

@OneToOne: означает, что появится столбец в таблице сущности-владельца связи, который будет содержать внешний ключ, ссылающийся на первичный ключ владеемой сущности.

@OneToMany/@ManyToOne: если не указать на владеемой стороне связи атрибут mappedBy, создается joinTable с ключами обеих таблиц. Но при этом же у владельца создается столбец с внешними ключами.

@JoinColumns используется для группировки нескольких аннотаций @JoinColumn, которые используются при установлении связей между сущностями или коллекциями, у которых составной первичный ключ и требуется несколько колонок для указания внешнего ключа.

В каждой аннотации @JoinColumn должны быть указаны элементы name и referencedColumnName.

@JoinTable используется для указания связывающей (сводной, третьей) таблицы между двумя другими таблицами.

== Для чего нужны аннотации @OrderBy и @OrderColumn, чем они отличаются?

@OrderBy указывает порядок, в соответствии с которым должны располагаться элементы коллекций сущностей, базовых или встраиваемых типов при их извлечении из БД. Если в кэше есть нужные данные, то сортировки не будет. Так как @OrderBy просто добавляет к sql-запросу Order By, а при получении данных из кэша, обращения к бд нет. Эта аннотация может использоваться с аннотациями @ElementCollection, @OneToMany, @ManyToMany.

При использовании с коллекциями базовых типов, которые имеют аннотацию @ElementCollection, элементы этой коллекции будут отсортированы в натуральном порядке, по значению базовых типов.

Если это коллекция встраиваемых типов (@Embeddable), то используя точку (""""."""") мы можем сослаться на атрибут внутри встроенного атрибута.

Если это коллекция сущностей, то у аннотации @OrderBy можно указать имя поля сущности, по которому сортировать эти самые сущности:

Если мы не укажем у @OrderBy параметр, то сущности будут упорядочены по первичному ключу.

В случае с сущностями доступ к полю по точке не работает. Попытка использовать вложенное свойство, например @OrderBy (""""supervisor.name"""") повлечет Runtime Exceprtion.

@OrderColumn создает в таблице столбец с индексами порядка элементов, который используется для поддержания постоянного порядка в списке, но этот столбец не считается частью состояния сущности или встраиваемого класса.

Hibernate отвечает за поддержание порядка как в базе данных при помощи столбца, так и при получении сущностей и элементов из БД. Hibernate отвечает за обновление порядка при записи в базу данных, чтобы отразить любое добавление, удаление или иное изменение порядка, влияющее на список в таблице.

@OrderBy vs @OrderColumn

Порядок, указанный в @OrderBy, применяется только в рантайме при выполнении запроса к БД, То есть в контексте персистентности, в то время как при использовании @OrderColumn, порядок сохраняется в отдельном столбце таблицы и поддерживается при каждой вставке/обновлении/удалении элементов.

== Для чего нужна аннотация Transient?

@Transient – указывает, что свойство не нужно записывать. Значения под этой аннотацией не записываются в базу данных (так же не участвуют в сериализации). static и final переменные экземпляра всегда transient.

== Какие шесть видов блокировок (lock) описаны в спецификации JPA (или какие есть значения у enum LockModeType в JPA)?

В порядке от самого ненадежного и быстрого, до самого надежного и медленного:</div>

*  NONE — без блокировки
* OPTIMISTIC (синоним READ в JPA 1) — оптимистическая  блокировка, которая работает, как описано ниже: если при завершении транзакции кто-то извне изменит поле @Version, то будет сделан RollBack транзакции и будет выброшено OptimisticLockException
* OPTIMISTIC_FORCE_INCREMENT (синоним WRITE в JPA 1) — работает по тому же алгоритму, что и LockModeType.OPTIMISTIC за тем исключением, что после commit значение поле Version принудительно увеличивается на 1. В итоге окончательн о после каждого коммита поле увеличится на 2(увеличение, которое можно увидеть в Post-Update + принудительное увеличение)
* PESSIMISTIC_READ — данные блокируются в момент чтения и это гарантирует, что никто в ходе выполнения транзакции не сможет их изменить. Остальные транзакции, тем не менее, смогут параллельно читать эти данные. Использование этой блокировки может вызывать долгое ожидание блокировки или даже выкидывание PessimisticLockException
* PESSIMISTIC_WRITE — данные блокируются в момент записи и никто с момента захвата блокировки не может в них писать и не может их читать до окончания транзакции, владеющей блокировкой. Использование этой блокировки может вызывать долгое ожидание блокировки.
* PESSIMISTIC_FORCE_INCREMENT — ведёт себя как PESSIMISTIC_WRITE, но в конце транзакции увеличивает значение поля @Version, даже если фактически сущность не изменилась.

Оптимистичное блокирование - подход предполагает, что параллельно выполняющиеся транзакции редко обращаются к одним и тем же данным и позволяет им свободно выполнять любые чтения и обновления данных. Но при окончании транзакции производится проверка, изменились ли данные в ходе выполнения данной транзакции и, если да, транзакция обрывается и выбрасывается OptimisticLockException. Оптимистичное блокирование в JPA реализовано путем внедрения в сущность специального поля версии:

 @Version

 private long version;

Поле, аннотирование @Version, может быть целочисленным или временным. При завершении транзакции, если сущность была заблокирована оптимистично, будет проверено, не изменилось ли значение @Version кем-либо ещё, после того как данные были прочитаны, и, если изменилось, будет выкинуто OptimisticLockException. Использование этого поля позволяет отказаться от блокировок на уровне базы данных и сделать всё на уровне JPA, улучшая уровень конкурентности.

Пессимистичное блокирование - подход напротив, ориентирован на транзакции, которые часто конкурируют за одни и те же данные и поэтому блокирует доступ к данным в тот момент когда читает их. Другие транзакции останавливаются, когда пытаются обратиться к заблокированным данным и ждут снятия блокировки (или кидают исключение). Пессимистичное блокирование выполняется на уровне базы и поэтому не требует вмешательств в код сущности.

Блокировки ставятся путём вызова метода lock() у EntityManager, в который передаётся сущность, требующая блокировки и уровень блокировки:

EntityManager em = entityManagerFactory.createEntityManager();

em.lock(company1, LockModeType.OPTIMISTIC).

== Какие два вида кэшей (cache) вы знаете в JPA и для чего они нужны?

<a href=""https://sysout.ru/kesh-pervogo-i-vtorogo-urovnya-v-hibernate-i-read_only-cacheconcurrencystrategy/"">https://sysout.ru/kesh-pervogo-i-vtorogo-urovnya-v-hibernate-i-read_only-cacheconcurrencystrategy/</a> - подробнее с примерами

Кеширование является одним из способов оптимизации работы приложения, ключевой задачей которого является уменьшить количество прямых обращений к базе данных.

Кэш первого уровня – это кэш Сессии (Session), который является обязательным. Через него проходят все запросы. Перед тем, как отправить объект в БД, сессия хранит объект за счёт своих ресурсов.

В том случае, если мы выполняем несколько обновлений объекта, Hibernate старается отсрочить (насколько это возможно) обновление для того, чтобы сократить количество выполненных запросов. Если мы закроем сессию, то все объекты, находящиеся в кэше теряются, а далее – либо сохраняются, либо обновляются. Кэш первого уровня это и есть PersistenceContext.

Кэш второго уровня является необязательным (опциональным) и изначально Hibernate будет искать необходимый объект в кэше первого уровня. В основном, кэширование второго уровня отвечает за кэширование объектов. Кэш второго уровня привязан к EntityManagerFactory.

Кэш запросов (Query Cache)

В Hibernate предусмотрен кэш для запросов и он интегрирован с кэшем второго уровня. Это требует двух дополнительных физических мест для хранения кэшированных запросов и временных меток для обновления таблицы БД. Этот вид кэширования эффективен только для часто используемых запросов с одинаковыми параметрами.

Особенности кэша первого уровня:

* включен по умолчанию, его нельзя отключить;
* связан с сессией (контекстом персистентности), то есть разные сессии видят только объекты из своего кэша, и не видят объекты, находящиеся в кэшах других сессий;
* при закрытии сессии PersistenceContext очищается - кэшированные объекты, находившиеся в нем, удаляются;
* при первом запросе сущности из БД, она загружается в кэш, связанный с этой сессией;
* если в рамках этой же сессии мы снова запросим эту же сущность из БД, то она будет загружена из кэша, и никакого второго SQL-запроса в БД сделано не будет;
* сущность можно удалить из кэша сессии методом evict(), после чего следующая попытка получить эту же сущность повлечет обращение к базе данных;
* метод clear() очищает весь кэш сессии.

== Как работать с кешем 2 уровня?

Чтение из кэша второго уровня происходит только в том случае, если нужный объект не был найден в кэше первого уровня.

Hibernate поставляется со встроенной поддержкой стандарта кэширования Java JCache, а также двух популярных библиотек кэширования: Ehcache и Infinispan.

В Hibernate кэширование второго уровня реализовано в виде абстракции, то есть мы должны предоставить любую её реализацию, вот несколько провайдеров: Ehcache, OSCache, SwarmCache, JBoss TreeCache. Для Hibernate требуется только реализация интерфейса org.hibernate.cache.spi.RegionFactory, который инкапсулирует все детали, относящиеся к конкретным провайдерам. По сути, RegionFactory действует как мост между Hibernate и поставщиками кэша. В примерах будем использовать Ehcache. Что нужно сделать:

добавить мавен-зависимость кэш-провайдера нужной версии

* включить кэш второго уровня и определить конкретного провайдера

* hibernate.cache.use_second_level_cache=true

* hibernate.cache.region.factory_class=org.hibernate.cache.ehcache.EhCacheRegionFactory

* установить у нужных сущностей JPA-аннотацию @Cacheable, обозначающую, что сущность нужно кэшировать, и Hibernate-аннотацию @Cache, настраивающую детали кэширования, у которой в качестве параметра указать стратегию параллельного доступа

Стратегии параллельного доступа к объектам

Проблема заключается в том, что кэш второго уровня доступен из нескольких сессий сразу и несколько потоков программы могут одновременно в разных транзакциях работать с одним и тем же объектом. Следовательно надо как-то обеспечивать их одинаковым представлением этого объекта.

* READ_ONLY: Используется только для сущностей, которые никогда не изменяются (будет выброшено исключение, если попытаться обновить такую сущность). Очень просто и производительно. Подходит для некоторых статических данных, которые не меняются.
* NONSTRICT_READ_WRITE: Кэш обновляется после совершения транзакции, которая изменила данные в БД и закоммитила их. Таким образом, строгая согласованность не гарантируется, и существует небольшое временное окно между обновлением данных в БД и обновлением тех же данных в кэше, во время которого параллельная транзакция может получить из кэша устаревшие данные.
* READ_WRITE: Эта стратегия гарантирует строгую согласованность, которую она достигает, используя «мягкие» блокировки: когда обновляется кэшированная сущность, на нее накладывается мягкая блокировка, которая снимается после коммита транзакции. Все параллельные транзакции, которые пытаются получить доступ к записям в кэше с наложенной мягкой блокировкой, не смогут их прочитать или записать и отправят запрос в БД. Ehcache использует эту стратегию по умолчанию.
* TRANSACTIONAL: полноценное разделение транзакций. Каждая сессия и каждая транзакция видят объекты, словно они работали с ними последовательно одна транзакция за другой. Плата за это — блокировки и потеря производительности.

@Cache

Это аннотация Hibernate, настраивающая тонкости кэширования объекта в кэше второго уровня Hibernate. @Cache принимает три параметра:

* include - имеет по умолчанию значение all и означающий кэширование всего объекта. Второе возможное значение - non-lazy, запрещает кэширование лениво загружаемых объектов. Кэш первого уровня не обращает внимания на эту директиву и всегда кэширует лениво загружаемые объекты.
* region - позволяет задать имя региона кэша для хранения сущности. Регион можно представить как разные области кэша, имеющие разные настройки на уровне реализации кэша.
* usage - задаёт стратегию одновременного доступа к объектам.

== Что такое JPQL/HQL и чем он отличается от SQL?

Hibernate Query Language (HQL) и Java Persistence Query Language (JPQL) - оба являются объектно-ориентированными языками запросов, схожими по природе с SQL. JPQL - это подмножество HQL. JPQL-запрос всегда является допустимым HQL - запросом, однако обратное неверно.

Java Persistence query language (JPQL)

Это язык запросов, практически такой же как SQL, однако, вместо имен и колонок таблиц базы данных, он использует имена классов Entity и их атрибуты. В качестве параметров запросов также используются типы данных атрибутов Entity, а не полей баз данных. В отличии от SQL в JPQL есть автоматический полиморфизм. Также в JPQL используются функции, которых нет в SQL: такие как KEY (ключ Map’ы), VALUE (значение Map’ы), TREAT (для приведения суперкласса к его объекту - наследнику, downcasting), ENTRY и т.п.

Полиморфные запросы

В отличии от SQL в запросах JPQL есть автоматический полиморфизм, то есть каждый запрос к Entity возвращает не только объекты этого Entity, но также объекты всех его классов-потомков, независимо от стратегии наследования (например, запрос select * from Animal, вернет не только объекты Animal, но и объекты классов Cat и Dog, которые унаследованы от Animal). Чтобы исключить такое поведение используется функция TYPE в where условии (например select * from Animal a where TYPE(a) IN (Animal, Cat) уже не вернет объекты класса Dog).

== Что такое Criteria API и для чего он используется?

Hibernate Criteria API

Это тоже язык запросов, аналогичный JPQL (Java Persistence query language), однако запросы основаны на методах и объектах. Hibernate Criteria API является более объектно-ориентированным для запросов, которые получают результат из базы данных. Для операций update, delete или других DDL манипуляций использовать Criteria API нельзя. Критерии используются только для выборки из базы данных в более объектно-ориентированном стиле. Используется для динамических запросов.

Запросы выглядят так:

<i> session.createCriteria(Person.class)
 </i><i>.setMaxResults(10)
 </i><i>.list()
 </i><i>.forEach(System.out::println);</i>

Запрос выше полностью аналогичен запросу HQL ""from Person"". С Criteria также работают и все те вещи, которые работают и с Query: пейджинг, таймауты и т.д. Разумеется, в Criteria запросах можно и нужно накладывать условия, по которым объекты будут отбираться:

<i> </i><i>session.createCriteria(Person.class)
 </i><i>.add(Restrictions.eq(""lastName"", ""Testoff""))
 </i><i>.list()
 </i><i>.forEach(System.out::println);</i>

JPA Criteria API

Criteria API - это актуальный API, используемый для определения запросов для сущностей. Это альтернативный способ определения JPQL-запроса. Эти запросы типобезопасны, переносимы и легко меняются путем изменения синтаксиса.

Основные преимущества JPA Criteria API:

* ошибки могут быть обнаружены во время компиляции;
* позволяет динамически формировать запросы на этапе выполнения приложения.

Запросы на основе строк JPQL и запросы на основе критериев JPA одинаковы по производительности и эффективности.

Для простых статических запросов предпочтительнее использовать строковые запросы JPQL (например, в виде именованных запросов). Для динамических запросов, которые создаются во время выполнения - JPA Criteria API может быть

предпочтительней. Например, построение динамического запроса на основе полей, которые пользователь заполняет в рантайме в форме, которая содержит много необязательных полей. Ожидается, что построение этого запроса будет более ясным и понятным при использовании JPA Criteria API, поскольку устраняет необходимость в создании запроса с использованием многих операций конкатенации строк.

== Расскажите про проблему N+1 Select и путях ее решения.

"<a href=""https://sysout.ru/n-1-problema-v-hibernate/"">https://sysout.ru/n-1-problema-v-hibernate/</a> - подробно с примерами

Проблема N+1 запросов возникает, когда получение данных из БД выполняется за N дополнительных SQL-запросов для извлечения тех же данных, которые могли быть получены при выполнении основного SQL-запроса.

N+1 при FetchType.EAGER

Так как у @ManyToOne план извлечения по умолчанию - EAGER, то при

получении из БД сущности немедленно будет загружена связанная с ней сущность

N+1 при FetchType.LAZY

Даже если мы явно переключимся на использование FetchType.LAZY для всех ассоциаций, мы всё равно можем столкнуться с проблемой N+1.

Решения проблемы N+1:

*  JOIN FETCH

И при FetchType.EAGER и при FetchType.LAZY нам поможет JPQL-запрос с JOIN FETCH. Опцию «FETCH» можно использовать в JOIN (INNER JOIN или LEFT JOIN) для выборки связанных объектов в одном запросе вместо дополнительных запросов для каждого доступа к ленивым полям объекта.

*  EntityGraph

В случаях, когда нам нужно получить по-настоящему много данных, и у нас jpql запрос - лучше всего использовать EntityGraph.

*  @Fetch(FetchMode.SUBSELECT)

Это Аннотация Hibernate, в JPA её нет. Можно использовать только с коллекциями. Будет сделан один sql-запрос для получения корневых сущностей и, если в контексте персистентности будет обращение к ленивым полям-коллекциям, то выполнится еще один запрос для получения связанных коллекций.

* @Batch fetching

Это Аннотация Hibernate, в JPA её нет. Указывается над классом сущности или над полем коллекции с ленивой загрузкой. Будет сделан один sql-запрос для получения корневых сущностей и, если в контексте персистентности будет обращение к ленивым полям-коллекциям, то выполнится еще один запрос для получения связанных коллекций.

* HibernateSpecificMapping, SqlResultSetMapping

Для нативных запросов рекомендуется использовать именно их.

== Что такое EntityGraph? Как и для чего их использовать?

Основная цель JPA Entity Graph - улучшить производительность в рантайме при загрузке базовых полей сущности и связанных сущностей и коллекций.

Вкратце, Hibernate загружает весь граф в одном SELECT-запросе, то есть все указанные связи от нужной нам сущности. Если надо загрузить дополнительные сущности, находящиеся в связанных сущностях - используется Subgraph.

EntityGraph можно определить с помощью аннотации @NamedEntityGraph для Entity, она определяет уникальное имя и список атрибутов ( attributeNodes ), которые должны быть загружены, и используя entityManager из JPA API:

<i>EntityGraph&lt;Post&gt; entityGraph = entityManager.createEntityGraph(Post.class);</i></div><i>
entityGraph.addAttributeNodes(""""subject"""");</i></div><i>
entityGraph.addAttributeNodes(""""user"""");</i></div><i>
entityGraph.addSubgraph(""""comments"""").addAttributeNodes(""""user"""");</i></div><i>
 </i>

JPA определяет два свойства или подсказки, с помощью которых Hibernate может выбирать стратегию извлечения графа сущностей во время выполнения:

* fetchgraph - все атрибуты перечисленные в EntityGraph меняют fetchType на EAGER, все остальные на LAZY
* loadgraph - все атрибуты перечисленные в EntityGraph меняют fetchType на EAGER, все остальные сохраняют свой fetchType. С помощью NamedSubgraph можно также изменить fetchType вложенных объектов Entity.

Загрузить EntityGraph можем тремя способами:</div>

* Используя перегруженный метод find(), который принимает Map с настройками EntityGraph
* Используя JPQL и передав подсказку через setHint()
* С помощью Criteria API

== Что такое инверсия контроля (IoC) и внедрение зависимостей (DI)? Как эти принципы реализованы в Spring?

*Inversion  of Control (IoC)***

Инверсия контроля (инверсия управления) - это принцип в разработке программного обеспечения, при котором управление объектами или частями программы передается контейнеру или фреймворку. Чаще всего этот принцип используется в контексте объектно-ориентированного программирования.

В отличие от традиционного программирования, в котором наш пользовательский код обращается напрямую к библиотекам, IoC позволяет фреймворку контролировать ход программы и обращаться к нашему коду, когда это необходимо. Для этого, фреймворки используют абстракции со встроенным дополнительным поведением. Если мы хотим добавить наше собственное поведение, нам нужно расширить классы фреймворка или подключить наши собственные классы.

Преимущества этой архитектуры:

* отделение выполнения задачи от ее реализации;
* легкое переключение между различными реализациями;
* бо́льшая модульность программы;
* более легкое тестирование программы путем изоляции компонента или проверки его зависимостей и обеспечения взаимодействия компонентов через контракты.

Инверсия управления может быть достигнута с помощью различных механизмов, таких как: шаблон проектирования “Стратегия”, шаблон “Локатор служб”, шаблон “Фабрика” и внедрение зависимостей (DI).

*Dependency Injection (DI)*

Внедрение зависимостей - это шаблон проектирования для реализации IoC, где инвертируемым элементом контроля является зависимостей объекта.

Соединение объектов с другими объектами или «внедрение» объектов в другие объекты выполняется контейнером IoC, а не самими объектами.

В Spring Framework инверсия контроля достигается именно внедрением зависимостей. В Spring Framework инверсия контроля и внедрение зависимостей считаются одним и тем же.

В Spring Framework внедрение зависимостей описывается как процесс, посредством которого объекты определяют свои зависимости (то есть другие объекты, с которыми они работают) только через аргументы конструктора, аргументы фабричного метода или свойства, которые устанавливаются в экземпляре объекта после того, как он создан или возвращен из метода фабрики. После чего контейнер IoC внедряет эти зависимости в компонент при его создании.

Внедрение зависимостей в Spring Framework может быть сделано через конструкторы, сеттеры или поля.

== Что такое IoC контейнер?

В Spring Framework контейнер отвечает за создание, настройку и сборку объектов, известных как бины, а также за управление их жизненным циклом. Он представлен интерфейсом ApplicationContext.

Spring Framework предоставляет несколько реализаций интерфейса ApplicationContext:

* ClassPathXmlApplicationContext и FileSystemXmlApplicationContext - для автономных приложений;
* WebApplicationContext - для веб-приложений;
* AnnotationConfigApplicationContext - для обычной Java-конфигурации, в качестве аргумента которому передается класс, либо список классов с аннотацией @Configuration, либо с любой другой аннотацией JSR-330, в том числе и @Component.

Контейнер получает инструкции о том, какие объекты создавать, настраивать и собирать, через метаданные конфигурации, которые представлены в виде XML, Java-аннотаций или Java-кода:

* XML - Метаданные считываются из файла с расширением *.xml;
* Java-аннотации - В Spring 2.5 появилась поддержка метаданных конфигурации на основе аннотаций, которая использует данные байт-кода для подключения компонентов. Вместо того, чтобы использовать XML-файл для описания связывания компонентов, разработчик перемещает конфигурацию в сам класс компонента, используя аннотации к соответствующему классу, методу или полю. При этом, сам XML-файл с базовыми настройками остаётся. Контейнер считывает аннотации перед считыванием XML, поэтому, если бин конфигурируется и через аннотации, и через XML-файл, то настройки XML переопределят настройки аннотаций.
* Java-код - Начиная со Spring 3.0, используя Java-код, а не файлы XML, мы можем определять настройки в специальном классе, помеченном аннотацией @Configuration. Появились аннотации @Configuration, @Bean, @Import и @DependsOn и т.д.

== Что такое Bean в спринге?

В Spring объекты, образующие основу приложения и управляемые контейнером Spring IoC, называются бинами. Бин - это объект, который создается, собирается и управляется контейнером Spring IoC. Иначе говоря, бин - это просто один из множества объектов в вашем приложении. Бины и их зависимости отражаются в метаданных конфигурации, используемых контейнером.

== Расскажите про аннотацию @Bean?

Это аннотация Spring Framework, она используется над методом для указания того, что данный метод создает, настраивает и инициализирует новый объект, управляемый Spring IoC контейнером. Такие методы можно использовать как в классах с аннотацией @Configuration, так и в классах с аннотацией @Component (или её наследниках).

Позволяет дополнительно определить у бина:

* name - имя (уникальный идентификатор) бина
* initMethod - имя метода для вызова во время инициализации бина
* destroyMethod - имя метода для вызова во время удаления бина из контекста
* autowireCandidate - является ли этот бин кандидатом на автоматическое внедрение в другой бин.

Классы, аннотированные @Configuration, проксируются через CGLIB.

Классы @Component или обычные классы не проксируются и не перехватывают вызовы методов с аннотациями @Bean, что означает, что вызовы не будут маршрутизироваться через контейнер и каждый раз будет возвращаться новый экземпляр бина.

Также методы бинов, вызывая друг друга в таких классах, не будут создавать бины, а будет просто выполняться код метода, ведь в данном случае они отработают не через прокси.

Имена бинов

Имя бина, которое в контейнере является одновременно и его уникальным идентификатором, по умолчанию соответствует имени метода, аннотированного @Bean. Но если требуется указать иное имя, то можно использовать атрибут name, который принимает String. Однако, атрибут name также может принимать массив String, что позволяет использовать несколько имен. Первый элемент массива будет являться именем и уникальным идентификатором бина, а остальные будут его псевдонимами.

== Что такое CGLIB?

Классы в Java загружаются динамически во время выполнения. Cglib использует эту особенность языка Java, чтобы сделать возможным добавление новых классов в уже запущенную программу Java.

Hibernate использует cglib для генерации динамических прокси. Например, он не вернет полный объект, хранящийся в базе данных, но вернет инструментальную версию сохраненного класса, которая лениво загружает значения из базы данных по требованию.

Популярные макетные фреймворки, такие как Mockito, используют cglib для макетных методов. Макет - это инструментальный класс, в котором методы заменяются пустыми реализациями.

== Расскажите про аннотацию @Component?

Это аннотация Spring Framework, ею мы помечаем класс, если хотим, чтобы из этого класса был создан бин. Именно эту аннотацию ищет Spring Framework, когда сканирует наши классы. Можно указать имя (Id) для создаваемого бина, а можно не указывать, тогда по умолчанию именем будет название класса с маленькой буквы.

Аннотация @Component имеет наследников: @Repository, @Service и @Controller. Все они являются частными случаями использования @Component для слоёв DAO, сервиса и контроллера MVC соответственно. Также эти аннотации могут иметь дополнительный смысл в будущих версиях Spring Framework. В остальных же случаях достаточно использовать аннотацию @Component.

Итог:

* @Component - Spring определяет этот класс как кандидата для создания bean.
* @Service - класс содержит бизнес-логику и вызывает методы на уровне хранилища. Ничем не отличается от классов с @Component.
* @Repository - указывает, что класс выполняет роль хранилища (объект доступа к DAO).  Задача @Repository заключается в том, чтобы отлавливать определенные исключения пробрасывать их как одно непроверенное исключение Framework. Для этого Spring оборачивает эти классы в прокси, и в контекст должен быть PersistenceExceptionTranslationPostProcessor.
* @Controller - указывает, что класс выполняет роль контроллера MVC. DispatcherServlet просматривает такие @RequestMapping.

== Чем отличаются аннотации @Bean и @Component?

Аннотация @Component (как и @Service и @Repository) используется для автоматического обнаружения и автоматической настройки бинов в ходе сканирования путей к классам.

Аннотация @Bean используется для явного объявления бина, а не для того, чтобы Spring делал это автоматически в ходе сканирования путей к классам:

* прописываем вручную метод для создания бина;
* делает возможным объявление бина независимо объявления класса, что позволяет использовать классы из сторонних библиотек, у которых мы не можем указать аннотацию @Component;
* с аннотацией @Bean можно настроить initMethod, destroyMethod, autowireCandidate, делая создание бина более гибким.

== Расскажите про аннотации @Service и @Repository. Чем они отличаются?

@Service и @Repository являются частными случаями @Component. Технически они одинаковы, но мы используем их для разных целей.

Задача @Repository заключается в том, чтобы отлавливать определенные исключения персистентности и пробрасывать их как одно непроверенное исключение Spring Framework. Для этого в контекст должен быть добавлен класс PersistenceExceptionTranslationPostProcessor.

Мы помечаем бины аннотацией @Service, чтобы указать, что они содержат бизнес-логику. Так что нет никакого другого предназначения, кроме как использовать ее на уровне сервиса.

== Расскажите про аннотацию @Autowired

Это аннотация Spring Framework, ею помечают конструктор, поле, сеттер-метод или метод конфигурации, сигнализируя, что им обязательно требуется внедрение зависимостей.

Если в контейнере не будет обнаружен необходимый для вставки бин, то будет выброшено исключение, либо можно указать @Autowired(required = false), означающее, что внедрение зависимости в данном месте не обязательно.

Аннотация @Autowired является альтернативой Java-аннотации @Inject, не имеющей required = false (зависимость должна быть обязательно внедрена).

Начиная со Spring Framework 4.3, аннотация @Autowired для конструктора больше не требуется, если целевой компонент определяет только один конструктор. Однако, если доступно несколько конструкторов и нет основного/стандартного конструктора, по крайней мере один из конструкторов должен быть аннотирован @Autowired, чтобы указать контейнеру, какой из них использовать.

По умолчанию Spring распознает объекты для вставки по типу. Если в контейнере доступно более одного бина одного и того же типа, будет исключение. Во избежание этого можно указать аннотацию Spring Framework - @Qualifier(""fooFormatter""), где fooFormatter - это имя (Id) одного из нескольких бинов одного типа, находящихся в контейнере и доступных для внедрения.

== Расскажите про аннотацию @Resource

Java-аннотация @Resource может применяться к классам, полям и методам. Она пытается получить зависимость: сначала по имени, затем по типу, затем по описанию (Qualifier). Имя извлекается из имени аннотируемого сеттера или поля, либо берется из параметра name. При аннотировании классов имя не извлекается из имени класса по умолчанию, поэтому оно должно быть указано явно.

Указав данную аннотацию у полей или методов с аргументом name, в контейнере будет произведен поиск компонентов с данным именем, и в контейнере должен быть бин с таким именем:

<i><u>@Resource(name=""namedFile"")</u>
<u>private File defaultFile;</u></i>

Если указать ее без аргументов, то Spring Framework поможет найти бин по типу.

Если в контейнере несколько бинов-кандидатов на внедрение, то нужно использовать аннотацию @Qualifier:

<i><u>@Resource</u>
<u>@Qualifier(""defaultFile"")</u>
<u>private File dependency1;</u>
<u>@Resource</u>
<u>@Qualifier(""namedFile"")</u>
<u>private File dependency2;</u></i>

Разница с @Autowired:

* ищет бин сначала по имени, а потом по типу
* не нужна дополнительная аннотация для указания имени конкретного бина
* @Autowired позволяет отметить место вставки бина как необязательное @Autowired(required = false)
* при замене Spring Framework на другой фреймворк, менять аннотацию @Resource не нужно

== Расскажите про аннотацию @Inject

Java-аннотация @Inject входит в пакет javax.inject и, чтобы её использовать, нужно добавить зависимость:

<i>&lt;dependency&gt;
&lt;groupId&gt;javax.inject&lt;/groupId&gt;
&lt;artifactId&gt;javax.inject&lt;/artifactId&gt;
&lt;version&gt;1&lt;/version&gt;
&lt;/dependency&gt;</i>

Размещается над полями, методами, и конструкторами с аргументами. @Inject как и @Autowired в первую очередь пытается подключить зависимость по типу, затем по описанию и только потом по имени. Это означает, что даже если имя переменной ссылки на класс отличается от имени компонента, но они одинакового типа, зависимость все равно будет разрешена:

<i><u>@Inject</u>
<u>private ArbitraryDependency fieldInjectDependency;</u></i>

отличается от имени компонента, настроенного в контексте приложения:

<i><u>@Bean</u>
<u>public ArbitraryDependency injectDependency() {</u>
<u>ArbitraryDependency injectDependency = new ArbitraryDependency();</u>
<u>return injectDependency;</u>
<u>}</u></i>

Разность имён injectDependency и fieldInjectDependency не имеет значения, зависимость будет подобрана по типу ArbitraryDependency.

Если в контейнере несколько бинов-кандидатов на внедрение, то нужно использовать аннотацию @Qualifier:

<i><u>@Inject</u>
<u>@Qualifier(""defaultFile"")</u>
<u>private ArbitraryDependency defaultDependency;</u>
<u>@Inject</u>
<u>@Qualifier(""namedFile"")</u>
<u>private ArbitraryDependency namedDependency;</u></i>

При использовании конкретного имени (Id) бина используем @Named:

<i><u>@Inject</u>
<u>@Named(""yetAnotherFieldInjectDependency"")</u>
<u>private ArbitraryDependency yetAnotherFieldInjectDependency;</u></i>

== Расскажите про аннотацию @Lookup

Обычно бины в приложении Spring являтся синглтонами, и для внедрения зависимостей мы используем конструктор или сеттер.

Но бывает и другая ситуация: имеется бин Car – синглтон (singleton bean), и ему требуется каждый раз новый экземпляр бина Passenger. То есть Car – синглтон, а Passenger – так называемый прототипный бин (prototype bean). Жизненные циклы бинов разные. Бин Car создается контейнером только раз, а бин Passenger создается каждый раз новый – допустим, это происходит каждый раз при вызове какого-то метода бина Car. Вот здесь-то и пригодится внедрение бина с помощью Lookup-метода. Оно происходит не при инициализации контейнера, а позднее: каждый раз, когда вызывается метод.

Суть в том, что мы создаем метод-заглушку в бине Car и помечаем его специальным образом – аннотацией @Lookup. Этот метод должен возвращать бин Passenger, каждый раз новый. Контейнер Spring под капотом создаст прокси-подкласс и переопределит этот метод и будет нам выдавать новый экземпляр бина Passenger при каждом вызове аннотированного метода. Даже если в нашей заглушке он возвращает (а так и надо делать - всё равно этот метод будет переопределен в прокси-подклассе):

<i>@Component</i></div><i>
public class Car {</i></div><i>
@Lookup</i></div><i>
public Passenger createPassenger() {</i></div><i>
return null;</i></div><i>
}</i></div><i>
public String drive(String name) {</i></div><i>
Passenger passenger = createPassenger();</i></div><i>
passenger.setName(name);</i></div><i>
return ""car with "" + passenger.getName();</i></div><i>
}</i></div><i>
}</i>

Допустим, в бине есть метод drive(), и при каждом вызове метода drive() бину Car требуется новый экземпляр бина Passenger – сегодня пассажир Петя, завтра – Вася. То есть бин Passenger прототипный. Для получения этого бина надо написать метод-заглушку createPassenger() и аннотировать его с помощью @Lookup.

Контейнер Spring переопределит этот метод-заглушку и будет выдавать при его вызове каждый раз новый экземпляр Passenger.

Осталось только определить бин Passenger как прототипный:

----
@Component
@Scope(""prototype"")
public class Passenger {

private String name;

public String getName() {

return name;

}

public void setName(String name) {

this.name = name;

}

}
----

Теперь при вызове метода drive() мы можем везти каждый раз нового пассажира. Имя его передается в аргументе метода drive(), и затем задается сеттером во вновь созданном экземпляре пассажира.

== Можно ли вставить бин в статическое поле? Почему?

Spring не позволяет внедрять бины напрямую в статические поля, например:

----
<i>@Component
public class TestDataInit {
@Autowired
private static OrderItemService orderItemService;
}</i>
----

Если вы распечатаете TestDataInit.orderItemService, там будет null. Это связано с тем, что, когда загрузчик классов загружает статические значения, контекст Spring ещё не загружен.

Чтобы исправить это, создайте нестатический сеттер-метод:

----
<i>@Component
public class TestDataInit {
private static OrderItemService orderItemService;
@Autowired
public void setOrderItemService(OrderItemService orderItemService) {
TestDataInit.orderItemService = orderItemService;
}
}</i>
----

== Расскажите про аннотации @Primary и @Qualifier

Мы используем @Primary, чтобы отдавать предпочтение бину, когда есть несколько бинов одного типа. Эта аннотация полезна, когда мы хотим указать, какой компонент определенного типа должен внедряться по умолчанию.

----
<i>@Configuration
public class Config {
@Bean
public Employee JohnEmployee() {
return new Employee(""John"");
}
@Bean
@Primary
public Employee TonyEmployee() {
return new Employee(""Tony"");
}
}</i>
----

или с аннотацией @Component

<i>@Component
public class DepartmentManager implements Manager {
@Override
public String getManagerName() {
return ""Department manager"";
}
}
@Component
@Primary
public class GeneralManager implements Manager {
@Override
public String getManagerName() {
return ""General manager"";
}
}</i>

Теперь, где будут требоваться бины типа Employee и Manager будут созданы и внедрены TonyEmployee и GeneralManager.

Когда есть несколько бинов одного типа, подходящих для внедрения, аннотация @Qualifier позволяет указать в качестве аргумента имя конкретного бина, который следует внедрить.

Стоит отметить, что если присутствуют аннотации @Qualifier и @Primary, то аннотация @Qualifier будет иметь приоритет. По сути, @Primary определяет значение по умолчанию, в то время как @Qualifier более специфичен.

== Как заинжектить примитив?

Для этого можно использовать аннотацию @Value. Можно ставить над полем, конструктором, методом.

Такие значения можно получать из property файлов, из бинов, и т.п.

@Value(""""${some.key}"""")

public String stringWithDefaultValue;

В эту переменную будет внедрена строка, например из property или из view.

Кроме того, для внедрения значений мы можем использовать язык SpEL (Spring Expression Language)

== Как заинжектить коллекцию?

Если внедряемый объект массив, коллекция, или map с дженериком, то используя аннотацию @Autowired, Spring внедрит все бины подходящие по типу в этот массив(или другую структуру данных).

<i>@Autowired</i>
<i>List&lt;Employee&gt; employees // создастья лист с бином эмлои если он у нас есть </i>

В случае с map ключом будет имя бина.

Используя аннотацию @Qualifier можно настроить тип искомого бина.

Бины могут быть упорядочены, когда они вставляются в списки (не Set или Map) или массивы. Поддерживаются как аннотация @Order, так и интерфейс Ordered.

Метод который возвращает коллекцию с аннотацией @Bean

== Расскажите про аннотацию @Conditional

<a href=""https://www.baeldung.com/spring-conditional-annotations"">https://www.baeldung.com/spring-conditional-annotations</a> - подробно

Spring предоставляет возможность на основе вашего алгоритма включить или выключить определение бина или всей конфигурации через @Conditional, в качестве параметра которой указывается класс, реализующий интерфейс Condition, с единственным методом

<i>matches(ConditionContext var1, AnnotatedTypeMetadata var2) - </i>возвращающий boolean.

Для создания более сложных условий можно использовать классы AnyNestedCondition, AllNestedConditions и NoneNestedConditions.

Аннотация @Conditional указывает, что компонент имеет право на регистрацию в контексте только тогда, когда все условия соответствуют.

Условия проверяются непосредственно перед тем, как должен быть зарегистрирован BeanDefinition компонента, и они могут помешать регистрации данного BeanDefinition. Поэтому нельзя допускать, чтобы при проверке условий мы взаимодействовали с бинами, которых еще не существует, с их BeanDefinition-ами можно.

Для того, чтобы проверить несколько условий, можно передать в @Conditional несколько классов с условиями:

@Conditional(HibernateCondition.class, OurConditionClass.class)

Если класс @Configuration помечен как @Conditional, то на все методы @Bean, аннотации @Import и аннотации @ComponentScan, связанные с этим классом, также будут распространяться указанные условия.

Для более детальной настройки классов, аннотированных @Configuration, предлагается использовать интерфейс ConfigurationCondition.

В одном классе - одно условие. Для создания более сложных условий можно использовать классы AnyNestedCondition, AllNestedConditions и NoneNestedConditions.

В Spring Framework имеется множество готовых аннотаций (и связанных с ними склассами-условиями, имплементирующими интерфейс Condition), которые можно применять совместно над одним определением бина:

<img src=""paste-76100e152911bdf394b166343f288c1d048cf8b8.png"">

== Расскажите про аннотацию @Profile

Профили - это ключевая особенность Spring Framework, позволяющая нам относить наши бины к разным профилям (логическим группам), например, dev, test, prod.

Мы можем активировать разные профили в разных средах, чтобы загрузить только те бины, которые нам нужны.

Используя аннотацию @Profile, мы относим бин к конкретному профилю. Её можно применять на уровне класса или метода. Аннотация @Profile принимает в качестве аргумента имя одного или нескольких профилей. Она фактически реализована с помощью гораздо более гибкой аннотации @Conditional.

Ее можно ставить на @Configuration и Component классы.

В качестве быстрого обозначения имена профилей также могут начинаться с оператора NOT, например «!dev», чтобы исключить их из профиля.

По умолчанию, если профиль бина не определен, то он относится к профилю “default”. Spring также предоставляет способ установить профиль по умолчанию, когда другой профиль не активен, используя свойство «spring.profiles.default».

== Расскажите про ApplicationContext и BeanFactory, чем отличаются? В каких случаях что стоит использовать?

<a href=""https://www.baeldung.com/spring-beanfactory-vs-applicationcontext"">https://www.baeldung.com/spring-beanfactory-vs-applicationcontext</a> - подробнее

BeanFactory

BeanFactory - это самая базовая версия IOC контейнера.

ApplicationContext

ApplicationContext - это наследник BeanFactory и он расширяет возможности BeanFactory.

ApplicationContext vs. BeanFactory</div>

* ApplicationContext загружает все бины при запуске, а BeanFactory - по требованию.
* ApplicationContext расширяет BeanFactory и предоставляет функции, которые подходят для корпоративных приложений:</li>

* поддержка  внедрения зависимостей на основе аннотаций;
* удобный  доступ к MessageSource (для использования в интернационализации);
* публикация  ApplicationEvent - для бинов, реализующих интерфейс ApplicationListener,  с помощью ApplicationEventPublisher;
* простая  интеграция с функциями Spring AOP.
 <li>ApplicationContext поддерживает автоматическую регистрацию BeanPostProcessor и BeanFactoryPostProcessor. Поэтому всегда желательно использовать ApplicationContext, потому что Spring 2 (и выше) интенсивно использует BeanPostProcessor.
* ApplicationContext поддерживает практически все типы scope для бинов, а BeanFactory поддерживает только два - Singleton и Prototype.
* В BeanFactory не будут работать транзакции и Spring AOP. Это может привести к путанице, потому что конфигурация с виду будет корректной.

== Расскажите про жизненный цикл бина, аннотации @PostConstruct и @PreDestroy()

"<a href=""https://stackoverflow.com/questions/30455536/beanfactorypostprocessor-and-beanpostprocessor-in-lifecycle-events"">https://stackoverflow.com/questions/30455536/beanfactorypostprocessor-and-beanpostprocessor-in-lifecycle-events</a> - про beanFPP/beanPP

<a href=""https://habr.com/ru/post/222579/"">https://habr.com/ru/post/222579/</a> - подробно и хорошо объяснено

<i>BeanDefinition</i> — это специальный интерфейс, через который можно получить доступ к метаданным будущего бина. В зависимости от того, какая у вас конфигурация, будет использоваться тот или иной механизм парсирования конфигурации.

* Загрузка BeanDefenition (описание бинов), создание графа зависимостей(между бинами)
* Создание и запуск BeanFactoryPostProcessors
* Создание бинов
* Spring внедряет значения и зависимости в свойства бина
* Если бин реализует метод setBeanName() из интерфейса NameBeanAware, то ID бина передается в метод
* Если бин реализует BeanFactoryAware, то Spring устанавливает ссылку на bean factory через setBeanFactory() из этого интерфейса.
* Если бин реализует интерфейс ApplicationContextAware, то Spring устанавливает ссылку на ApplicationContext через setApplicationContext().
* BeanPostProcessor это специальный интерфейс(о нем ниже), и Spring позволяет бинам имплементировать этот интерфейс. Реализуя метод postProcessBeforeInitialization(), можно изменить экземпляр бина перед его(бина) инициализацией(установка свойств и т.п.)
* Если определены методы обратного вызова, то Spring вызывает их. Например, это метод, аннотированный @PostConstruct или метод initMethod из аннотации @Bean.
* Теперь бин готов к использованию. Его можно получить с помощью метода ApplicationContext#getBean().
* После того как контекст будет закрыт(метод close() из ApplicationContext), бин уничтожается.
* Если в бине есть метод, аннотированный @PreDestroy, то перед уничтожением вызовется этот метод. Если бин имплементирует DisposibleBean, то Spring вызовет метод destroy(), чтобы очистить ресурсы или убить процессы в приложении. Если в аннотации @Bean определен метод destroyMethod, то вызовется и он.

<img src=""paste-28f62fb27ca70ec2486f4d93e133965cff2db513.png"">

<img src=""paste-f712ac186b1df05dfab31686bcd71319315d194b.png"">

== Расскажите про скоупы бинов? Какой скоуп используется по умолчанию? Что изменилось в пятом спринге?

Spring Framework поддерживает шесть scopes:</div>

* singleton
* prototype
* request
* session
* application
* websocket
* не активированный по умолчанию Custom thread scope.

С 3 по 6 доступны только в веб-приложениях. Мы также можем создать свой собственный scope.

Singleton

Является дефолтным scope. В контейнере будет создан только один бин, и все запросы на него будут возвращать один и тот же бин. Этот бин хранится в контейнере, и все запросы и ссылки на этот бин возвращают закэшированный экземпляр.

Prototype

Scope “prototype” приводит к созданию нового бина каждый раз, когда он запрашивается.

Для бинов со scope “prototype” Spring не вызывает метод destroy(). Spring не берет на себя контроль полного жизненного цикла бина со scope @prototype”. Spring не хранит такие бины в своём контексте ( контейнере), а отдаёт их клиенту и больше о них не заботится (в отличие от синглтон-бинов).

И 4 области видимости в веб-приложении.

Request - Область видимости — 1 HTTP запрос. Контейнер создает новый экземпляр для каждого HTTP-запроса. Любое изменение состояния одного  кземпляра не будет видимодругим экземплярам. Эти экземпляры уничтожаются, как только HTTP-запрос завершен.

@Scope(""request"")

@RequestScope

Session - Область видимости — 1 сессия. На каждую сессию создается новый бин. Бин создается в одном экземпляре для одной HTTP-сессии. Все HTTP-запросы в пределах времени жизни одной сессии будут иметь доступ к одному и тому же бину.

@Scope(""session"")

@SessionScope

Application - Область видимости — жизненный цикл ServletContext

Бин со scope “application” создается в одном экземпляре для жизненного цикла ServletContext. Виден как атрибут ServletContext. Синглтон - в одном экземпляре для ApplicationContext.

@Scope(""application"")

@ApplicationScope

WebSocket - Область видимости — жизненный цикл WebSocket

Бин со scope “websocket” создается в одном экземпляре для определенного сеанса WebSocket. Один и тот же бин возвращается всякий раз, когда к нему обращаются в течение всего сеанса WebSocket.

@Scope(""websocket"")

В пятой версии Spring Framework не стало Global session scope. И появились Application и WebSocket

== Расскажите про аннотацию @ComponentScan

Аннотация @ComponentScan используется вместе с аннотацией @Configuration для указания пакетов, которые мы хотим сканировать на наличие компонентов, из которых нужно сделать бины.

@ComponentScan без аргументов указывает Spring по умолчанию сканировать текущий пакет и все его подпакеты. Текущий пакет - тот, в котором находится файл конфигурации с этой самой аннотацией @ComponentScan. В данном случае в контейнер попадут:

* бин конфигурационного класса;
* бины, объявленные в конфигурационном классе с помощью @Bean;
* все бины из пакета и его подпакетов.

Если указать @ComponentScan с атрибутом basePackages, то это изменит пакет по умолчанию на указанный:

Если указать @ComponentScan с атрибутом excludeFilters, то это позволит использовать фильтр и исключить ненужные классы из процесса сканирования:

@ComponentScan(excludeFilters =

@ComponentScan.Filter(type=FilterType.REGEX,

pattern=""com\\.baeldung\\.componentscan\\.springapp\\.flowers\\..*""))

== Как спринг работает с транзакциями? Расскажите про аннотацию @Transactional.

marcobehler.com/guides/spring-transaction-management-transactional-in-depth

Коротко: Spring создает прокси для всех классов, помеченных @Transactional (либо если любой из методов класса помечен этой аннотацией), что позволяет вводить транзакционную логику до и после вызываемого метода. При вызове такого метода происходит следующее: proxy, который создал Spring, создаёт persistence context (или соединение с базой), открывает в нём транзакцию и сохраняет всё это в контексте нити исполнения (натурально, в ThreadLocal). По мере надобности всё сохранённое достаётся и внедряется в бины. Таким образом, если в вашем коде есть несколько параллельных нитей, у вас будет и несколько параллельных транзакций, которые будут взаимодействовать друг с другом согласно уровням изоляции.

Что произойдёт, если один метод с @Transactional вызовет другой метод с @Transactional? Если это происходит в рамках одного сервиса, то второй транзакционный метод будет считаться частью первого, так как вызван у него изнутри, а так как спринг не знает о внутреннем вызове, то не создаст прокси для второго метода. То есть у них будет ОДНА транзакция.

Что произойдёт, если один метод БЕЗ @Transactional вызовет другой метод с @Transactional? Так как spring не знает о внутреннем вызове, то не создаст прокси для второго метода. То есть транзакция запущена НЕ БУДЕТ.

Будет ли транзакция откачена, если будет брошено исключение, которое указано в контракте метода? Если в контракте описано это исключение, то она не откатится. Unchecked исключения в транзакционном методе можно ловить, а можно и не ловить.

Значения атрибута propagation у аннотации:

* REQUIRED - транзакция требуется, сгодится уже открытая, если есть, или новая
* SUPPORTS - если транзакция открыта, она будет использована, если нет, метод исполнится нетранзакционно (метод не будет проксирован)
* MANDATORY - обязательно наличие открытой транзакции, если её нету, будет выброшено исключение
* REQUIRED_NEW - останавливает текущую транзакцию и исполняет метод в новой транзакции
* NOT_SUPPORTED - останавливает текущую транзакцию и исполняет метод нетранзакционно
* NEVER - транзакции не должно быть
* NESTED - обращает к savepoint если какая-то непредвиденная ситуация

== Расскажите про аннотации @Controller и @RestController. Чем они отличаются? Как вернуть ответ со своим статусом (например 213)?

@Controller

@Controller помечает класс как контроллер HTTP-запросов. @Controller обычно используется в сочетании с аннотацией используемой в методах обработки запросов. Это просто дочерняя аннотация аннотации @Component и позволяет автоматически определять классы при сканировании пакетов.

@RestController

Аннотация @RestController была введена в Spring 4 для упрощения создания RESTful веб-сервисов. Это удобная аннотация, которая объединяет @Controller и @ResponseBody, что устраняет необходимость аннотировать каждый метод обработки запросов аннотацией @ResponseBody.

@ResponseBody сообщает контроллеру, что возвращаемый объект автоматически сериализуется в json или xml и передается обратно в объект HttpResponse. Контроллер использует Jackson message конвертации входящих/исходящих данных. Как правило целевые данные представлены в json или xml.

ResponseEntity

Данный класс используется для формирования ответа пользовательскими параметрами (заголовки, код статуса и тело ответа). ResponseEntity необходим, только если мы хотим кастомизировать ответ. Во всех остальных случаях достаточно использовать @ResponseBody.

Если мы хотим использовать ResponseEntity, то просто должны вернуть его из метода, Spring позаботится обо всем остальном.

== Что такое ViewResolver?

Model

Интерфейс, лежит в пакете spring-context. В методах контроллера мы можем использовать объекты Model для того, чтобы складывать туда данные, предназначенные для формирования представлений. Кроме того, в Model мы можем передать даже Map с атрибутами.

ModelMap

Этот класс наследуется от LinkedHashMap&lt;String, Object&gt; и по сути служит общим контейнером модели для Servlet MVC, но не привязан к нему, и лежит в пакете spring-context. Имеет все преимущества LinkedHashMap плюс несколько удобных методов.

ModelAndView

Этот класс лежит в пакете spring-webmvc и может одновременно хранить модели и представление, чтобы контроллер мог отдавать их в одном возвращаемом значении. Внутри содержит поле private Object view, куда записывает нужное представление, а также поле private ModelMap model, куда и складывает все атрибуты модели.

== Расскажите про паттерн MVC, как он реализован в Spring?

MVC (Model-View-Controller)

Это шаблон проектирования программного обеспечения, который делит программную логику на три отдельных, но взаимосвязанных компонента: модель, представление и контроллер — таким образом, что модификация каждого компонента может осуществляться независимо.

* Модель (Model) предоставляет данные и реагирует на команды контроллера, изменяя своё состояние. Она содержит всю бизнес-логику приложения.
* Представление (View) отвечает за отображение пользователю данных из модели в нужном формате.
* Контроллер (Controller) содержит код, который отвечает за обработку действий пользователя и обменивается данными с моделью (любое действие пользователя в системе обрабатывается в контроллере).


Основная цель следования принципам MVC — отделить реализацию бизнес-логики приложения (модели) от ее визуализации (вида). Такое разделение повысит возможность повторного использования кода.

Польза применения MVC наиболее наглядна в случаях, когда пользователю нужно предоставлять одни и те же данные в разных формах. Например, в виде таблицы, графика или диаграммы (используя различные виды). При этом, не затрагивая реализацию видов, можно изменить реакции на действия пользователя (нажатие мышью на кнопке, ввод данных).

Spring Web MVC

Spring MVC - это оригинальный веб-фреймворк, основанный на Servlet API, предназначенный для создания веб-приложений на языке Java, с использованием двух самых популярных шаблонов проектирования - Front controller и MVC.

Front controller (Единая точка входа) - паттерн, где центральный сервлет, DispatcherServlet, принимает все запросы и распределяет их между контроллерами, обрабатывающими разные URL.

Spring MVC реализует четкое разделение задач, что позволяет нам легко разрабатывать и тестировать наши приложения. Данные задачи разбит между разными компонентами: Dispatcher Servlet, Controllers, View Resolvers, Views, Models, ModelAndView, Model and Session Attributes, которые полностью независимы друг от друга, и отвечают только за одно направление. Поэтому MVC дает нам довольно большую гибкость. Он основан на интерфейсах (с предоставленными классами реализации), и мы можем настраивать каждую часть фреймворка с помощью пользовательских интерфейсов.

Основные интерфейсы для обработки запросов:

HandlerMapping. По запросу определяет, какие перехватчики (interceptors) с пре- и пост-процессорной обработкой запроса должны отработать, а затем решает, какому контроллеру (обработчику) нужно передать данный запрос на исполнение. Процесс их определения основан на некоторых критериях, детали которых зависят от реализации HandlerMapping.

Двумя основными реализациями HandlerMapping являются RequestMappingHandlerMapping (который поддерживает аннотированные методы @RequestMapping) и SimpleUrlHandlerMapping (который поддерживает явную регистрацию путей URI для обработчиков).

HandlerAdapter. Помогает DispatcherServlet вызвать обработчик, сопоставленный с запросом. Для вызова аннотированного контроллера необходимо прочитать аннотации над методами контроллера и принять решение. Основная цель HandlerAdapter - избавить DispatcherServlet от этой рутины.

ViewResolver. Сопоставляет имена представлений, возвращаемых методами контроллеров, с фактическими представлениями (html-файлами).

View. Отвечает за возвращение ответа клиенту в виде текстов и изображений. Используются встраиваемые шаблонизаторы (Thymeleaf, FreeMarker и т.д.), так как у Spring нет родных. Некоторые запросы могут идти прямо во View, не заходя в Model, другие проходят через все слои.

LocaleResolver. Определение часового пояса и языка клиента для того, чтобы предложить представления на его языке.

MultipartResolver. Обеспечивает Upload — загрузку на сервер локальных файлов клиента. По умолчанию этот интерфейс не включается в приложении и необходимо указывать его в файле конфигурации. После настройки любой запрос о загрузке будет отправляться этому интерфейсу.

FlashMapManager. Сохраняет и извлекает «входной» и «выходной» FlashMap, который можно использовать для передачи атрибутов из одного запроса в другой, обычно через редирект.

<img src=""clip_image002-bd34790f3b2fe74f73f0b55a545d3591ee5f7762.gif"">

Ниже приведена последовательность событий, соответствующая входящему HTTP-запросу:

* После получения HTTP-запроса DispatcherServlet обращается к интерфейсу HandlerMapping, который определяет, какой Контроллер (Controller) должен быть вызван, после чего HandlerAdapter, отправляет запрос в нужный метод Контроллера.

* Контроллер принимает запрос и вызывает соответствующий служебный метод, основанный на GET, POST и т.д. Вызванный метод формирует данные Модели

* (например, набор данных из БД) и возвращает их в DispatcherServlet вместе с именем Представления (View) (как правило имя html-файла).

* При помощи интерфейса ViewResolver DispatcherServlet определяет, какое Представление нужно использовать на основании полученного имени и получает в ответе имя представления View.

* если это REST-запрос на сырые данные (JSON/XML), то DispatcherServlet сам его отправляет;

* если обычный запрос, то DispatcherServlet отправляет данные Модели в виде атрибутов в Представление (View) - шаблонизаторы Thymeleaf, FreeMarker и т.д., которые сами отправляют ответ.

Как мы видим все действия происходят через один единственный DispatcherServlet.

Сконфигурировать наше Spring MVC-приложение мы можем с помощью Java-config, добавив зависимость spring-webmvc и установив над классом конфигурации @EnableWebMvc, которая применит дефолтные настройки - зарегистрирует некоторые специальные бины из Spring MVC и адаптирует их к нашим бинам. Но, если требуется тонкая настройка, то мы можем имплементировать интерфейс необходимые методы.

Теперь нужно зарегистрировать конфигурацию в Spring Context это позволит сделать созданный нами класс MyWebAppInitializer, который нужно унаследовать от AbstractAnnotationConfigDispatcherServletInitializer, и передать в его методы классы нашей конфигурации RootConfig.class и App1Config.class:

<i>public class MyWebAppInitializer extends AbstractAnnotationConfigDispatcherServletInitializer
@Override
protected Class&lt;?&gt;[] getRootConfigClasses() {
return new Class&lt;?&gt;[] { RootConfig.class };
}
@Override
protected Class&lt;?&gt;[] getServletConfigClasses() { </i><i>return new Class&lt;?&gt;[] { App1Config.class };
}
@Override
protected String[] getServletMappings() {
return new String[] { ""/*"" };
}
}</i>

Своими внутренними методами он создает два экземпляра WebApplicationContext в виде объектов класса AnnotationConfigWebApplicationContext.

Если же у нас только один класс конфигурации, то его нужно передать в метод getRootConfigClasses(), а getServletConfigClasses() должен возвращать null.

== Расскажите про паттерн Front Controller, как он реализован в Spring?

Паттерн Front Controller обеспечивает единую точку входа для всех входящих запросов. Все запросы обрабатываются одним фрагментом кода, который затем может делегировать ответственность за обработку запроса другим объектам приложения. Он также обеспечивает интерфейс для общего поведения, такого как безопасность, интернационализация и передача определенных представлений определенным пользователям.

В Spring в качестве Front Controller выступает DispatcherServlet, все действия проходят через него. Как правило в приложении задаётся только один DispatcherServlet с маппингом “/”, который перехватывает все запросы. Это и есть реализация паттерна Front Controller.

Однако иногда необходимо определить два и более DispatcherServlet-а, которые будут отвечать за свой собственный функционал. Например, чтобы один обрабатывал REST-запросы с маппингом “/api”, а другой обычные запросы с маппингом “/default”. Spring предоставляет нам такую возможность, начала нужно понять, что:

Spring может иметь несколько контекстов одновременно. Одним из них будет корневой контекст, а все остальные контексты будут дочерними.

Все дочерние контексты могут получить доступ к бинам, определенным в корневом контексте, но не наоборот. Корневой контекст не может получить доступ к бинам дочерних контекстов.

Каждый дочерний контекст внутри себя может переопределить бины из корневого контекста. Каждый DispatcherServlet имеет свой дочерний контекст приложения. DispatcherServlet по сути является сервлетом (он расширяет HttpServlet), основной целью которого является обработка входящих веб-запросов, соответствующих настроенному шаблону URL. Он принимает входящий URI и находит правильную комбинацию контроллера и вида. Веб-приложение может определять любое количество DispatcherServlet-ов. Каждый из них будет работать в своем собственном пространстве имен, загружая свой собственный дочерний WebApplicationContext (на рисунке - Servlet WebApplicationContext) с вьюшками, контроллерами и т.д. Например, когда нам нужно в одном Servlet WebApplicationContext определить обычные контроллеры, а в другом REST - контроллеры.

<img alt=""HTTP запросы не делегируются контроллерам корневого WebApplicationContext -  CodeRoad"" src=""clip_image002-0cf1bc96e920e70891b366e362c235bb98faf51d.gif"">

WebApplicationContext расширяет ApplicationContext (создаёт и управляет бинами и т.д.), но помимо этого он имеет дополнительный метод getServletContext(), через который у него есть возможность получать доступ к ServletContext-у.

ContextLoaderListener создает корневой контекст приложения (на рисунке - Root WebApplicationContext) и будет использоваться всеми дочерними контекстами, созданными всеми DispatcherServlet. Напомню, что корневой контекст приложения будет общим и может быть только один. Root WebApplicationContext содержит компоненты, которые видны всем дочерним контекстам, такие как сервисы, репозитории, компоненты инфраструктуры и т.д. После создания корневого контекста приложения он сохраняется в ServletContext как атрибут, имя которого:

<i><u>WebApplicationContext.class.getName() + "".ROOT"" </u></i>

Чтобы из контроллера любого дочернего контекста обратиться к корневому контексту приложения, мы можем использовать класс WebApplicationContextUtils, содержащий статические методы:

@Autowired

ServletContext context;

ApplicationContext ac =WebApplicationContextUtils.getWebApplicationContext(context);

if(ac == null){

return ""root application context is null"";

}

ContextLoaderListener vs DispatcherServlet</div>

* ContextLoaderListener создает корневой контекст приложения.
* Каждый DispatcherServlet создаёт себе один дочерний контекст.
* Дочерние контексты могут обращаться к бинам, определенным в корневом контексте.
* Бины в корневом контексте не могут получить доступ к бинам в дочерних контекстах (напрямую).
* Все контексты добавляются в ServletContext.
* Мы можем получить доступ к корневому контексту, используя класс WebApplicationContextUtils.

<img alt=""ContextLoaderListener vs DispatcherServlet"" src=""clip_image004.jpg"">

== Что такое АОП? Как реализовано в спринге?

<a href=""https://habr.com/ru/post/428548/"">https://habr.com/ru/post/428548/</a> - подробно

Аспектно-ориентированное программирование (АОП) — это парадигма программирования, целью которой является повышение  модульности за счет разделения междисциплинарных задач. Это достигается путем добавления дополнительного поведения к существующему коду без изменения самого кода.

АОП предоставляет возможность реализации в одном месте сквозной логики - т.е. логики, которая применяется к множеству частей приложения - и обеспечения автоматического применения этой логики по всему приложению.

Подход Spring к АОП заключается в создании ""динамических прокси"" для целевых объектов и ""привязывании"" объектов к конфигурированному совету для выполнения сквозной логики.

== Расскажите про Concurrent Collections

"<img src=""Java 8 ConcurrentCollections.png"" width=""872"" data-editor-shrink=""true"">

Concurrent Collections — набор коллекций, более эффективно работающие в многопоточной среде нежели стандартные универсальные коллекции из java.util пакета. Вместо базового враппера Collections.synchronizedList с блокированием доступа ко всей коллекции используются блокировки по сегментам данных или же оптимизируется работа для параллельного чтения данных по wail-free алгоритмам.

Коллекции:

* *BlockingQueue*- При обработке больших потоков данных через очереди становится явно недостаточно использования ConcurrentLinkedQueue. Если потоки, разгребающие очередь перестанут справляться с наплывом данных, то можно довольно быстро схлопотать out of memory или перегрузить IO/Net настолько, что производительность упадет в разы пока не настанет отказ системы по таймаутам или из за отсутствия свободных дескрипторов в системе. Для таких случаев нужна queue с возможностью задать размер очереди или с блокировками по условиям. Тут то и появляется интерфейс BlockingQueue, открывающий дорогу к целому набору полезных классов. Помимо возможности задавать размер queue, добавились новые методы, которые реагируют по-разному на незаполнение или переполнение queue. Так, например, при добавлении элемента в переполненную queue, один метод кинет IllegalStateException, другой вернет false, третий заблокирует поток, пока не появится место, четвертый же заблокирует поток с таймаутом и вернет false, если место так и не появится. Также стоит отметить, что блокирующие очереди не поддерживают null значения, т.к. это значение используется в методе poll как индикатор таймаута.

* *ArrayBlockingQueue*- Класс блокирующей очереди, построенный на классическом кольцевом буфере. Помимо размера очереди, доступна возможность управлять «честностью» блокировок. Если fair=false (по умолчанию), то очередность работы потоков не гарантируется. Более подробно о «честности» можно посмотреть в описании ReentrantLock'a.

* *LinkedBlockingQueue*- Блокирующая очередь на связанных нодах, реализованная на «two lock queue» алгоритме: один лок на добавление, другой на вытаскивание элемента. За счет двух локов, по сравнению с ArrayBlockingQueue, данный класс показывает более высокую производительность, но и расход памяти у него выше. Размер очереди задается через конструктор и по умолчанию равен Integer.MAX_VALUE.


* *ConcurrentLinkedQueue*- в имплементации используется wait-free алгоритм от Michael &amp; Scott, адаптированный для работы с garbage collector'ом. Этот алгоритм довольно эффективен и, что самое важное, очень быстр, т.к. построен на CAS. Метод size() может работать долго, т.ч. лучше постоянно его не дергать.

* *ConcurrentLinkedDeque *- Deque расшифровывается как Double ended queue и читается как «Deck». Это означает, что данные можно добавлять и вытаскивать с обоих сторон. Соответственно, класс поддерживает оба режима работы: FIFO (First In First Out) и LIFO (Last In First Out). На практике, ConcurrentLinkedDeque стоит использовать только, если обязательно нужно LIFO, т.к. за счет двунаправленности нод данный класс проигрывает по производительности на 40% по сравнению с ConcurrentLinkedQueue.

* *CopyOnWrightArrayList *- потокобезопасный аналог ArrayList, реализованный с CopyOnWrite алгоритмом.

* *CopyOnWriteArraySet&lt;E&gt; *- имплементация Set, использующая за основу CopyOnWriteArrayList. В отличии от CopyOnWriteArrayList, дополнительных методов нет.

Название говорит само за себя. Все операции по изменению коллекции (add, set, remove) приводят к созданию новой копии внутреннего массива. Тем самым гарантируется, что при проходе итератором по коллекции не кинется ConcurrentModificationException. Следует помнить, что при копировании массива копируются только референсы (ссылки) на объекты (shallow copy), т.ч. доступ к полям элементов не thread-safe. CopyOnWrite коллекции удобно использовать, когда write операции довольно редки, например при реализации механизма подписки listeners и прохода по ним.


* *ConcurrentMap *- интерфейс, расширяющий Map несколькими дополнительными атомарными операциями.

* *ConcurrentHashMap *- в отличие от Hashtable и блоков synhronized на HashMap, данные представлены в виде сегментов, разбитых по hash'ам ключей. В результате, для доступ к данным лочится по сегментам, а не по одному объекту. В дополнение, итераторы представляют данные на определенный срез времени и не кидают ConcurrentModificationException.

* *ConcurrentNavigableMap *- расширяет интерфейс NavigableMap и вынуждает использовать ConcurrentNavigableMap объекты в качестве возвращаемых значений. Все итераторы декларируются как безопасные к использованию и не кидают ConcurrentModificationException.

* *ConcurrentSkipListMap *- является аналогом TreeMap с поддержкой многопоточности. Данные также сортируются по ключу и гарантируется усредненная производительность log(N) для containsKey, get, put, remove и других похожих операций.

* *ConcurrentSkipListSet *- имплементация Set интерфейса, выполненная на основе ConcurrentSkipListMap.

== Почему ключевое слово synchronized плохое решение?

Потому что многопоточность сводится к однопотоку, нет параллельного выполнения кода, все потоки ждут друг друга. Это обеспечивает безопасность, но код все равно как буд-то выполняется в одном потоке.

== Что такое канкаренси (java.utill.concurrent)?

*Concurrency* – это библиотека классов в Java, в которой собрали специальные классы, оптимизированные для работы из нескольких нитей. Эти классы собраны в пакете `java.util.concurrent`. Их можно схематично поделить по функциональному признаку следующим образом:

* *Concurrent Collections* — набор коллекций, более эффективно работающие в многопоточной среде нежели стандартные универсальные коллекции из `java.util` пакета. Вместо базового враппера `Collections.synchronizedList` с блокированием доступа ко всей коллекции используются блокировки по сегментам данных или же оптимизируется работа для параллельного чтения данных по wait-free алгоритмам.
* *Queues* — неблокирующие и блокирующие очереди с поддержкой многопоточности. Неблокирующие очереди заточены на скорость и работу без блокирования потоков. Блокирующие очереди используются, когда нужно «притормозить» потоки «Producer» или «Consumer», если не выполнены какие-либо условия, например, очередь пуста или перепонена, или же нет свободного «Consumer»'a.
* *Synchronizers* — вспомогательные утилиты для синхронизации потоков. Представляют собой мощное оружие в «параллельных» вычислениях.
* *Executors* — содержит в себе отличные фрейморки для создания пулов потоков, планирования работы асинхронных задач с получением результатов.
* *Locks* — представляет собой альтернативные и более гибкие механизмы синхронизации потоков по сравнению с базовыми `synchronized`, `wait`, `notify`, `notifyAll`.
* *Atomics* — классы с поддержкой атомарных операций над примитивами и ссылками.

 <img src=""ff8e9d719402e1b164febae3fd8c0ff5.png"">

== Какие классы из «канкаренси» (java.utill.concurrent) ты знаешь?

*ConcurrentHashMap&lt;K, V&gt;* — В отличие от Hashtable и блоков synhronized на HashMap, данные представлены в виде сегментов, разбитых по hash'ам ключей. В результате, для доступа к данным лочится по сегментам, а не по одному объекту. В дополнение, итераторы представляют данные на определенный срез времени и не кидают ConcurrentModificationException.

*AtomicBoolean, AtomicInteger, AtomicLong, AtomicIntegerArray, AtomicLongArray* — Что если в классе нужно синхронизировать доступ к одной простой переменной типа int? Можно использовать конструкции с synchronized, а при использовании атомарных операций set/get, подойдет также и volatile. Но можно поступить еще лучше, использовав новые классы Atomic*. За счет использования CAS, операции с этими классами работают быстрее, чем если синхронизироваться через synchronized/volatile. Плюс существуют методы для атомарного добавления на заданную величину, а также инкремент/декремент.

== Как устроен класс ConcurrentHashMap?

* <div style=""display: inline !important;"">В отличие от элементов `HashMap`, `Entry` в `ConcurrentHashMap` объявлены как `volatile`. Это важная особенность, также связанная с изменениями в JMM.

</div>
*  *Хэш-функция*

В чём необходимость усложнения хэш-функции? Таблицы в хэш-карте имеют длину, определяемую степенью двойки. Для хэш-кодов, двоичные представления которых не различаются в младшей и старшей позиции, мы будем иметь коллизии. Усложнение хэш-функции как раз решает данную проблему, уменьшая вероятность коллизий в карте.

</div>
*  *Сегменты*

Карта делится на N различных сегментов (16 по умолчанию, максимальное значение может быть 16-битным и представлять собой степень двойки). Каждый сегмент представляет собой потокобезопасную таблицу элементов карты. Увеличение количества сегментов будет способствовать тому, что операции модификации будут затрагивать различные сегменты, что уменьшит вероятность блокировок во время выполнения.

</div>
*  *ConcurrencyLevel*

Данный параметр влияет на использование картой памяти и количество сегментов в карте.

Количество сегментов будет выбрано как ближайшая степень двойки, большая чем concurrencyLevel. Занижение concurrencyLevel ведёт к тому, что более вероятны блокировки потоками сегментов карты при записи. Завышение показателя ведёт к неэффективному использованию памяти. Если лишь один поток будет изменять карту, а остальные будут производить чтение — рекомендуется использовать значение 1.

</div>
*  *Итого*

Итак, основные преимущества и особенности реализации `ConcurrentHashMap`:</div>

* Карта имеет схожий с `hashmap` интерфейс взаимодействия
* Операции чтения не требуют блокировок и выполняются параллельно
* Операции записи зачастую также могут выполняться параллельно без блокировок
* При создании указывается требуемый `concurrencyLevel`, определяемый по статистике чтения и записи


* Элементы карты имеют значение `value`, объявленное как `volatile`



"

== Что такое mutex?

*Мютекс* – это специальный объект для синхронизации нитей/процессов. Он может принимать два состояния – занят и свободен. Если упростить, то мютекс – это boolean-переменная, которая принимает два значения: занят(true) и свободен(false).

 Когда нить хочет монопольно владеть некоторым объектом, она помечает его мютекс занятым, а когда закончила работу с ним – помечает его мютекс свободным.

 Мютекс прикреплен к каждому объекту в Java. Прямой доступ к мютексу есть только у Java-машины. От программиста он скрыт.

== Что включает в себя аннотация @SpringBootApplication?



* @EnableAutoConfiguration: включить механизм автоконфигурации Spring Boot
* @ComponentScan: включить сканирование @Component для пакета, в котором находится приложение
* @Configuration: позволяет регистрировать дополнительные компоненты (beans) в контексте или импортировать дополнительные классы конфигурации



== Как записать PID (processor ID) и port приложения в файл при старте?



* *org.springframework.boot.system.ApplicationPidFileWriter* — это класс istener, который отвечает за запись PID (processor ID) в указанную конфигурацию.

Пример:

<i>@SpringBootApplication

@ComponentScan // Using a root package also allows the @ComponentScan annotation to be used without needing to specify a basePackage attribute

public class SpringBootConfig {     public static void main(String[] args) throws Exception {

 springApplication.addListeners(new ApplicationPidFileWriter());     // register PID write to spring boot. It will write PID to file

 SpringApplication springApplication = new SpringApplication(SpringBootConfig.class);

 springApplication.run(args);     }

}</i>

Когда приложение запустится, оно запишет идентификатор процесса в указанный файл в конфигурации spring.pid.file.

spring.pid.file является необязательным. Если это свойство не указано, то spring boot создаст файл application.pid в корневой папке jar-файла приложения spring boot.

spring.pid.file=e:\\spring-boot-pid\\pid.txt #Location of the PID file to write


* *org.springframework.boot.web.context.WebServerPortFileWriter *- это класс listener для записи порта приложения в файл.

Чтобы записать порт в файл, нам нужно зарегистрировать WebServerPortFileWriter в приложении. Есть два способа зарегистрировать WebServerPortFileWriter в приложении весенней загрузки.

Добавьте WebServerPortFileWriter, используя метод SpringApplication.addListeners().

WebServerPortFileWriter в файл spring.factories в качестве слушателя. убедитесь, что spring.factories должен находиться внутри каталога resources/META-INF.

После регистрации WebServerPortFileWriter Listener, когда приложение запустится, оно автоматически создаст файл application.port в корневом каталоге, где доступен файл .jar.

*WebServerPortFileWriter доступен только после весенней загрузки 2 (spring-boot-starter-parent-2.0.0.RELEASE)!!*

Пример 1-ого способа:







<i>@SpringBootApplication</i></div>



<i>@ComponentScan // Using a root package also allows the @ComponentScan annotation to be used without needing to specify a basePackage attribute</i></div>



<i>public class SpringBootConfig {</i></div>



<i>    public static void main(String[] args) throws Exception {</i></div>



<i> SpringApplication application = new SpringApplication(SpringBootConfig.class);</i></div>



<i><i> </i>application.addListeners(new WebServerPortFileWriter());  </i></div>



<i><i> </i>//application.addListeners(new WebServerPortFileWriter(""YourFileName""));

<i> </i>for custom file name, default file name is application.port </i></div>



<i><i> </i>application.run(); </i></div>



<i>    } </i></div>



<i>}

</i>Пример 2-ого способа:

[source, java]
----
org.springframework.context.ApplicationListener=\ org.springframework.boot.web.context.WebServerPortFileWriter
----
</div></div></div>



== Разница между статическим и динамическим полиморфизмом?



* Переопределение метода (overright) - является примером статического полиморфизма во время компиляции, поскольку привязка метода между вызовом метода и определением метода происходит во время компиляции и зависит от ссылки на класс (ссылка создается во время компиляции и отправляется в стек).


* Перегрузка Переопределение метода (overload) - является примером динамического полиморфизма во время выполнения, потому что привязка метода между вызовом метода и определением метода происходит во время выполнения и зависит от объекта класса (объект создается во время выполнения и отправляется в кучу).



== Как работает Spring Security? Как сконфигурировать? Какие интерфейсы используются?

"

Spring Security обеспечивает всестороннюю поддержку аутентификации, авторизации и защиты от распространенных эксплойтов. Он также обеспечивает интеграцию с другими библиотеками, чтобы упростить его использование.

Spring Security - это список фильтров в виде класса FilterChainProxy, интегрированного в контейнер сервлетов, и в котором есть поле List&lt;SecurityFilterChain&gt;. Каждый фильтр реализует какой-то механизм безопасности. Важна последовательность фильтров в цепочке.

Когда мы добавляем аннотацию @EnableWebSecurity добавляется DelegatingFilterProxy, его задача заключается в том, чтобы вызвать цепочку фильтров (FilterChainProxy) из Spring Security.

В Java-based конфигурации цепочка фильтров создается неявно. Если мы хотим настроить свою цепочку фильтров, мы можем сделать это, создав класс, конфигурирующий наше Spring Security приложение, и унаследовавшись от абстрактного класса WebSecurityConfigurerAdapter. В данном классе, мы можем переопределить метод:

<i>@Override </i></div><i>
protected void configure(HttpSecurity http) throws Exception {</i></div><i>
http</i></div><i>
.csrf().disable()</i></div><i>
.authorizeRequests();</i></div><i>
}</i>

Именно этот метод конфигурирует цепочку фильтров Spring Security и

логика, указанная в этом методе, настроит цепочку фильтров.

Основные классы и интерфейсы

SecurityContext - интерфейс, отражающий контекст безопасности для текущего потока. Является контейнером для объекта типа Authentication. (Аналог - ApplicationContext, в котором лежат бины).

По умолчанию на каждый поток создается один SecurityContext. SecurityContext-ы хранятся в SecurityContextHolder. Имеет только два метода: getAuthentication() setAuthentication(Authentication authentication).

SecurityContextHolder - это место, где Spring Security хранит информацию о том, кто аутентифицирован. Класс, хранящий в ThreadLocal SecurityContext-ы для каждого потока, и содержащий статические методы для работы с SecurityContext-ами, а через них с текущим объектом Authentication, привязанным к нашему веб-запросу.

<img src=""clip_image002-2d7fdc76353aa2c82dbfe771ee2a732c8d1d527c.gif"">

Authentication - объект, отражающий информацию о текущем пользователе и его привилегиях. Вся работа Spring Security будет заключаться в том, что различные фильтры и обработчики будут брать и класть объект Authentication для каждого посетителя. Кстати объект Authentication можно достать в Spring MVC контроллере командой SecurityContextHolder.getContext().getAuthentication(). Authentication имеет реализацию по умолчанию - класс UsernamePasswordAuthenticationToken, предназначенный для хранения логина, пароля и коллекции Authorities.

Principal - интерфейс из пакета java.security, отражающий учетную запись пользователя. В терминах логин-пароль это логин. В интерфейсе Authentication есть метод getPrincipal(), возвращающий Object. При аутентификации с использованием имени пользователя/пароля Principal аутентификации с использованием имени пользователя/пароля Principal реализуется объектом типа UserDetails.

Credentials - любой Object; то, что подтверждает учетную запись пользователя, как правило пароль (отпечатки пальцев, пин - всё это Credentials, а владелец отпечатков и пина - Principal).

GrantedAuthority - полномочия, предоставленные пользователю, например, роли или уровни доступа.

UserDetails - интерфейс, представляющий учетную запись пользователя. Как правило модель нашего пользователя должна имплементировать его. Она просто хранит пользовательскую информацию в виде логина, пароля и флагов isAccountNonExpired, isAccountNonLocked, isCredentialsNonExpired, isEnabled, а также коллекции прав (ролей) пользователя. Данная информация позже инкапсулируется в объекты Authentication.

UserDetailsService - интерфейс объекта, реализующего загрузку пользовательских данных из хранилища. Созданный нами объект с этим интерфейсом должен обращаться к БД и получать оттуда юзеров.

AuthenticationManager - основной стратегический интерфейс для аутентификации. Имеет только один метод, который срабатывает, когда пользователь пытается аутентифицироваться в системе:

AuthenticationManager - основной стратегический интерфейс для аутентификации. Имеет только один метод, который срабатывает, когда пользователь пытается аутентифицироваться в системе:

public interface AuthenticationManager {

Authentication authenticate(Authentication authentication)

throws AuthenticationException;

}

AuthenticationManager может сделать одну из 3 вещей в своем методе authenticate():

вернуть Authentication (с authenticated=true), если предполагается, что вход осуществляет корректный пользователь.

бросить AuthenticationException, если предполагается, что вход осуществляет некорректный пользователь.

вернуть null, если принять решение не представляется возможным.

Наиболее часто используемая реализация AuthenticationManager - родной класс ProviderManager, который содержит поле private List&lt;AuthenticationProvider&gt; providers

со списком AuthenticationProvider-ов и итерирует запрос аутентификации по этому списку AuthenticationProvider-ов. Идея такого разделения - поддержка различных механизмов аутентификации на сайтах.

AuthenticationProvider - интерфейс объекта, аутентификацию. Имеет массу готовых реализаций. Также можем задать свой тип аутентификации. Как правило в небольших проектах одна логика аутентификации - по логину и паролю. В проектах побольше логик может быть несколько: Google-аутентификация и т.д., и для каждой из них создается свой

объект AuthenticationProvider.

AuthenticationProvider немного похож на AuthenticationManager, но у него есть дополнительный метод, позволяющий вызывающей стороне спрашивать, поддерживает ли он переданный ему объект Authentication, возможно этот AuthenticationProvider может

поддерживать аутентификацию по логину и паролю, но не поддерживать

аутентификацию:

boolean supports(java.lang.Class&lt;?&gt; authentication)

PasswordEncoder - интерфейс для шифрования/расшифровывания паролей. Одна из популярных реализаций - BCryptPasswordEncoder.

В случае, если нам необходимо добавить логику при успешной/ неудачной аутентификации, мы можем создать класс и имплементировать интерфейсы AuthenticationSuccessHandler и соответственно, переопределив их методы.

Как это работает с формой логина и UserDetailsService:

* Пользователь вводит в форму и отправляет логин и пароль.

* UsernamePasswordAuthenticationFilter создает объект Authentication - UsernamePasswordAuthenticationToken, где в качестве Principal - логин, а в качестве Credentials - пароль.

* Затем UsernamePasswordAuthenticationToken передаёт Authentication с логином и паролем AuthenticationManager-у.

* AuthenticationManager в виде конкретного ProviderManager внутри своего списка объектов AuthenticationProvider, имеющих разные логики аутентификации, пытается аутентифицировать посетителя, вызывая его метод authenticate(). AuthenticationProvider-а:

* Метод authenticate() принимает в качестве аргумента незаполненный объект Authentication, например только с логином и паролем, полученными в форме логина на сайте. Затем с помощью UserDetailsService метод идёт в БД и ищет такого пользователя.

* Если такой пользователь есть в БД, AuthenticationProvider получает его из базы в виде объекта UserDetails. Объект Authentication заполняется данными из UserDetails - в него включаются Authorities, а в Principal записывается сам объект UserDetails, содержащий пользователя.

* Затем этот метод возвращает заполненный объект Authentication (прошли аутентификацию). AuthenticationSuccessHandler.

* Если логин либо пароль неверные, то выбрасывается исключение. Вызывается AuthenticationFailureHandler.

* Затем этот объект Authentication передается в AccessDecisionManager и получаем решение на получение доступа к запрашиваемой странице (проходим авторизацию).

== Что такое SpringBoot? Какие у него преимущества? Как конфигурируется? Подробно.

Spring Boot - это модуль Spring-а, который предоставляет функцию RAD для среды Spring (Rapid Application Development - Быстрая разработка приложений). Он обеспечивает более простой и быстрый способ настройки и запуска как обычных, так и веб-приложений. Он просматривает наши пути к классам и настроенные нами бины, делает разумные предположения о том, чего нам не хватает, и добавляет эти элементы.`

Spring Boot представляет собой комбинацию Spring Framework и встроенного контейнера сервлетов и отсутствие (или минимальное наличие) конфигурации приложения.

Преимущества Spring Boot:</div>

* Простота управления зависимостями. Для упрощения процесса конфигурации есть starter-пакеты (набор удобных дескрипторов зависимостей).
* Автоматическая конфигурация.


Автоматическая конфигурация включается аннотацией @EnableAutoConfiguration. (входит в состав аннотации @SpringBootApplication)

После выбора необходимых для приложения starter-пакетов Spring Boot попытается автоматически настроить Spring-приложение на основе выбранных jar-зависимостей, доступных в classpath классов, свойств в application.properties и т.п. Например, если добавим spring-boot-starter-web, то Spring boot автоматически сконфигурирует такие бины как DispatcherServlet, ResourceHandlers, MessageSource итд

Автоматическая конфигурация работает в последнюю очередь, после регистрации пользовательских бинов и всегда отдает им приоритет. Если ваш код уже зарегистрировал бин DataSource — автоконфигурация не будет его переопределять.</div>

* Встроенная поддержка сервера и контейнера сервлетов
* Дополнительные функции: метрики, проверки работоспособности, security и внешняя конфигурациии
* Инструмент CLI(command-line interface) для разработки и тестирования приложения Spring Boot.
* Минимизация boilerplate кода (код, который должен быть включен во многих местах практически без изменений), конфигурации XML и аннотаций.




Как происходит автоконфигурация в Spring Boot:

 </div>

* Отмечаем main класс аннотацией @SpringBootApplication (аннотация инкапсулирует в себе: @SpringBootConfiguration, @EnableAutoConfiguration), таким образом наличие @SpringBootApplication включает сканирование компонентов, автоконфигурацию и показывает разным компонентам Spring (например, интеграционным тестам), что это Spring Boot приложение.


<i><u>@SpringBootApplication</u>
<u>public class DemoApplication {</u>
<u>public static void main(String[] args) {</u>
<u>SpringApplication.run(DemoApplication.class, args);</u>
<u>}</u>
<u>}</u></i></div>

* @EnableAutoConfiguration импортирует класс EnableAutoConfigurationImportSelector. Этот класс не объявляет бины сам, а использует так называемые фабрики.
* Класс EnableAutoConfigurationImportSelector смотрит в файл META-INF/spring.factories и загружает оттуда список значений, которые являются именами классов (авто)конфигураций, которые Spring Boot импортирует. Т.е. аннотация @EnableAutoConfiguration просто импортирует ВСЕ (более 150) перечисленные в spring.factories конфигурации, чтобы предоставить нужные бины в контекст приложения.
* Каждая из этих конфигураций пытается сконфигурировать различные аспекты приложения (web, JPA, AMQP и т.д.), регистрируя нужные бины. Логика при регистрации бинов управляется набором @ConditionalOn* аннотаций. Можно указать, чтобы бин создавался при наличии класса в classpath (@ConditionalOnClass), наличии существующего бина (@ConditionalOnBean), отсуствии бина (@ConditionalOnMissingBean) и т.п. Таким образом наличие конфигурации не значит, что бин будет создан, и в большинстве случаев конфигурация ничего делать и создавать не будет.
* Созданный в итоге AnnotationConfigEmbeddedWebApplicationContext ищет в том же DI контейнере фабрику для запуска embedded servlet container.
* Servlet container запускается, приложение готово к работе!




== Расскажите про нововведения Spring 5

* Используется JDK 8+ (Optional, CompletableFuture, Time API, java.util.function, default methods)

* Поддержка Java 9 (Automatic-Module-Name in 5.0, module-info in 6.0+, ASM 6)

* Поддержка HTTP/2 (TLS, Push), NIO/NIO.2

* Поддержка Kotlin

* Реактивность (веб-инфраструктура с реактивным стеком, «Spring WebFlux»)

* Null-safety аннотации(@Nullable), новая документация

* Совместимость с Java EE 8 (Servlet 4.0, Bean Validation 2.0, JPA 2.2, JSON Binding API 1.0)

* Поддержка JUnit 5 + Testing Improvements (conditional and concurrent)

* Удалена поддержка: Portlet, Velocity, JasperReports, XMLBeans, JDO, Guava

== Что такое JWT токен?

"JWT (JSON Web Token) - это открытый стандарт для создания токенов доступа, основанный на формате JSON.

JWT токен состоит из 3 частей, которые разделены точками:



* Header (заголовок) - хранит пары ключ-значения, которые хранят служебную информацию об этом JWT токене.
* Payload (тело / полезная нагрузка) - хранит данные сесси пользователя, это может быть: email, login и все остальное, что хранилось бы в сессии.
* Signature (подпись) - часть токена, которая гаранитрует его неизменяемость, вычисляетя хеш от: header + payload + secret.

""Secret"" - секретный ключ на стороне сервера, который никому кроме него не известен. Алгоритм хеширования может быть любой, но чаще всего используется SHA256.

<span style=""color: rgb(170, 0, 0);"">eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9</span>. // Header

<span style=""color: rgb(170, 0, 255);"">eyJ1c2VySWQiOiJiMDhmODZhZi0zNWRhLTQ4ZjItOGZhYi1jZWYzOTA0NjYwYmQifQ</span>. // Payload

<span style=""color: rgb(0, 170, 255);"">-xN_h82PHVTCMA9vdoHrcZxH-x5mb11y1537t3rGzcM</span> // Signature



"
== "<span style=""color: rgb(0, 170, 255);"">JWT </span>vs. <span style=""color: rgb(217, 0, 0);"">Session + Cookies</span>"

"<span style=""color: rgb(41, 156, 255);"">JWT - ""все свои данные ношу с собой"":</span>



* <span style=""color: rgb(41, 156, 255);"">Stateless (не имеет состяния на сервере, хранит информацию в самом себе)</span>


* <span style=""color: rgb(41, 156, 255);"">если в сессии пользователя много информации её придется передавать в каждом запросе</span>
* <span style=""color: rgb(41, 156, 255);"">нагрузка на сеть и более долгие запросы</span>


* <span style=""color: rgb(41, 156, 255);"">пользователь может посмотреть, что мы храним о нём в нашем токене</span>
* <span style=""color: rgb(41, 156, 255);"">в токене менять данные мы не можем, он находиться на компьютере у пользователя, можем только выдать новый, когда срок старого истечёт</span>



<span style=""color: rgb(217, 0, 0);"">Session + Cookies - данные храню на сервере: </span>



* <span style=""color: rgb(217, 0, 0);"">Stateful (информация хранится на сервере)</span>


* <span style=""color: rgb(217, 0, 0);"">всегда лишь одна пара ключ значение</span>


* <span style=""color: rgb(217, 0, 0);"">более быстрые запросы</span>
* <span style=""color: rgb(217, 0, 0);"">пользователь не знает, что мы храним</span>
* <span style=""color: rgb(217, 0, 0);"">в сессиях мы можем менять данные пользователя у себя на сервере как захотим

</span>





<span style=""color: rgb(0, 255, 0);"">У механизма Session + Cookies больше преимуществ, поэтому JWT используется только тогда, когда в этом есть реальная необходимость.</span></div>

== Что такое Spring Security?

Это компонент Spring Framework - является стандратом обеспечения безопасности в Spring приложениях.

Помогает реализовать функционал аутентификации и авторизации.

Может использоваться как в монолитных так и в микросервисных приложениях.

== Что такое аутентификация и авторизация?

"

* Аутентификация - это когда мы доказываем серверу что это мы, посредством ввода логина и пароля.
* Авторизация - после аутентификации, что мы можем делать внутри сервера? Это зависит от нашей роли (пользователь, администратор), одни роли авторизованы на одно, другие на другое.



<img src=""paste-b92cfe472d17f519846e5a9d3bbc2ffbeb2eee98.png"">



== Как Spring Security встраивается в web приложение?

С помощью *фильтров*.

*Фильтр *- объект, который перехватывает все входящие HTTP запросы. Если в фильтре будет выясненно, что пользователь не тот, то есть, если пользователь не пройдет проверку (аутентификацию), то фильтр не пропустит его дальше до нашего Spring приложения.

== Как устроена аутентификация в Spring?

Есть интерфейс *AuthenticationProvider* с методом *authenticate()*, который принимает на вход объект класса *Authentication*, и так же возвращает объект этого класса.

Аутентификацию методом *authenticate()* можно проводить разными способами, к примеру:



* обращаться к БД, чтобы проверить валидность логиня и пароля пользователя
* можем обращаться к специальному серверу, который проводит аутентификацию

*Authentication *- хранит в себе *Credentials *(логин и пароль пользователя), когда подается на вход в параметры метода и хранит себе объект *Principal*, в который можно получит что угодно, но чаще всего туда ложится сам пользователь (информация о пользователе).

В приложении могут быть несколько *AuthenticationProvider*, каждый со своей реализацией метода *authenticate()*.

Особенность объекта *Principal *- это то что после успешной аутентификации пользователя, при каждом следующем запросе, мы будем иметь доступ к его *Authentication *с *Principal *внутри.

Как это возможно, ведь HTTP stateless? Объект помещается в сессию пользователя. За то, что при каждом запросе этот объект подгружался из сесси отвечает отдельный *фильтр *из Spring Security.

Пока сессия действительна, пользователю не надо проходить аутентификацию при каждом запросе.

== Что такое Session и Cookies?

Session - это набор данных о пользователе и его действиях, хранящихся на сервере, которая поддерживает состояние между HTTP-запросами. HTTP по сути является протоколом без состояния (stateless), сеансы используются для придания ему состояния. С помощью Cookies, сервер определяет какой сеанс принадлежит какому пользователю.

Cookies - это пара ключ - значение, который посыется бразуером при каждом запросе к какому-то серверу, чаще всего они содержать какую-то персональную информацию, как например ID, через который сервер может определить сессию пользователя.

Cookies находится в памяти браузера и ваш браузер заботиться о том, чтобы отправлять их только тем доменам, которые идентифицированы с ними.

== Возможны ли коллизии при шифровании пароля через SHA256 или BCrypt?

Да, теоритически это возможно, поскольку мы превращаем одну строку в другю фиксированный длинны, но это вероятность настолько мала, что ей можно пренебречь.

== Что такое детерминированный и недетерминированный алгоритм шифрования? Какой из них должен применятся в шифровании паролей?



* Детерминированный алгоритм всегда возвращает одно и тоже значения для какого-то аргумента.
* Недетерминированный алгоритм возвращает рандомные значения для одной и того же параметра.





Нужно применять детерминированный.

== Что такое одно/двусторонняя функция в шифровании?

Односторонняя это когда мы не можем из шифра получить зашифрованный текст, а двусторонняя, когда можем.

== Что такое микросервисная архитектура?

Микросервисы - Spring Cloud

Микросервисная архитектура - это архитектура приложения, которая строится как набор небольших и слабосвязанных компонентов (микросервисов), которые можно разрабатывать, развертывать и поддерживать независимо друг от друга.

== Плюсы и минусы микросервисов?

Плюсы:



* нет привязки к конкретным языкам и технологиям
* простая интеграция со сторонними решениями и возможность повторного использования
* практически бесконечная масштабируемость
* простота обслуживания
* отказоустойчивость
* упрощенная симметричная архитектура приложения вместо иерархической с одноранговыми зависимостями между компонентами
* внесение правок без рисков “обрушить” всю систему
* возможность производить обновления чаще и быстрее, так как использование микросервисов позволяет обновлять приложение п частям

Минусы:



* миграция монолитной архитектуры в микросервисную может обойтись очень дорого
* для развертывания микросервисов потребуются опытные специалисты
* Более сложный DevOps
* Мониторинг сложнее
* Retry запросы
* Распределенные логи и трейсинг запросов
* Circuit breaking
* Дубли данных



== Что такое монолитная архитектура?

Монолитная архитектура - это архитектура приложения, которая строится как единое целое, где вся логика по обработке запросов помещается внутрь одного процесса. Разумеется, монолиты могут иметь модульную структуру — содержать отдельные классы, функции и т.п. Но связи между этими модулями настолько сильны, что изменение каждого из них неизбежно отражается на работе приложения в целом.

== Плюсы и минусы монолитной архитектуры?

Плюсы:



* Упрощенная разработка и развертывание
* Меньше сквозных проблем
* Лучшая производительность
* Не надо отслеживать HTTP запросы

Минусы:



* Кодовая база со временем становится громоздкой
* Сложно внедрять новые технологии
* Небольшое обновление требует полного повторного развертывания
* Невозможность масштабирования части приложения
* Отказ одного модуля чаще всего сказывается на всей работе



== Как общаются между собой микросервисы?

Есть два варианта: синхронное взаимодействие или асинхронное взаимодействие.



* Синхронное взаимодействие с помощью HTTP/REST сервисов

Синхронное взаимодействие микросервисов обычно осуществляется через HTTP и REST-подобные сервисы, которые возвращают XML или JSON — хотя это ни в коем случае не является обязательным (посмотрите, например, на Google Protocol Buffers).

Используйте REST-коммуникацию, когда вам нужен немедленный ответ, который мы используем в нашем случае, так как проверка риска обязательна перед открытием счета: нет проверки риска, нет счета.


* Асинхронное взаимодействие с помощью обменасообщениями

Асинхронная микросервисная связь обычно осуществляется посредством обмена сообщениями с помощью реализации JMS и/или с помощью протокола, такого как AMQP. Обычно, на практике не следует недооценивать интеграцию по электронной почте / SMTP.

Используйте асинхронное взаимодействие, когда вам не нужен немедленный ответ, скажем, пользователи нажимают кнопку «купить сейчас», и вы хотите сгенерировать счет-фактуру, что, безусловно, не должно происходить в рамках цикла запроса-ответа пользователя на покупку.



== Как понять, какой микросервис упал?



* Spring sleuth
* Нужно добавить трассировку по id к запросу (паттернDistributing TracerId)



== Что такое Load Balancer?

Балансировщик нагрузки – перенаправляет запросы на нужный экземпляр приложения (если их запущено несколько).

Распределяет траффик между экземплярами микросервисов. Раньше использовалась интеграция с LB Netflix Ribbon Сейчас Spring разработал свою реализацию: Spring Cloud Load Balancer. Рекомендуется использовать ее.

В Spring API Gateway уже автоматически встроен LB, который сам принимает решение, куда перенаправить запрос, “видит” какие экземпляры запущены и пр.

== Что такое API Gateway?

Является шлюзом, который обрабатывает входящие запросы и “перекидывает” их на нужный мс (с логированием, кешированием, безопасностью и пр.)

В технологиях Spring это направление называется Spring Cloud Gateway микросервисов.

AG – это маршрутизатор запросов (он сам не содержит микросервисы, а только перенаправляет запросы)

== Что такое REST? Принципы REST?

REST - означает Representational State Transfer (Передача состояния представления)

REST API — REST - это набор правил (архитектурный стиль) о том, какпрограммисту организовать написание кода серверного приложения, чтобы все системы легко обменивались данными и приложение можно было масштабировать. И использует HTTP-запросы для получения, извлечения, размещения и удаления данных. Его также называют RESTful.

*ПРИНЦИПЫ REST API*

Принципы REST API определены в диссертации его создателя Роя Филдинга. Основные из них:



* единый интерфейс
* разграничение клиента и сервера
* нет сохранения состояния
* кэширование всегда разрешено
* многоуровневая система
* код предоставляется по запросу.





</div>

* Единый интерфейс

Ресурсы должны быть однозначно идентифицированы посредством одного URL-адреса и только с помощью базовых методов сетевого протокола (DELETE, PUT, GET, HTTP).


* Клиент-сервер

Должно быть четкое разграничение между клиентом и сервером:

пользовательский интерфейс и вопросы сбора запросов — на стороне клиента.

доступ к данным, управление рабочей нагрузкой и безопасность — на сторонесервера.


* Сохранение состояния

Все клиент-серверные операции должны быть без сохранения состояния. Любое необходимое управление состоянием должно осуществляться наклиенте, а не на сервере.


* Кэширование

Все ресурсы должны разрешать кэширование, если явно не указано, что оно невозможно.


* Многоуровневая система

REST API допускает архитектуру, которая состоит из нескольких уровней серверов.
* Запрос кодаВ большинстве случаев сервер отправляет обратно статические представленияресурсов в формате XML или JSON. Однако при необходимости серверы могутотправлять исполняемый код непосредственно клиенту.


